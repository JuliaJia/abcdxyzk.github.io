<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: kernel | kk Blog —— 通用基础]]></title>
  <link href="http://abcdxyzk.github.io/blog/cats/kernel/atom.xml" rel="self"/>
  <link href="http://abcdxyzk.github.io/"/>
  <updated>2015-05-13T14:20:30+08:00</updated>
  <id>http://abcdxyzk.github.io/</id>
  <author>
    <name><![CDATA[kk]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[tcp三个接收队列]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/05/11/kernel-net-tcp_queue/"/>
    <updated>2015-05-11T15:46:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/05/11/kernel-net-tcp_queue</id>
    <content type="html"><![CDATA[<p><a href="http://www.cnblogs.com/alreadyskb/p/4386565.html">http://www.cnblogs.com/alreadyskb/p/4386565.html</a></p>

<h4>三个接收队列</h4>

<ul>
<li>tcp协议栈数据接收实现了三个接收缓存分别是prequeue、sk_write_queue、sk_backlog。</li>
</ul>


<p>之所以需要三个接收缓存的原因如下：<br/>
tcp协议栈接收到数据包时struct sock *sk 可能被进程下上文或者中断上下文占用：</p>

<p>  1、如果处于进程上下文sk_lock.owned=1，软中断因为sk_lock.owned=1，所以数据只能暂存在后备队列中（backlog），当进程上下文逻辑处理完成后会回调tcp_v4_do_rcv处理backlog队列作为补偿，具体看tcp_sendmsg 函数 release_sock的实现。</p>

<p>  2、如果当前处于中断上下文，sk_lock.owned=0，那么数据可能被放置到receive_queue或者prequeue，数据优先放置到prequeue中，如果prequeue满了则会放置到receive_queue中，理论上这里有一个队列就行了，但是TCP协议栈为什么要设计两个呢？其实是为了快点结束软中断数据处理流程，软中断处理函数中禁止了进程抢占和其他软中断发生，效率应该是很低下的，如果数据被放置到prequeue中，那么软中断流程很快就结束了，如果放置到receive_queue那么会有很复杂的逻辑需要处理。receive_queue队列的处理在软中断中，prequeue队列的处理则是在进程上下文中。总的来说就是为了提高TCP协议栈的效率。</p>

<h4>后备队列的处理逻辑</h4>

<h5>1、什么时候使用后备队列</h5>

<p>tcp协议栈对struct sock <em>sk有两把锁，第一把是sk_lock.slock，第二把则是sk_lock.owned。sk_lock.slock用于获取struct sock </em>sk对象的成员的修改权限；sk_lock.owned用于区分当前是进程上下文或是软中断上下文，为进程上下文时sk_lock.owned会被置1，中断上下文为0。</p>

<p>如果是要对sk修改，首先是必须拿锁sk_lock.slock，其后是判断当前是软中断或是进程上下文，如果是进程上下文，那么接收到的skb则只能先放置到后备队列中sk_backlog中。如果是软中断上下文则可以放置到prequeue和sk_write_queue中。</p>

<p>代码片段如下：
<code>
        bh_lock_sock_nested(sk);               // 获取第一把锁。
        ret = 0;
        if (!sock_owned_by_user(sk)) {         // 判断第二把锁，区分是处于进程上下文还是软中断上下文。
    #ifdef CONFIG_NET_DMA
            struct tcp_sock *tp = tcp_sk(sk);
            if (!tp-&gt;ucopy.dma_chan &amp;&amp; tp-&gt;ucopy.pinned_list)
                tp-&gt;ucopy.dma_chan = dma_find_channel(DMA_MEMCPY);
            if (tp-&gt;ucopy.dma_chan)
                ret = tcp_v4_do_rcv(sk, skb);
            else
    #endif
            {
                if (!tcp_prequeue(sk, skb))    // 如果处于中断上下文，则优先放置到prequeue中，如果prequeue满则放置到sk_write_queue中。
                    ret = tcp_v4_do_rcv(sk, skb);
            }
        } else if (unlikely(sk_add_backlog(sk, skb,  // 如果是处于进程上下文则直接放置到后备队列中(sk_backlog中)。
                            sk-&gt;sk_rcvbuf + sk-&gt;sk_sndbuf))) {
            bh_unlock_sock(sk);
            NET_INC_STATS_BH(net, LINUX_MIB_TCPBACKLOGDROP);
            goto discard_and_relse;
        }
        bh_unlock_sock(sk);
</code></p>

<h5>2、skb怎么add到sk_backlog中</h5>

<p>sk_add_backlog函数用于add sbk到sk_backlog中，所以下面我们分析次函数。
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/&lt;em&gt; The per-socket spinlock must be held here. &lt;/em&gt;/
</span><span class='line'>static inline __must_check int sk_add_backlog(struct sock &lt;em&gt;sk, struct sk_buff &lt;/em&gt;skb,
</span><span class='line'>                           unsigned int limit)
</span><span class='line'>{
</span><span class='line'>    if (sk_rcvqueues_full(sk, skb, limit))  // 判断接收缓存是否已经用完了，很明显sk_backlog的缓存大小也算在了总接收缓存中。
</span><span class='line'>        return -ENOBUFS;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    __sk_add_backlog(sk, skb);              // 将skb添加到sk_backlog队列中。
</span><span class='line'>sk_extended(sk)-&gt;sk_backlog.len += skb-&gt;truesize;  // 更新sk_backlog中已经挂载的数据量。
</span><span class='line'>return 0;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;/* OOB backlog add */
</span><span class='line'>static inline void __sk_add_backlog(struct sock *sk, struct sk_buff *skb)
</span><span class='line'>{
</span><span class='line'>if (!sk-&gt;sk_backlog.tail) {   // 如果当前sk_backlog为NULL，此时head和tail都指向skb。
</span><span class='line'>    sk-&gt;sk_backlog.head = sk-&gt;sk_backlog.tail = skb;
</span><span class='line'>} else {                      // 分支表示sk_backlog中已经有数据了，那么skb直接挂在tail的尾部，之后tail指针后移到skb。
</span><span class='line'>    sk-&gt;sk_backlog.tail-&gt;next = skb;
</span><span class='line'>    sk-&gt;sk_backlog.tail = skb;
</span><span class='line'>}
</span><span class='line'>skb-&gt;next = NULL;             // 这种很重要，在sk_backlog处理时会用来判断skb是否处理完毕。
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>##### 3、sk_backlog中skb的处理
</span><span class='line'>
</span><span class='line'>很明显sk_backlog的处理必然中进程上下文进行，对于数据接收，进程上下文的接口是tcp_recvmmsg，所以sk_backlog肯定要在tcp_recvmmsg中处理。
</span><span class='line'>
</span><span class='line'>tcp_recvmmsg sk_backlog的代码处理片段如下：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;tcp_cleanup_rbuf(sk, copied);
</span><span class='line'>TCP_CHECK_TIMER(sk);
</span><span class='line'>release_sock(sk);
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>release_sock(sk)涉及到sk_backlog处理。
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;void release_sock(struct sock *sk)
</span><span class='line'>{
</span><span class='line'>/*
</span><span class='line'>* The sk_lock has mutex_unlock() semantics:
</span><span class='line'>*/
</span><span class='line'>mutex_release(&amp;sk-&gt;sk_lock.dep_map, 1, _RET_IP_);
</span><span class='line'>
</span><span class='line'>spin_lock_bh(&amp;sk-&gt;sk_lock.slock);   // 获取第一把锁。
</span><span class='line'>if (sk-&gt;sk_backlog.tail)            // 如果后备队列不为NULL，则开始处理。
</span><span class='line'>    __release_sock(sk);
</span><span class='line'>
</span><span class='line'>if (proto_has_rhel_ext(sk-&gt;sk_prot, RHEL_PROTO_HAS_RELEASE_CB) &amp;&amp;
</span><span class='line'>        sk-&gt;sk_prot-&gt;release_cb)
</span><span class='line'>    sk-&gt;sk_prot-&gt;release_cb(sk);
</span><span class='line'>
</span><span class='line'>sk-&gt;sk_lock.owned = 0;              // 进成上下文skb处理完了，释放第二把锁。
</span><span class='line'>if (waitqueue_active(&amp;sk-&gt;sk_lock.wq))
</span><span class='line'>    wake_up(&amp;sk-&gt;sk_lock.wq);
</span><span class='line'>spin_unlock_bh(&amp;sk-&gt;sk_lock.slock); // 释放第一把锁。
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>`__release_sock(sk)`是后备队列的真正处理函数。
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;static void __release_sock(struct sock *sk)
</span><span class='line'>{
</span><span class='line'>struct sk_buff *skb = sk-&gt;sk_backlog.head;
</span><span class='line'>
</span><span class='line'>do {
</span><span class='line'>    sk-&gt;sk_backlog.head = sk-&gt;sk_backlog.tail = NULL;
</span><span class='line'>    bh_unlock_sock(sk);
</span><span class='line'>
</span><span class='line'>    do {
</span><span class='line'>        struct sk_buff *next = skb-&gt;next;
</span><span class='line'>
</span><span class='line'>        skb-&gt;next = NULL;
</span><span class='line'>        sk_backlog_rcv(sk, skb);    // skb的处理函数，其实调用的是tcp_v4_do_rcv函数。
</span><span class='line'>
</span><span class='line'>        /*
</span><span class='line'>         * We are in process context here with softirqs
</span><span class='line'>         * disabled, use cond_resched_softirq() to preempt.
</span><span class='line'>         * This is safe to do because we've taken the backlog
</span><span class='line'>         * queue private:
</span><span class='line'>         */
</span><span class='line'>        cond_resched_softirq();
</span><span class='line'>
</span><span class='line'>        skb = next;
</span><span class='line'>    } while (skb != NULL);          // 如果skb=NULL，那么说明之前的sk_backlog已经处理完了。
</span><span class='line'>
</span><span class='line'>    bh_lock_sock(sk);
</span><span class='line'>} while ((skb = sk-&gt;sk_backlog.head) != NULL); // 在处理上一个sk_backlog时，可能被软中断中断了，建立了新的sk_backlog，新建立的sk_backlog也将一并被处理。
</span><span class='line'>
</span><span class='line'>/*
</span><span class='line'>* Doing the zeroing here guarantee we can not loop forever
</span><span class='line'>* while a wild producer attempts to flood us.
</span><span class='line'>*/
</span><span class='line'>sk_extended(sk)-&gt;sk_backlog.len = 0;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;code&gt;``
</span><span class='line'>  一开始重置sk-&gt;sk_backlog.head ，sk-&gt;sk_backlog.tail为NULL。sk_backlog是一个双链表，head指向了链表头部的skb，而tail则指向了链表尾部的skb。这里之所以置NULL head 和tail，是因为struct sk_buff *skb = sk-&gt;sk_backlog.head 提前取到了head指向的skb，之后就可以通过skb-&gt;next来获取下一个skb处理，结束的条件是skb-&gt;next=NULL，这个是在&lt;/code&gt;__sk_add_backlog`函数中置位的，也就说对于sk_backlog的处理head和tail指针已经没有用了。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  为什么要置NULLsk-&gt;sk_backlog.head ，sk-&gt;sk_backlog.tail呢？第一想法是它可能要被重新使用了。那么在什么情况下会被重新使用呢？试想一下当前是在进程上下文，并且sk-&gt;sk_lock.slock没有被锁住，那是不是可能被软中断打断呢？如果被软中断打断了是不是要接收数据呢，tcp协议栈为了效率考虑肯定是要接收数据的，前面分析道这种情况的数据必须放置到后备队列中(sk_backlog)，所以可以肯定置NULL sk-&gt;sk_backlog.head ，sk-&gt;sk_backlog.tail是为了在处理上一个sk_backlog时，能重用sk_backlog，建立一条新的sk_backlog，或许有人会问为什么不直接添加到原先的sk_backlog tail末尾呢？这个问题我也没有想太清楚，或许是同步不好做吧。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h5&gt;4、skb被处理到哪去了&lt;/h5&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  很明显接收的数据最终都将被传递到应用层，在传递到应用层前必须要保证三个接收队列中的数据有序，那么这三个队列是怎么保证数据字节流有序的被递交给应用层呢？三个队列都会调用tcp_v4_do_rcv函数，prequeue和sk_backlog是在tcp_recvmsg中调用tcp_v4_do_rcv函数，也就是进程上下文中调用tcp_v4_do_rcv函数，但会local_bh_disable禁止软中断。如果在tcp_rcv_established, tcp_data_queue中如果刚好数据可以直接copy到用户空间，又会短暂开始软中断local_bh_enable。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  但在tcp_checksum_complete_user、tcp_rcv_established、tcp_data_queue函数中开启软中断将来容易出问题，进入软中断:softirq()+=1; local_bh_enable:softirq()-=2; 所以现在只是软中断中softirq()统计不准，进程中还是准的。但如果以后在软中断中在local_bh_enable之前给softirq()+=1了，那么就会导致软中断被打断，导致软中断执行途中被切走而且永远切不回来。tcp_checksum_complete_user被切走导致收包不成功，tcp_rcv_established、tcp_data_queue函数中如果在tp-&gt;copied_seq+=chunk后被切走就会导致tp-&gt;copied_seq&gt;tp-&gt;rcv_nxt，那么下次收包后就有可能出现tp-&gt;copied_seq &gt; sk_write_queue.first.end_seq, 等异常。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  如果仔细分析tcp_v4_do_rcv函数能发现，这个函数能保证数据有序的排列在一起，所以无论是在处理sk_backlog还是prequeue，最终都会调用tcp_v4_do_rcv函数将数据有效地插入到sk_write_queue中，最后被应用层取走。&lt;/p&gt;
</span><span class='line'>]]&gt;&lt;/content&gt;
</span><span class='line'>  &lt;/entry&gt;
</span><span class='line'>  
</span><span class='line'>  &lt;entry&gt;
</span><span class='line'>&lt;title type="html"&gt;&lt;![CDATA[中断子系统之（八）：softirq]]&gt;&lt;/title&gt;
</span><span class='line'>&lt;link href="http://abcdxyzk.github.io/blog/2015/05/07/kernel-irq-softirq/"/&gt;
</span><span class='line'>&lt;updated&gt;2015-05-07T16:04:00+08:00&lt;/updated&gt;
</span><span class='line'>&lt;id&gt;http://abcdxyzk.github.io/blog/2015/05/07/kernel-irq-softirq&lt;/id&gt;
</span><span class='line'>&lt;content type="html"&gt;&lt;![CDATA[&lt;p&gt;&lt;a href="http://www.wowotech.net/linux_kenrel/soft-irq.html"&gt;http://www.wowotech.net/linux_kenrel/soft-irq.html&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h3&gt;一、前言&lt;/h3&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;对于中断处理而言，linux将其分成了两个部分，一个叫做中断handler（top half），是全程关闭中断的，另外一部分是deferable task（bottom half），属于不那么紧急需要处理的事情。在执行bottom half的时候，是开中断的。有多种bottom half的机制，例如：softirq、tasklet、workqueue或是直接创建一个kernel thread来执行bottom half（这在旧的kernel驱动中常见，现在，一个理智的driver厂商是不会这么做的）。本文主要讨论softirq机制。由于tasklet是基于softirq的，因此本文也会提及tasklet，但主要是从需求层面考虑，不会涉及其具体的代码实现。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;在普通的驱动中一般是不会用到softirq，但是由于驱动经常使用的tasklet是基于softirq的，因此，了解softirq机制有助于撰写更优雅的driver。softirq不能动态分配，都是静态定义的。内核已经定义了若干种softirq number，例如网络数据的收发、block设备的数据访问（数据量大，通信带宽高），timer的deferable task（时间方面要求高）。本文的第二章讨论了softirq和tasklet这两种机制有何不同，分别适用于什么样的场景。第三章描述了一些context的概念，这是要理解后续内容的基础。第四章是进入softirq的实现，对比hard irq来解析soft irq的注册、触发，调度的过程。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;ul&gt;
</span><span class='line'>&lt;li&gt;注：本文中的linux kernel的版本是3.14&lt;/li&gt;
</span><span class='line'>&lt;/ul&gt;
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>&lt;h3&gt;二、为何有softirq和tasklet&lt;/h3&gt;
</span><span class='line'>
</span><span class='line'>&lt;h4&gt;1、为何有top half和bottom half&lt;/h4&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;中断处理模块是任何OS中最重要的一个模块，对系统的性能会有直接的影响。想像一下：如果在通过U盘进行大量数据拷贝的时候，你按下一个key，需要半秒的时间才显示出来，这个场景是否让你崩溃？因此，对于那些复杂的、需要大量数据处理的硬件中断，我们不能让handler中处理完一切再恢复现场（handler是全程关闭中断的），而是仅仅在handler中处理一部分，具体包括：&lt;br/&gt;
</span><span class='line'>（1）有实时性要求的&lt;br/&gt;
</span><span class='line'>（2）和硬件相关的。例如ack中断，read HW FIFO to ram等&lt;br/&gt;
</span><span class='line'>（3）如果是共享中断，那么获取硬件中断状态以便判断是否是本中断发生&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;除此之外，其他的内容都是放到bottom half中处理。在把中断处理过程划分成top half和bottom half之后，关中断的top half被瘦身，可以非常快速的执行完毕，大大减少了系统关中断的时间，提高了系统的性能。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;我们可以基于下面的系统进一步的进行讨论：&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;img src="/images/kernel/2015-05-07-11.gif" alt="" /&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;当网卡控制器的FIFO收到的来自以太网的数据的时候（例如半满的时候，可以软件设定），可以将该事件通过irq signal送达Interrupt Controller。Interrupt Controller可以把中断分发给系统中的Processor A or B。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;NIC的中断处理过程大概包括：
</span><span class='line'>&lt;code&gt;
</span><span class='line'>mask and ack interrupt controller---&gt;ack NIC---&gt;copy FIFO to ram---&gt;handle Data in the ram---&gt;unmask interrupt controller
</span><span class='line'>&lt;/code&gt;
</span><span class='line'>我们先假设Processor A处理了这个网卡中断事件，于是NIC的中断handler在Processor A上欢快的执行，这时候，Processor A的本地中断是disable的。NIC的中断handler在执行的过程中，网络数据仍然源源不断的到来，但是，如果NIC的中断handler不操作NIC的寄存器来ack这个中断的话，NIC是不会触发下一次中断的。还好，我们的NIC interrupt handler总是在最开始就会ack，因此，这不会导致性能问题。ack之后，NIC已经具体再次trigger中断的能力。当Processor A上的handler 在处理接收来自网络的数据的时候，NIC的FIFO很可能又收到新的数据，并trigger了中断，这时候，Interrupt controller还没有umask，因此，即便还有Processor B（也就是说有处理器资源），中断控制器也无法把这个中断送达处理器系统。因此，只能眼睁睁的看着NIC FIFO填满数据，数据溢出，或者向对端发出拥塞信号，无论如何，整体的系统性能是受到严重的影响。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;注意：对于新的interrupt controller，可能没有mask和umask操作，但是原理是一样的，只不过NIC的handler执行完毕要发生EOI而已。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;要解决上面的问题，最重要的是尽快的执行完中断handler，打开中断，unmask IRQ（或者发送EOI），方法就是把耗时的handle Data in the ram这个步骤踢出handler，让其在bottom half中执行。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h4&gt;2、为何有softirq和tasklet&lt;/h4&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;OK，linux kernel已经把中断处理分成了top half和bottom half，看起来已经不错了，那为何还要提供softirq、tasklet和workqueue这些bottom half机制，linux kernel本来就够复杂了，bottom half还来添乱。实际上，在早期的linux kernel还真是只有一个bottom half机制，简称BH，简单好用，但是性能不佳。后来，linux kernel的开发者开发了task queue机制，试图来替代BH，当然，最后task queue也消失在内核代码中了。现在的linux kernel提供了三种bottom half的机制，来应对不同的需求。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;workqueue和softirq、tasklet有本质的区别：workqueue运行在process context，而softirq和tasklet运行在interrupt context。因此，出现workqueue是不奇怪的，在有sleep需求的场景中，defering task必须延迟到kernel thread中执行，也就是说必须使用workqueue机制。softirq和tasklet是怎么回事呢？从本质上将，bottom half机制的设计有两方面的需求，一个是性能，一个是易用性。设计一个通用的bottom half机制来满足这两个需求非常的困难，因此，内核提供了softirq和tasklet两种机制。softirq更倾向于性能，而tasklet更倾向于易用性。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;我们还是进入实际的例子吧，还是使用上一节的系统图。在引入softirq之后，网络数据的处理如下：&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;关中断：
</span><span class='line'>&lt;code&gt;
</span><span class='line'>mask and ack interrupt controller---&gt;ack NIC---&gt;copy FIFO to ram---&gt;raise softirq---&gt;unmask interrupt controller
</span><span class='line'>&lt;/code&gt;
</span><span class='line'>开中断：在softirq上下文中进行handle Data in the ram的动作&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;同样的，我们先假设Processor A处理了这个网卡中断事件，很快的完成了基本的HW操作后，raise softirq。在返回中断现场前，会检查softirq的触发情况，因此，后续网络数据处理的softirq在processor A上执行。在执行过程中，NIC硬件再次触发中断，Interrupt controller将该中断分发给processor B，执行动作和Processor A是类似的，因此，最后，网络数据处理的softirq在processor B上执行。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;为了性能，同一类型的softirq有可能在不同的CPU上并发执行，这给使用者带来了极大的痛苦，因为驱动工程师在撰写softirq的回调函数的时候要考虑重入，考虑并发，要引入同步机制。但是，为了性能，我们必须如此。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;当网络数据处理的softirq同时在Processor A和B上运行的时候，网卡中断又来了（可能是10G的网卡吧）。这时候，中断分发给processor A，这时候，processor A上的handler仍然会raise softirq，但是并不会调度该softirq。也就是说，softirq在一个CPU上是串行执行的。这种情况下，系统性能瓶颈是CPU资源，需要增加更多的CPU来解决该问题。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;如果是tasklet的情况会如何呢？为何tasklet性能不如softirq呢？如果一个tasklet在processor A上被调度执行，那么它永远也不会同时在processor B上执行，也就是说，tasklet是串行执行的（注：不同的tasklet还是会并发的），不需要考虑重入的问题。我们还是用网卡这个例子吧（注意：这个例子仅仅是用来对比，实际上，网络数据是使用softirq机制的），同样是上面的系统结构图。假设使用tasklet，网络数据的处理如下：&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;关中断：
</span><span class='line'>&lt;code&gt;
</span><span class='line'>mask and ack interrupt controller---&gt;ack NIC---&gt;copy FIFO to ram---&gt;schedule tasklet---&gt;unmask interrupt controller
</span><span class='line'>&lt;/code&gt;
</span><span class='line'>开中断：在softirq上下文中（一般使用TASKLET_SOFTIRQ这个softirq）进行handle Data in the ram的动作&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;同样的，我们先假设Processor A处理了这个网卡中断事件，很快的完成了基本的HW操作后，schedule tasklet（同时也就raise TASKLET_SOFTIRQ softirq）。在返回中断现场前，会检查softirq的触发情况，因此，在TASKLET_SOFTIRQ softirq的handler中，获取tasklet相关信息并在processor A上执行该tasklet的handler。在执行过程中，NIC硬件再次触发中断，Interrupt controller将该中断分发给processor B，执行动作和Processor A是类似的，虽然TASKLET_SOFTIRQ softirq在processor B上可以执行，但是，在检查tasklet的状态的时候，如果发现该tasklet在其他processor上已经正在运行，那么该tasklet不会被处理，一直等到在processor A上的tasklet处理完，在processor B上的这个tasklet才能被执行。这样的串行化操作虽然对驱动工程师是一个福利，但是对性能而言是极大的损伤。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h3&gt;三、理解softirq需要的基础知识（各种context）&lt;/h3&gt;
</span><span class='line'>
</span><span class='line'>&lt;h4&gt;1、preempt_count&lt;/h4&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;为了更好的理解下面的内容，我们需要先看看一些基础知识：一个task的thread info数据结构定义如下（只保留和本场景相关的内容）：
</span><span class='line'>&lt;code&gt;
</span><span class='line'>struct thread_info {
</span><span class='line'>    ......
</span><span class='line'>    int preempt_count;    /* 0 =&gt; preemptable, &lt;0 =&gt; bug */
</span><span class='line'>    ......
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;
</span><span class='line'>preempt_count这个成员被用来判断当前进程是否可以被抢占。如果preempt_count不等于0（可能是代码调用preempt_disable显式的禁止了抢占，也可能是处于中断上下文等），说明当前不能进行抢占，如果preempt_count等于0，说明已经具备了抢占的条件（当然具体是否要抢占当前进程还是要看看thread info中的flag成员是否设定了_TIF_NEED_RESCHED这个标记，可能是当前的进程的时间片用完了，也可能是由于中断唤醒了优先级更高的进程）。 具体preempt_count的数据格式可以参考下图：&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;img src="/images/kernel/2015-05-07-12.gif" alt="" /&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;preemption count用来记录当前被显式的禁止抢占的次数，也就是说，每调用一次preempt_disable，preemption count就会加一，调用preempt_enable，该区域的数值会减去一。preempt_disable和preempt_enable必须成对出现，可以嵌套，最大嵌套的深度是255。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;hardirq count描述当前中断handler嵌套的深度。对于ARM平台的linux kernel，其中断部分的代码如下：</span></code></pre></td></tr></table></div></figure>
    void handle_IRQ(unsigned int irq, struct pt_regs <em>regs)
    {
        struct pt_regs </em>old_regs = set_irq_regs(regs);</p>

<pre><code>    irq_enter(); 
    generic_handle_irq(irq);

    irq_exit();
    set_irq_regs(old_regs);
}
</code></pre>

<pre><code>通用的IRQ handler被irq_enter和irq_exit这两个函数包围。irq_enter说明进入到IRQ context，而irq_exit则说明退出IRQ context。在irq_enter函数中会调用preempt_count_add(HARDIRQ_OFFSET)，为hardirq count的bit field增加1。在irq_exit函数中，会调用preempt_count_sub(HARDIRQ_OFFSET)，为hardirq count的bit field减去1。hardirq count占用了4个bit，说明硬件中断handler最大可以嵌套15层。在旧的内核中，hardirq count占用了12个bit，支持4096个嵌套。当然，在旧的kernel中还区分fast interrupt handler和slow interrupt handler，中断handler最大可以嵌套的次数理论上等于系统IRQ的个数。在实际中，这个数目不可能那么大（内核栈就受不了），因此，即使系统支持了非常大的中断个数，也不可能各个中断依次嵌套，达到理论的上限。基于这样的考虑，后来内核减少了hardirq count占用bit数目，改成了10个bit（在general arch的代码中修改为10，实际上，各个arch可以redefine自己的hardirq count的bit数）。但是，当内核大佬们决定废弃slow interrupt handler的时候，实际上，中断的嵌套已经不会发生了。因此，理论上，hardirq count要么是0，要么是1。不过呢，不能总拿理论说事，实际上，万一有写奇葩或者老古董driver在handler中打开中断，那么这时候中断嵌套还是会发生的，但是，应该不会太多（一个系统中怎么可能有那么多奇葩呢？呵呵），因此，目前hardirq count占用了4个bit，应付15个奇葩driver是妥妥的。

对softirq count进行操作有两个场景：

（1）也是在进入soft irq handler之前给 softirq count加一，退出soft irq handler之后给 softirq count减去一。由于soft irq handler在一个CPU上是不会并发的，总是串行执行，因此，这个场景下只需要一个bit就够了，也就是上图中的bit 8。通过该bit可以知道当前task是否在sofirq context。

（2）由于内核同步的需求，进程上下文需要禁止softirq。这时候，kernel提供了local_bf_enable和local_bf_disable这样的接口函数。这部分的概念是和preempt disable/enable类似的，占用了bit9～15，最大可以支持127次嵌套。

#### 2、一个task的各种上下文

看完了preempt_count之后，我们来介绍各种context：
</code></pre>

<pre><code>#define in_irq()        (hardirq_count())
#define in_softirq()        (softirq_count())
#define in_interrupt()        (irq_count())

#define in_serving_softirq()    (softirq_count() &amp; SOFTIRQ_OFFSET)
</code></pre>

<pre><code>这里首先要介绍的是一个叫做IRQ context的术语。这里的IRQ context其实就是hard irq context，也就是说明当前正在执行中断handler（top half），只要preempt_count中的hardirq count大于0（＝1是没有中断嵌套，如果大于1，说明有中断嵌套），那么就是IRQ context。

softirq context并没有那么的直接，一般人会认为当sofirq handler正在执行的时候就是softirq context。这样说当然没有错，sofirq handler正在执行的时候，会增加softirq count，当然是softirq context。不过，在其他context的情况下，例如进程上下文中，有有可能因为同步的要求而调用local_bh_disable，这时候，通过local_bh_disable/enable保护起来的代码也是执行在softirq context中。当然，这时候其实并没有正在执行softirq handler。如果你确实想知道当前是否正在执行softirq handler，in_serving_softirq可以完成这个使命，这是通过操作preempt_count的bit 8来完成的。

所谓中断上下文，就是IRQ context ＋ softirq context＋NMI context。

### 四、softirq机制

softirq和hardirq（就是硬件中断啦）是对应的，因此softirq的机制可以参考hardirq对应理解，当然softirq是纯软件的，不需要硬件参与。

#### 1、softirq number

和IRQ number一样，对于软中断，linux kernel也是用一个softirq number唯一标识一个softirq，具体定义如下：
</code></pre>

<pre><code>enum
{
    HI_SOFTIRQ=0,
    TIMER_SOFTIRQ,
    NET_TX_SOFTIRQ,
    NET_RX_SOFTIRQ,
    BLOCK_SOFTIRQ,
    BLOCK_IOPOLL_SOFTIRQ,
    TASKLET_SOFTIRQ,
    SCHED_SOFTIRQ,
    HRTIMER_SOFTIRQ,
    RCU_SOFTIRQ,    /* Preferable RCU should always be the last softirq */

    NR_SOFTIRQS
};
</code></pre>

<pre><code>HI_SOFTIRQ用于高优先级的tasklet，TASKLET_SOFTIRQ用于普通的tasklet。TIMER_SOFTIRQ是for software timer的（所谓software timer就是说该timer是基于系统tick的）。NET_TX_SOFTIRQ和NET_RX_SOFTIRQ是用于网卡数据收发的。BLOCK_SOFTIRQ和BLOCK_IOPOLL_SOFTIRQ是用于block device的。SCHED_SOFTIRQ用于多CPU之间的负载均衡的。HRTIMER_SOFTIRQ用于高精度timer的。RCU_SOFTIRQ是处理RCU的。这些具体使用情景分析会在各自的子系统中分析，本文只是描述softirq的工作原理。

#### 2、softirq描述符

我们前面已经说了，softirq是静态定义的，也就是说系统中有一个定义softirq描述符的数组，而softirq number就是这个数组的index。这个概念和早期的静态分配的中断描述符概念是类似的。具体定义如下：
</code></pre>

<pre><code>struct softirq_action
{
    void    (*action)(struct softirq_action *);
};

static struct softirq_action softirq_vec[NR_SOFTIRQS] __cacheline_aligned_in_smp;
</code></pre>

<pre><code>系统支持多少个软中断，静态定义的数组就会有多少个entry。`____cacheline_aligned`保证了在SMP的情况下，softirq_vec是对齐到cache line的。softirq描述符非常简单，只有一个action成员，表示如果触发了该softirq，那么应该调用action回调函数来处理这个soft irq。对于硬件中断而言，其mask、ack等都是和硬件寄存器相关并封装在irq chip函数中，对于softirq，没有硬件寄存器，只有“软件寄存器”，定义如下：
</code></pre>

<pre><code>typedef struct {
    unsigned int __softirq_pending;
#ifdef CONFIG_SMP
    unsigned int ipi_irqs[NR_IPI];
#endif
} ____cacheline_aligned irq_cpustat_t;

irq_cpustat_t irq_stat[NR_CPUS] ____cacheline_aligned;
</code></pre>

<pre><code>ipi_irqs这个成员用于处理器之间的中断，我们留到下一个专题来描述。`__softirq_pending`就是这个“软件寄存器”。softirq采用谁触发，谁负责处理的。例如：当一个驱动的硬件中断被分发给了指定的CPU，并且在该中断handler中触发了一个softirq，那么该CPU负责调用该softirq number对应的action callback来处理该软中断。因此，这个“软件寄存器”应该是每个CPU拥有一个（专业术语叫做banked register）。为了性能，irq_stat中的每一个entry被定义对齐到cache line。

#### 3、如何注册一个softirq

通过调用open_softirq接口函数可以注册softirq的action callback函数，具体如下：
</code></pre>

<pre><code>void open_softirq(int nr, void (*action)(struct softirq_action *))
{
    softirq_vec[nr].action = action;
}
</code></pre>

<pre><code>softirq_vec是一个多CPU之间共享的数据，不过，由于所有的注册都是在系统初始化的时候完成的，那时候，系统是串行执行的。此外，softirq是静态定义的，每个entry（或者说每个softirq number）都是固定分配的，因此，不需要保护。

#### 4、如何触发softirq？

在linux kernel中，可以调用raise_softirq这个接口函数来触发本地CPU上的softirq，具体如下：
</code></pre>

<pre><code>void raise_softirq(unsigned int nr)
{
    unsigned long flags;

    local_irq_save(flags);
    raise_softirq_irqoff(nr);
    local_irq_restore(flags);
}
</code></pre>

<pre><code>虽然大部分的使用场景都是在中断handler中（也就是说关闭本地CPU中断）来执行softirq的触发动作，但是，这不是全部，在其他的上下文中也可以调用raise_softirq。因此，触发softirq的接口函数有两个版本，一个是raise_softirq，有关中断的保护，另外一个是raise_softirq_irqoff，调用者已经关闭了中断，不需要关中断来保护“soft irq status register”。

所谓trigger softirq，就是在`__softirq_pending`（也就是上面说的soft irq status register）的某个bit置一。从上面的定义可知，`__softirq_pending`是per cpu的，因此不需要考虑多个CPU的并发，只要disable本地中断，就可以确保对，`__softirq_pending`操作的原子性。

具体raise_softirq_irqoff的代码如下：
</code></pre>

<pre><code>inline void raise_softirq_irqoff(unsigned int nr)
{
    __raise_softirq_irqoff(nr); ---------- （1）

    if (!in_interrupt())
        wakeup_softirqd();      ---------- （2）
}
</code></pre>

<pre><code>（1）`__raise_softirq_irqoff`函数设定本CPU上的`__softirq_pending`的某个bit等于1，具体的bit是由soft irq number（nr参数）指定的。

（2）如果在中断上下文，我们只要set `__softirq_pending`的某个bit就OK了，在中断返回的时候自然会进行软中断的处理。但是，如果在context上下文调用这个函数的时候，我们必须要调用wakeup_softirqd函数用来唤醒本CPU上的softirqd这个内核线程。具体softirqd的内容请参考下一个章节。

#### 5、disable/enable softirq

在linux kernel中，可以使用local_irq_disable和local_irq_enable来disable和enable本CPU中断。和硬件中断一样，软中断也可以disable，接口函数是local_bh_disable和local_bh_enable。虽然和想像的local_softirq_enable/disable有些出入，不过bh这个名字更准确反应了该接口函数的意涵，因为local_bh_disable/enable函数就是用来disable/enable bottom half的，这里就包括softirq和tasklet。

先看disable吧，毕竟禁止bottom half比较简单：
</code></pre>

<pre><code>static inline void local_bh_disable(void)
{
    __local_bh_disable_ip(_THIS_IP_, SOFTIRQ_DISABLE_OFFSET);
}

static __always_inline void __local_bh_disable_ip(unsigned long ip, unsigned int cnt)
{
    preempt_count_add(cnt);
    barrier();
}
</code></pre>

<pre><code>看起来disable bottom half比较简单，就是讲current thread info上的preempt_count成员中的softirq count的bit field9～15加上一就OK了。barrier是优化屏障（Optimization barrier），会在内核同步系列文章中描述。

enable函数比较复杂，如下：
</code></pre>

<pre><code>static inline void local_bh_enable(void)
{
    __local_bh_enable_ip(_THIS_IP_, SOFTIRQ_DISABLE_OFFSET);
}

void __local_bh_enable_ip(unsigned long ip, unsigned int cnt)
{
    WARN_ON_ONCE(in_irq() || irqs_disabled()); --------- （1）

    preempt_count_sub(cnt - 1);                --------- （2）

    if (unlikely(!in_interrupt() &amp;&amp; local_softirq_pending())) {  ------- （3）
        do_softirq();
    }

    preempt_count_dec();                       --------- （4）
    preempt_check_resched();
}
</code></pre>

<pre><code>（1）disable/enable bottom half是一种内核同步机制。在硬件中断的handler（top half）中，不应该调用disable/enable bottom half函数来保护共享数据，因为bottom half其实是不可能抢占top half的。同样的，soft irq也不会抢占另外一个soft irq的执行，也就是说，一旦一个softirq handler被调度执行（无论在哪一个processor上），那么，本地的softirq handler都无法抢占其运行，要等到当前的softirq handler运行完毕后，才能执行下一个soft irq handler。注意：上面我们说的是本地，是local，softirq handler是可以在多个CPU上同时运行的，但是，linux kernel中没有disable all softirq的接口函数（就好像没有disable all CPU interrupt的接口一样，注意体会local_bh_enable/disable中的local的含义）。

说了这么多，一言以蔽之，local_bh_enable/disable是给进程上下文使用的，用于防止softirq handler抢占local_bh_enable/disable之间的临界区的。

irqs_disabled接口函数可以获知当前本地CPU中断是否是disable的，如果返回1，那么当前是disable 本地CPU的中断的。如果irqs_disabled返回1，有可能是下面这样的代码造成的：
</code></pre>

<pre><code>local_irq_disable();
......
local_bh_disable();

......

local_bh_enable();
......
local_irq_enable();
</code></pre>

<pre><code>本质上，关本地中断是一种比关本地bottom half更强劲的锁，关本地中断实际上是禁止了top half和bottom half抢占当前进程上下文的运行。也许你会说：这也没有什么，就是有些浪费，至少代码逻辑没有问题。但事情没有这么简单，在`local_bh_enable---&gt;do_softirq---&gt;__do_softirq`中，有一条无条件打开当前中断的操作，也就是说，原本想通过local_irq_disable/local_irq_enable保护的临界区被破坏了，其他的中断handler可以插入执行，从而无法保证local_irq_disable/local_irq_enable保护的临界区的原子性，从而破坏了代码逻辑。

in_irq()这个函数如果不等于0的话，说明local_bh_enable被irq_enter和irq_exit包围，也就是说在中断handler中调用了local_bh_enable/disable。这道理是和上面类似的，这里就不再详细描述了。

（2）在local_bh_disable中我们为preempt_count增加了SOFTIRQ_DISABLE_OFFSET，在local_bh_enable函数中应该减掉同样的数值。这一步，我们首先减去了（SOFTIRQ_DISABLE_OFFSET-1），为何不一次性的减去SOFTIRQ_DISABLE_OFFSET呢？考虑下面运行在进程上下文的代码场景：
</code></pre>

<pre><code>......

local_bh_disable

...需要被保护的临界区...

local_bh_enable
......
</code></pre>

<pre><code>在临界区内，有进程context 和softirq共享的数据，因此，在进程上下文中使用local_bh_enable/disable进行保护。假设在临界区代码执行的时候，发生了中断，由于代码并没有阻止top half的抢占，因此中断handler会抢占当前正在执行的thread。在中断handler中，我们raise了softirq，在返回中断现场的时候，由于disable了bottom half，因此虽然触发了softirq，但是不会调度执行。因此，代码返回临界区继续执行，直到local_bh_enable。一旦enable了bottom half，那么之前raise的softirq就需要调度执行了，因此，这也是为什么在local_bh_enable会调用do_softirq函数。

调用do_softirq函数来处理pending的softirq的时候，当前的task是不能被抢占的，因为一旦被抢占，下一次该task被调度运行的时候很可能在其他的CPU上去了（还记得吗？softirq的pending 寄存器是per cpu的）。因此，我们不能一次性的全部减掉，那样的话有可能preempt_count等于0，那样就允许抢占了。因此，这里减去了（SOFTIRQ_DISABLE_OFFSET-1），既保证了softirq count的bit field9~15被减去了1，又保持了preempt disable的状态。

（3）如果当前不是interrupt context的话，并且有pending的softirq，那么调用do_softirq函数来处理软中断。

（4）该来的总会来，在step 2中我们少减了1，这里补上，其实也就是preempt count-1。

（5）在softirq handler中很可能wakeup了高优先级的任务，这里最好要检查一下，看看是否需要进行调度，确保高优先级的任务得以调度执行。


#### 5、如何处理一个被触发的soft irq

我们说softirq是一种defering task的机制，也就是说top half没有做的事情，需要延迟到bottom half中来执行。那么具体延迟到什么时候呢？这是本节需要讲述的内容，也就是说soft irq是如何调度执行的。

在上一节已经描述一个softirq被调度执行的场景，本节主要关注在中断返回现场时候调度softirq的场景。我们来看中断退出的代码，具体如下：
</code></pre>

<pre><code>void irq_exit(void)
{
    ......
    if (!in_interrupt() &amp;&amp; local_softirq_pending())
        invoke_softirq();

    ......
}
</code></pre>

<pre><code>代码中“!in_interrupt()”这个条件可以确保下面的场景不会触发sotfirq的调度：

（1）中断handler是嵌套的。也就是说本次irq_exit是退出到上一个中断handler。当然，在新的内核中，这种情况一般不会发生，因为中断handler都是关中断执行的。

（2）本次中断是中断了softirq handler的执行。也就是说本次irq_exit是不是退出到进程上下文，而是退出到上一个softirq context。这一点也保证了在一个CPU上的softirq是串行执行的（注意：多个CPU上还是有可能并发的）

我们继续看invoke_softirq的代码：
</code></pre>

<pre><code>static inline void invoke_softirq(void)
{
    if (!force_irqthreads) {
#ifdef CONFIG_HAVE_IRQ_EXIT_ON_IRQ_STACK
        __do_softirq();
#else
        do_softirq_own_stack();
#endif
    } else {
        wakeup_softirqd();
    }
}
</code></pre>

<pre><code>force_irqthreads是和强制线程化相关的，主要用于interrupt handler的调试（一般而言，在线程环境下比在中断上下文中更容易收集调试数据）。如果系统选择了对所有的interrupt handler进行线程化处理，那么softirq也没有理由在中断上下文中处理（中断handler都在线程中执行了，softirq怎么可能在中断上下文中执行）。本身invoke_softirq这个函数是在中断上下文中被调用的，如果强制线程化，那么系统中所有的软中断都在sofirq的daemon进程中被调度执行。

如果没有强制线程化，softirq的处理也分成两种情况，主要是和softirq执行的时候使用的stack相关。如果arch支持单独的IRQ STACK，这时候，由于要退出中断，因此irq stack已经接近全空了（不考虑中断栈嵌套的情况，因此新内核下，中断不会嵌套），因此直接调用`__do_softirq()`处理软中断就OK了，否则就调用do_softirq_own_stack函数在softirq自己的stack上执行。当然对ARM而言，softirq的处理就是在当前的内核栈上执行的，因此do_softirq_own_stack的调用就是调用`__do_softirq()`，代码如下（删除了部分无关代码）：
</code></pre>

<pre><code>asmlinkage void __do_softirq(void)
{
......
    pending = local_softirq_pending();  ----------- 获取softirq pending的状态
    __local_bh_disable_ip(_RET_IP_, SOFTIRQ_OFFSET); ---- 标识下面的代码是正在处理softirq
    cpu = smp_processor_id();
restart:
    set_softirq_pending(0);  ------------- 清除pending标志
    local_irq_enable();      ------------- 打开中断，softirq handler是开中断执行的
    h = softirq_vec;         ------------- 获取软中断描述符指针

    while ((softirq_bit = ffs(pending))) { --------- 寻找pending中第一个被设定为1的bit
        unsigned int vec_nr;
        int prev_count;

        h += softirq_bit - 1; ----------- 指向pending的那个软中断描述符
        vec_nr = h - softirq_vec; ------- 获取soft irq number
        h-&gt;action(h);         ----------- 指向softirq handler
        h++;
        pending &gt;&gt;= softirq_bit;
    }

    local_irq_disable();      ----------- 打开中断

    pending = local_softirq_pending(); ------ （注1）
    if (pending) {
        if (time_before(jiffies, end) &amp;&amp; !need_resched() &amp;&amp;
            --max_restart)
            goto restart;

        wakeup_softirqd();
    }
    __local_bh_enable(SOFTIRQ_OFFSET); ----------- 标识softirq处理完毕
}
</code></pre>

<p>```
（注1）再次检查softirq pending，有可能上面的softirq handler在执行过程中，发生了中断，又raise了softirq。如果的确如此，那么我们需要跳转到restart那里重新处理soft irq。当然，也不能总是在这里不断的loop，因此linux kernel设定了下面的条件：</p>

<p>（1）softirq的处理时间没有超过2个ms</p>

<p>（2）上次的softirq中没有设定TIF_NEED_RESCHED，也就是说没有有高优先级任务需要调度</p>

<p>（3）loop的次数小于 10次</p>

<p>因此，只有同时满足上面三个条件，程序才会跳转到restart那里重新处理soft irq。否则wakeup_softirqd就OK了。这样的设计也是一个平衡的方案。一方面照顾了调度延迟：本来，发生一个中断，系统期望在限定的时间内调度某个进程来处理这个中断，如果softirq handler不断触发，其实linux kernel是无法保证调度延迟时间的。另外一方面，也照顾了硬件的thoughput：已经预留了一定的时间来处理softirq。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[内核源码分析之linux内核栈]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/05/07/kernel-irq-stack2/"/>
    <updated>2015-05-07T15:54:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/05/07/kernel-irq-stack2</id>
    <content type="html"><![CDATA[<p><a href="http://www.cnblogs.com/liangning/p/3879177.html">http://www.cnblogs.com/liangning/p/3879177.html</a></p>

<p>基于3.16-rc4</p>

<p>在3.16-rc4内核源码中，内核给每个进程分配的内核栈大小为8KB。这个内核栈被称为异常栈，在进程的内核空间运行时或者执行异常处理程序时，使用的都是异常栈，看下异常栈的代码（include/linux/sched.h）：
<code>
    union thread_union {
        struct thread_info thread_info;
        unsigned long stack[THREAD_SIZE/sizeof(long)];
    };
</code>
THREAD_SIZE值为8KB，因此内核为进程的异常栈（内核栈）分配了两个页框大小（页框大小4KB）。另外，进程的thread_info结构体保存在栈顶部。</p>

<p>此外，内核为每个cpu分配一个硬中断栈和一个软中断栈（这两个栈也是内核栈），用来执行中断服务例程和下半部（软中断），看看代码（arch/x86/kernel/irq_32.c）。这两个栈属于cpu，不属于进程，这和异常栈是有区别的。
<code>
    DEFINE_PER_CPU(struct irq_stack *, hardirq_stack);
    DEFINE_PER_CPU(struct irq_stack *, softirq_stack);
</code>
定义了两个数组hardirq_stack和softirq_stack，每个数组元素对应一个cpu，指向了该cpu的硬中断栈或者软中断栈。再来看下struct irq_stack结构体（arch/x86/include/asm/processor.h）：
<code>
    struct irq_stack {
        u32                     stack[THREAD_SIZE/sizeof(u32)];
    } __aligned(THREAD_SIZE);
</code>
可见，硬中断栈和软中断栈的大小均为8KB。</p>

<p>内核在执行中断处理程序时，在do_IRQ函数中会调用handle_irq函数，在handle_irq函数中要进行堆栈切换，代码如下（arch/x86/kernel/irq_32.c）：
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>bool handle_irq(unsigned irq, struct pt_regs &lt;em&gt;regs)
</span><span class='line'>{
</span><span class='line'>    struct irq_desc &lt;/em&gt;desc;
</span><span class='line'>    int overflow;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    overflow = check_stack_overflow();
</span><span class='line'>
</span><span class='line'>desc = irq_to_desc(irq);
</span><span class='line'>if (unlikely(!desc))
</span><span class='line'>return false;
</span><span class='line'>
</span><span class='line'>if (user_mode_vm(regs) || !execute_on_irq_stack(overflow, desc, irq)) {
</span><span class='line'>    if (unlikely(overflow))
</span><span class='line'>        print_stack_overflow();
</span><span class='line'>    desc-&gt;handle_irq(irq, desc);
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>return true;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>第12行中执行execute_on_irq_stack函数来判断是否需要堆栈切换，如果不需要，则执行if体的中断服务例程，即在当前堆栈中执行中断服务例程，如果需要切换堆栈，则在execute_on_irq_stack函数中切换堆栈并在该函数中（新堆栈中）执行中断服务例程。下面看下execute_on_irq_stack代码（arch/x86/kernel/irq_32.c）：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;static inline int
</span><span class='line'>execute_on_irq_stack(int overflow, struct irq_desc *desc, int irq)
</span><span class='line'>{
</span><span class='line'>struct irq_stack *curstk, *irqstk;
</span><span class='line'>u32 *isp, *prev_esp, arg1, arg2;
</span><span class='line'>
</span><span class='line'>curstk = (struct irq_stack *) current_stack();
</span><span class='line'>irqstk = __this_cpu_read(hardirq_stack);
</span><span class='line'>
</span><span class='line'>/*
</span><span class='line'> * this is where we switch to the IRQ stack. However, if we are
</span><span class='line'> * already using the IRQ stack (because we interrupted a hardirq
</span><span class='line'> * handler) we can't do that and just have to keep using the
</span><span class='line'> * current stack (which is the irq stack already after all)
</span><span class='line'> */
</span><span class='line'>if (unlikely(curstk == irqstk))
</span><span class='line'>    return 0;
</span><span class='line'>
</span><span class='line'>isp = (u32 *) ((char *)irqstk + sizeof(*irqstk));
</span><span class='line'>
</span><span class='line'>/* Save the next esp at the bottom of the stack */
</span><span class='line'>prev_esp = (u32 *)irqstk;
</span><span class='line'>*prev_esp = current_stack_pointer;
</span><span class='line'>
</span><span class='line'>if (unlikely(overflow))
</span><span class='line'>    call_on_stack(print_stack_overflow, isp);
</span><span class='line'>
</span><span class='line'>asm volatile("xchgl    %%ebx,%%esp    \n"
</span><span class='line'>         "call    *%%edi        \n"
</span><span class='line'>         "movl    %%ebx,%%esp    \n"
</span><span class='line'>         : "=a" (arg1), "=d" (arg2), "=b" (isp)
</span><span class='line'>         :  "0" (irq),   "1" (desc),  "2" (isp),
</span><span class='line'>        "D" (desc-&gt;handle_irq)
</span><span class='line'>         : "memory", "cc", "ecx");
</span><span class='line'>return 1;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;```&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;第7行获取当前堆栈的指针，第8行获取本地cpu的硬中断栈指针，第16行对二者进行比较，如果相等，则不需要切换堆栈（说明当前堆栈就是硬中断栈，也说明是在中断处理程序中时又发生了中断）。如果不相等，就要进行堆栈切换，第22-23行将当前堆栈指针保存在将要切换到的堆栈中（用于返回）。第28行，交换ebx和esp寄存器的值（实现了堆栈切换，将中断栈指针给了esp），第29行跳转到相应的中断服务例程，第30行从中断服务例程返回后，又将原来的堆栈指针赋给esp，切换到原先堆栈。第33行将中断服务例程函数名存放在%edi中。&lt;/p&gt;
</span><span class='line'>]]&gt;&lt;/content&gt;
</span><span class='line'>  &lt;/entry&gt;
</span><span class='line'>  
</span><span class='line'>  &lt;entry&gt;
</span><span class='line'>&lt;title type="html"&gt;&lt;![CDATA[中断栈溢出后的结果]]&gt;&lt;/title&gt;
</span><span class='line'>&lt;link href="http://abcdxyzk.github.io/blog/2015/05/07/kernel-irq-stack/"/&gt;
</span><span class='line'>&lt;updated&gt;2015-05-07T15:54:00+08:00&lt;/updated&gt;
</span><span class='line'>&lt;id&gt;http://abcdxyzk.github.io/blog/2015/05/07/kernel-irq-stack&lt;/id&gt;
</span><span class='line'>&lt;content type="html"&gt;&lt;![CDATA[&lt;p&gt;&lt;a href="http://www.lenky.info/archives/2013/03/2247"&gt;http://www.lenky.info/archives/2013/03/2247&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;说一下上文中最开始提到的“某个问题”：如果一台主机网卡比较多，然后每个网卡分队列又比较多，总之结果就是系统里的网卡设备的中断号比较多（关于超过256个中断数的情况，请见参考1，2，3），一旦所有这些中断都绑定到同一个CPU，那么如果网卡收到数据包进而触发中断，而众多硬中断一嵌套就非常容易出现中断栈溢出。一旦中断栈溢出，那么将会导致怎样的结果，这曾在之前的文章里隐含的提到过，这里再重新整理一遍。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;在继续下面的描述之前，先看两个知识点：&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h5&gt;1，Linux 2.4.x的中断栈：&lt;/h5&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;a)，由硬中断/软中断共同使用同一个中断栈&lt;br/&gt;
</span><span class='line'>b)，中断栈与内核栈共享一个栈&lt;br/&gt;
</span><span class='line'>c)，中断执行的时候使用的栈就是当前进程的内核栈&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h5&gt;2，Linux 2.6.x的中断栈：&lt;/h5&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;a)，硬中断与软中断分离使用不同的中断栈&lt;br/&gt;
</span><span class='line'>b)，中断栈与内核栈分离&lt;br/&gt;
</span><span class='line'>c)，X86_64 double fault、NMI还可以有额外的栈（64bit特性：IST(Interrupt Stack Table)）&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;可以看到，对于Linux 2.4.x内核而言，因为中断处理函数使用内核栈作为中断栈，所以导致更加容易发生内核栈溢出（因内核函数本身用栈过多导致溢出，或内核函数本身还未导致内核栈溢出，但此时来了一个中断，因中断函数使用栈而导致溢出，即中断函数成了压死骆驼的最后一根稻草），而内核栈溢出的直接结果就是踩坏task结构体，从而无法正常执行对应的task进程而出现oops宕机。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;由于“中断执行的时候使用的栈就是当前进程的内核栈”，所以如果是执行到中断函数后才溢出，那么导致oops里提示的进程信息可能每次都不一样，因此如果出现这种情况，需要考虑是中断函数导致内核栈溢出，否则需怀疑普通的内核函数导致栈溢出即可。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;对于Linux 2.6.x内核而言，因为其中断/内核栈分离、软/硬中断栈分离，即每个CPU私有两个栈（见下面注释）分别处理软中断和硬中断，因此出现内核栈溢出，特别是中断栈溢出的概率大大降低。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;注释：这个说法来之书本《Understanding.the.Linux.Kernel.3rd.Edition》4.6.1.4. Multiple Kernel Mode stacks，而这本书针对的内核版本是2.6.11，且主要是指32位架构，所以与现在的新版内核源码有些许出入（比如现在情况的栈大小可能是占用2页），但这些细微改变与本文的具体问题相关不大（无非是溢出的难易程度问题），这里不再深入研究，具体情况请参考源代码自行斟酌。</span></code></pre></td></tr></table></div></figure>
    The hard IRQ stack is used when handling interrupts. There is one hard IRQ stack for each CPU in the system, and each stack is contained in a single page frame.</p>

<pre><code>The soft IRQ stack is used when handling deferrable functions (softirqs or tasklets; see the later section “Softirqs and Tasklets”). There is one soft IRQ stack for each CPU in the system, and each stack is contained in a single page frame. 
</code></pre>

<pre><code>回到本文的主题，在之前的文章里提到过，即如果中断/异常处理函数本身在处理的过程中出现异常，那么就有可能发生double fault，比如中断栈溢出。中断栈溢出导致的最终结果有两种情况，这由所使用的具体Linux内核版本来决定，更具体点说是由double fault异常的栈是否单独来决定（见参考1）。

1，double fault的栈被单独出来  
这意味着double fault的处理函数还能正常执行，因此打印oops，宕机。

2，double fault的栈没有被单独出来  
这意味着double fault的处理函数也无法正常执行，进而触发triple fault，机器直接重启。

对于86-64架构下的Linux 2.6.x内核，因为IST(Interrupt Stack Table)的帮助，所以中断栈溢出导致的最终结果就是打印oops，宕机。

下面来看内核源码文档kernel-stacks，  
1，每一个活动线程都有一个内核栈，大小为2页。  
2，每一个cpu有一些专门的栈，只有当cpu执行在内核态时，这些栈才有用；一旦cpu回退到用户态，这些特定栈就不再包含任何有用数据。  
3，主要的特定栈有：  
a，中断栈：外部硬件中断的处理函数使用，单独的栈可以提供给中断处理函数更多的栈空间。  
这里还提到，在2.6.x-i386下，如果设置内核栈只有4K，即CONFIG_4KSTACKS，那么中断栈也是单独开的。备注：这个已有修改，2010-06-29 x86: Always use irq stacks，即不管设置的内核栈是否只有4K，中断栈都是独立的了。  

另外，这里有个说法与前面的引用有点出入：
</code></pre>

<pre><code>The interrupt stack is also used when processing a softirq. 
</code></pre>

<p>```
即软中断和硬中断一样，也是使用这个中断栈。</p>

<p>b，x86_64所特有的（也就是i386没有，即同时2.6.30.8内核，32位的Linux就不具备下面所说的这个特性），为double fault或NMI单独准备的栈，这个特性被称为Interrupt Stack Table(IST)。每个cpu最多支持7个IST。关于IST的具体原理与实现暂且不说，直接来看当前已经分配的IST独立栈：</p>

<ul>
<li><p>STACKFAULT_STACK. EXCEPTION_STKSZ (PAGE_SIZE)<br/>
12号中断Stack Fault Exception (#SS)使用</p></li>
<li><p>DOUBLEFAULT_STACK. EXCEPTION_STKSZ (PAGE_SIZE)<br/>
8号中断Double Fault Exception (#DF)使用</p></li>
<li><p>NMI_STACK. EXCEPTION_STKSZ (PAGE_SIZE)<br/>
2号中断non-maskable interrupts (NMI)使用</p></li>
<li><p>DEBUG_STACK. DEBUG_STKSZ<br/>
1号中断硬件调试和3号中断软件调试使用</p></li>
<li><p>MCE_STACK. EXCEPTION_STKSZ (PAGE_SIZE)<br/>
18号中断Machine Check Exception (#MC)使用</p></li>
</ul>


<p>正因为double fault异常处理函数所使用的栈被单独了出来，所以在出现中断栈溢出时，double fault异常的处理函数还能正常执行，顺利打印出oops信息。</p>

<p>最后的最后，有补丁移除IST功能（貌似是因为如果没有IST功能，那么kvm可以得到更好的优化，具体请见参考5），但通过对比补丁修改与实际源码（2.6.30.8以及3.6.11）来看，这个补丁并没有合入mainline主线。</p>

<h4>参考资料：</h4>

<p>1，where is hardware timer interrupt?<br/>
<a href="http://stackoverflow.com/questions/14481032/where-is-hardware-timer-interrupt">http://stackoverflow.com/questions/14481032/where-is-hardware-timer-interrupt</a></p>

<p>2，The MSI Driver Guide HOWTO<br/>
<a href="https://git.kernel.org/cgit/linux/kernel/git/stable/linux-stable.git/tree/Documentation/PCI/MSI-HOWTO.txt?id=v2.6.30.8  ">https://git.kernel.org/cgit/linux/kernel/git/stable/linux-stable.git/tree/Documentation/PCI/MSI-HOWTO.txt?id=v2.6.30.8  </a>
对应的翻译版：<a href="http://blog.csdn.net/reviver/article/details/6802347">http://blog.csdn.net/reviver/article/details/6802347</a></p>

<p>3，[PATCH] x86: 64bit support more than 256 irq v2<br/>
<a href="http://linux-kernel.2935.n7.nabble.com/PATCH-x86-64bit-support-more-than-256-irq-v2-td323261.html">http://linux-kernel.2935.n7.nabble.com/PATCH-x86-64bit-support-more-than-256-irq-v2-td323261.html</a></p>

<p>4，How is an Interrupt handled in Linux?<br/>
<a href="http://unix.stackexchange.com/questions/5788/how-is-an-interrupt-handled-in-linux">http://unix.stackexchange.com/questions/5788/how-is-an-interrupt-handled-in-linux</a></p>

<p>5，Remove interrupt stack table usage from x86_64 kernel (v2)<br/>
<a href="http://lwn.net/Articles/313029/  ">http://lwn.net/Articles/313029/  </a>
<a href="http://thread.gmane.org/gmane.comp.emulators.kvm.devel/26741">http://thread.gmane.org/gmane.comp.emulators.kvm.devel/26741</a></p>

<p>6，Interrupt Descriptor Table<br/>
<a href="http://wiki.osdev.org/IDT">http://wiki.osdev.org/IDT</a></p>

<p>转载请保留地址：<a href="http://www.lenky.info/archives/2013/03/2247">http://www.lenky.info/archives/2013/03/2247</a> 或 <a href="http://lenky.info/?p=2247">http://lenky.info/?p=2247</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[对Linux x86-64架构上硬中断的重新认识]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/05/07/kernel-irq-irq/"/>
    <updated>2015-05-07T15:48:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/05/07/kernel-irq-irq</id>
    <content type="html"><![CDATA[<p><a href="http://www.lenky.info/archives/2013/03/2245">http://www.lenky.info/archives/2013/03/2245</a></p>

<p>对于x86硬中断的概念，一直都落在理论的认识之上，直到这两天才（因某个问题）发现Linux的实现却并非如此，这里纠正一下（注意：Linux内核源码更新太快，一个说法的时效性太短，所以需注意我提到的香草内核版本，并且以x86-64架构为基准）。</p>

<p>以前的认识：Linux对硬中断（本文如无特殊说明，都是指普通意义上的可屏蔽硬件中断）的处理有优先级概念，高优先级硬中断可以打断低优先级硬中断。</p>

<h4>重新认识：</h4>

<p>1，对于x86硬件而言，在文档325462.pdf卷3章节6.9 PRIORITY AMONG SIMULTANEOUS EXCEPTIONS AND INTERRUPTS 提到一个表格，是指如果在同一时刻有多个异常或中断到达，那么CPU会按照一个指定的优先级顺序对它们进行响应和服务，而并不是我之前所想的判断是否可相互打断执行的高低级别。</p>

<p>2，对于Linux系统而言，硬中断之间并没有优先级的概念（虽然Intel CPU提供支持，请参考文档325462.pdf卷3章节10.8.3 Interrupt, Task, and Processor Priority），或者说优先级只有两个，全部关闭或全部开启，如下：</p>

<blockquote><blockquote><p>Regardless of what the hardware might support, typical UNIX-type systems only make use of two levels: the minimum (all interrupts enabled) and the maximum (all interrupts disabled).</p></blockquote></blockquote>

<p>这意味着，如果一个硬中断处理函数正在执行，只要当前是处于开启中断的情况，那么此时发生的任何另外一个中断都可以打断当前处理函数，从而出现中断嵌套的情况。
值得注意的是，Linux提供对单个中断开启/禁止的接口（以软件实现为主，比如给对应中断描述符desc的status打上IRQ_DISABLED旗标）：
<code>
    void disable_irq(unsigned int irq)
    void enable_irq(unsigned int irq)
</code>
下面来看看Linux的实际处理，其硬中断的一般处理流程（具体可见参考1、2、3以及源代码，以2.6.30.8为例）：
<code>
硬件中断 -&gt; common_interrupt -&gt; do_IRQ -&gt; handle_irq -&gt; generic_handle_irq_desc -&gt; desc-&gt;handle_irq或__do_IRQ。
</code></p>

<p>其中desc->handle_irq是一个回调函数，会根据不同中断类型（I/O APIC、MSI）有不同的指向，比如：handle_fasteoi_irq()、handle_edge_irq()，这可以参考设置函数ioapic_register_intr()和setup_msi_irq()。通过/proc/interrupts可以看到各个中断的具体类型：
<code>
    [root@localhost ~]# cat /proc/interrupts
               CPU0       CPU1      
      0:        888          0   IO-APIC-edge      timer
      1:         96        112   IO-APIC-edge      i8042
      3:          1          0   IO-APIC-edge   
      4:          1          0   IO-APIC-edge   
      7:          0          0   IO-APIC-edge      parport0
      8:          1          0   IO-APIC-edge      rtc0
      9:          0          0   IO-APIC-fasteoi   acpi
     12:        204          0   IO-APIC-edge      i8042
     14:          0          0   IO-APIC-edge      ata_piix
     15:     460641        900   IO-APIC-edge      ata_piix
     16:          0          0   IO-APIC-fasteoi   Ensoniq AudioPCI
     17:     118347          0   IO-APIC-fasteoi   ehci_hcd:usb1, ioc0
     18:         70          0   IO-APIC-fasteoi   uhci_hcd:usb2
     19:     115143          0   IO-APIC-fasteoi   eth0
     24:          0          0   PCI-MSI-edge      pciehp
     25:          0          0   PCI-MSI-edge      pciehp
     26:          0          0   PCI-MSI-edge      pciehp
     27:          0          0   PCI-MSI-edge      pciehp
     28:          0          0   PCI-MSI-edge      pciehp
    ...
</code>
不管是desc->handle_irq还是__do_IRQ，它们都会调入到另外一个函数handle_IRQ_event()。重点：从CPU接收到中断信号并开始处理，到这个函数为止，都是处于中断禁止状态。为什么？很简单，因为Intel开发者手册上是这么说的，在文档325462.pdf卷3章节6.8.1 Masking Maskable Hardware Interrupts提到：
<code>
    When an interrupt is handled through an interrupt gate, the IF flag is automati-
    cally cleared, which disables maskable hardware interrupts. (If an interrupt is
    handled through a trap gate, the IF flag is not cleared.)
</code>
在CPU开始处理一个硬中断到进入函数handle_IRQ_event()为止的这段时间里，因为处于中断禁止状态，所以不会出现被其它中断打断的情况。但是，在进入到函数handle_IRQ_event()后，立马有了这么两句：
```
    irqreturn_t handle_IRQ_event(unsigned int irq, struct irqaction *action)
    {
        irqreturn_t ret, retval = IRQ_NONE;
        unsigned int status = 0;</p>

<pre><code>    if (!(action-&gt;flags &amp; IRQF_DISABLED))
        local_irq_enable_in_hardirq();
...
</code></pre>

<pre><code>函数local_irq_enable_in_hardirq()的定义如下：
</code></pre>

<pre><code>#ifdef CONFIG_LOCKDEP
# define local_irq_enable_in_hardirq()  do { } while (0)
#else
# define local_irq_enable_in_hardirq()  local_irq_enable()
#endif
</code></pre>

<pre><code>宏CONFIG_LOCKDEP用于表示当前是否开启内核Lockdep功能，这是一个调试功能，用于检测潜在的死锁类风险，如果开启，那么函数local_irq_enable_in_hardirq()为空，即继续保持中断禁止状态，为什么Lockdep功能需要保持中断禁止待后文再述，这里考虑一般情况，即不开启Lockdep功能，那么执行函数local_irq_enable_in_hardirq()就会开启中断。
看函数handle_IRQ_event()里的代码，如果没有带上IRQF_DISABLED旗标，那么就会执行函数local_irq_enable_in_hardirq()，从而启用中断。旗标IRQF_DISABLED可在利用函数request_irq()注册中断处理回调时设置，比如：
</code></pre>

<pre><code>if (request_irq(uart-&gt;port.irq, bfin_serial_rx_int, IRQF_DISABLED,
     "BFIN_UART_RX", uart)) {
</code></pre>

<pre><code>如果没有设置，那么到函数handle_IRQ_event()这里的代码后，因为中断已经开启，当前中断的后续处理就可能被其它中断打断，从而出现中断嵌套的情况。

3，如果新来的中断类型与当前正在执行的中断类型相同，那么会暂时挂起。主要实现代码在函数__do_IRQ()（handle_fasteoi_irq()、handle_edge_irq()类似）内：
</code></pre>

<pre><code>/*
 * If the IRQ is disabled for whatever reason, we cannot
 * use the action we have.
 */
action = NULL;
if (likely(!(status &amp; (IRQ_DISABLED | IRQ_INPROGRESS)))) {
    action = desc-&gt;action;
    status &amp;= ~IRQ_PENDING; /* we commit to handling */
    status |= IRQ_INPROGRESS; /* we are handling it */
}
desc-&gt;status = status;

/*
 * If there is no IRQ handler or it was disabled, exit early.
 * Since we set PENDING, if another processor is handling
 * a different instance of this same irq, the other processor
 * will take care of it.
 */
if (unlikely(!action))
    goto out;
</code></pre>

<pre><code>逻辑很简单，如果当前中断被禁止（IRQ_DISABLED）或正在执行（IRQ_INPROGRESS），那么goto cot，所以同种类型中断不会相互嵌套。

4，从这个补丁开始，Linux内核已经全面禁止硬中断嵌套了，即从2.6.35开始，默认就是：
</code></pre>

<pre><code>run the irq handlers with interrupts disabled.
</code></pre>

<pre><code>因为这个补丁，所以旗标IRQF_DISABLED没用了，mainline内核在逐步删除它。

我仔细检查了一下，对于2.6.34以及以前的内核，如果要合入这个补丁，那么有略微影响的主要是两个慢速驱动，分别为rtc-twl4030和twl4030-usb，需要按照类似开启Lockdep功能一样：
</code></pre>

<pre><code>#ifdef CONFIG_LOCKDEP
/* WORKAROUND for lockdep forcing IRQF_DISABLED on us, which
 * we don't want and can't tolerate.  Although it might be
 * friendlier not to borrow this thread context...
 */
local_irq_enable();
#endif
</code></pre>

<p>```
进行主动启用中断。还有另个一个慢速驱动IDE，其驱动中调用的是函数local_irq_enable_in_hardirq()，即它在开启Lockdep功能的情况下并没有明确要求启用中断，所以它应该不受补丁合入影响。嘛，我只是理论分析研究一下，仅供参考，如有风险，请实际操作者自行承担，:)。其它请看参考4，5，6。</p>

<h4>参考：</h4>

<p>1，Linux下386中断处理<br/>
2，Linux中断基础构架<br/>
3，linux源码entry_32.S中interrupt数组的分析<br/>
4，<a href="http://lwn.net/Articles/321663/  ">http://lwn.net/Articles/321663/  </a>
5，<a href="http://lwn.net/Articles/380931/  ">http://lwn.net/Articles/380931/  </a>
6，<a href="http://thread.gmane.org/gmane.linux.kernel/801267">http://thread.gmane.org/gmane.linux.kernel/801267</a></p>

<p>转载请保留地址：<a href="http://www.lenky.info/archives/2013/03/2245">http://www.lenky.info/archives/2013/03/2245</a> 或 <a href="http://lenky.info/?p=2245">http://lenky.info/?p=2245</a></p>
]]></content>
  </entry>
  
</feed>
