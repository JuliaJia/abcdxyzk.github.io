<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: kernel | kk Blog —— 通用基础]]></title>
  <link href="http://abcdxyzk.github.io/blog/cats/kernel/atom.xml" rel="self"/>
  <link href="http://abcdxyzk.github.io/"/>
  <updated>2015-02-09T16:44:07+08:00</updated>
  <id>http://abcdxyzk.github.io/</id>
  <author>
    <name><![CDATA[kk]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[NUMA技术相关笔记]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/02/09/kernel-mm-numa2/"/>
    <updated>2015-02-09T16:34:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/02/09/kernel-mm-numa2</id>
    <content type="html"><![CDATA[<p><a href="http://blog.csdn.net/jollyjumper/article/details/17168175">http://blog.csdn.net/jollyjumper/article/details/17168175</a></p>

<p>起源于在mongo启动脚本中看到<code>numactl --interleave=all mongod ...</code>。</p>

<p>  NUMA,非统一内存访问(Non-uniform Memory Access),介于SMP(对称多处理)和MPP(大规模并行处理)之间，各个节点自有内存(甚至IO子系统),访问其它节点的内存则通过高速网络通道。NUMA信息主要通过BIOS中的ACPI(高级配置和编程接口)进行配置,Linux对NUMA系统的物理内存分布信息从系统firmware的ACPi表中获得，最重要的是SRAT(System Resource Affinity Table)和SLIT(System locality Information Table)表。SRAT表包含CPU信息、内存相关性信息,SLIT表则记录了各个节点之间的距离，在系统中由数组node_distance[]记录。这样系统可以就近分配内存，减少延迟。</p>

<p>Linux中用一个struct pg_data_t表示一个numa节点，Linux内核支持numa调度,并实现CPU的负载均衡。</p>

<h5>查看是否支持:</h5>

<p>dmesg | grep -i numa</p>

<h5>要查看具体的numa信息用numastat</h5>

<pre><code>numastat
                           node0           node1
numa_hit             19983469427     20741805466
numa_miss             1981451471      2503049250
numa_foreign          2503049250      1981451471
interleave_hit         849781831       878579884
local_node           19627390917     20298995632
other_node            2337529981      2945859084
</code></pre>

<p>numa_hit是打算在该节点上分配内存，最后从这个节点分配的次数;<br/>
num_miss是打算在该节点分配内存，最后却从其他节点分配的次数;<br/>
num_foregin是打算在其他节点分配内存，最后却从这个节点分配的次数;<br/>
interleave_hit是采用interleave策略最后从该节点分配的次数;<br/>
local_node该节点上的进程在该节点上分配的次数<br/>
other_node是其他节点进程在该节点上分配的次数</p>

<h5>lscpu可以看到两个node的cpu归属:</h5>

<pre><code>lscpu
...
NUMA node0 CPU(s):     0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30
NUMA node1 CPU(s):     1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31
</code></pre>

<h5><code>numactl --hardware</code>命令</h5>

<p>会返回不同节点的内存总大小，可用大小,以及node distance等信息。</p>

<p>各个cpu负载情况，使用命令:mpstat -P ALL(需要安装sysstat)</p>

<p>Linux上使用numactl设定进程的numa策略。常见的情况是,数据库daemon进程(mongodb,mysql)可能会吃掉很多内存，而一个numa节点上的内存很有限，内存不够时虚拟内存频繁与硬盘交换数据，导致性能急剧下降(标识是irqbalance进程top中居高不下),这时应该采用interleave的numa策略，允许从其他节点分配内存。</p>

<p>各个内存的访问延迟如何?numactl man中的example提供了参考,我在公司的服务器上测了一下:</p>

<h5>写速度:</h5>

<pre><code>numactl --cpubind=0 --membind=0 dd if=/dev/zero of=/dev/shm/A bs=1M count=1024

1024+0 records in
1024+0 records out
1073741824 bytes (1.1 GB) copied, 0.546679 s, 2.0 GB/s

numactl --cpubind=0 --membind=1 dd if=/dev/zero of=/dev/shm/A bs=1M count=1024
1024+0 records in
1024+0 records out
1073741824 bytes (1.1 GB) copied, 0.612825 s, 1.8 GB/s
</code></pre>

<h5>读速度:</h5>

<p>测试从同一个节点读取:
<code>
numactl --cpubind=0 --membind=0 dd if=/dev/zero of=/dev/shm/A bs=1M count=1000
date +%s.%N
numactl --cpubind=0 --membind=0 cp /dev/shm/A /dev/null
date +%s.%N
rm /dev/shm/A
</code>
花费0.264556884765625秒,速度是3.779905410081901GB/s。</p>

<p>从另一个节点读取:
<code>
numactl --cpubind=0 --membind=0 dd if=/dev/zero of=/dev/shm/A bs=1M count=1000
date +%s.%N
numactl --cpubind=1 --membind=1 cp /dev/shm/A /dev/null
date +%s.%N
rm /dev/shm/A
</code>
花费0.3308408260345459秒,速度是3.022601569419312GB/s。</p>

<p>加速效果还是很明显的。</p>

<h4>参考:</h4>

<p><a href="http://www.ibm.com/developerworks/cn/linux/l-numa/  ">http://www.ibm.com/developerworks/cn/linux/l-numa/  </a>
<a href="http://www.dedecms.com/knowledge/data-base/nosql/2012/0820/8684.html">http://www.dedecms.com/knowledge/data-base/nosql/2012/0820/8684.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[玩转CPU Topology]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/02/09/kernel-mm-numa/"/>
    <updated>2015-02-09T16:19:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/02/09/kernel-mm-numa</id>
    <content type="html"><![CDATA[<p><a href="http://www.searchtb.com/2012/12/%E7%8E%A9%E8%BD%ACcpu-topology.html">http://www.searchtb.com/2012/12/%E7%8E%A9%E8%BD%ACcpu-topology.html</a></p>

<h4>先温习几个概念</h4>

<p>请原谅对部分术语笔者直接引用了wikipedia上的英文解释，因为哥实在做不到比wikipedia上更准确描述。我会试着解释部分的术语，并在本节的最后梳理一下这些术语之间的关系。注意，笔者对由于不准确的描述导致的性能下降，进程crash等任何问题不承担任何责任☺</p>

<p>NUMA：Non-Uniform Memory Access (NUMA) is a computer memory design used in multiprocessing, where the memory access time depends on the memory location relative to a processor. Under NUMA, a processor can access its own local memory faster than non-local memory, that is, memory local to another processor or memory shared between processors.NUMA architectures logically follow in scaling from symmetric multiprocessing (SMP) architectures.</p>

<p>提到NUMA就不能不对比SMP，</p>

<p>SMP：Symmetric multiprocessing (SMP) involves a multiprocessor computer hardware architecture where two or more identical processors are connected to a single shared main memory and are controlled by a single OS instance.</p>

<p>说了这么多其实都是为了介绍NUMA Node:</p>

<p>A fairly technically correct and also fairly ugly definition of a node is: a region of memory in which every byte has the same distance from each CPU.<br/>
A more common definition is: a block of memory and the CPUs, I/O, etc. physically on the same bus as the memory.</p>

<p>CPU：这个不解释，原因你懂得。想当年CPU拼的是频率，频率越高越NB，但是提升频率和制程密切相关。</p>

<p><img src="/images/kernel/2015-02-09-11.jpg" alt="" /></p>

<p>Intel cpu制程<br/>
但是制程这玩意有一个物理天花板，提升越来越难，有报道指出，现阶段普遍应用的硅晶体管在尺寸上有一个10nm的物理极限。为了提升性能cpu走上了多核的道路，即在一个封装（socket或者processor）里放多个core。这还不够，又发明了超线程技术Hyper-threading</p>

<p>HT：HT Technology is used to improve parallelization of computations (doing multiple tasks at once) performed on PC microprocessors. For each processor core that is physically present, the operating system addresses two virtual or logical cores, and shares the workload between them when possible. They appear to the OS as two processors, thus the OS can schedule two processes at once. 一个core 在HT之后OS看到的就是2个Logical Processor。</p>

<p>下图展示了这些术语之间的逻辑关系：</p>

<p><img src="/images/kernel/2015-02-09-12.jpg" alt="" /></p>

<h4>cpu 概念逻辑关系</h4>

<p>一个NUMA node包括一个或者多个Socket，以及与之相连的local memory。一个多核的Socket有多个Core。如果CPU支持HT，OS还会把这个Core看成 2个Logical Processor。为了避免混淆，在下文中统一用socket指代Processor or Socket;为了偷懒，下文中用Processor指代Logical Processor，击键能省则省不是。</p>

<h4>查看CPU Topology</h4>

<p>本文以笔者能访问的某台Red Hat Enterprise Linux Server release 5.4为例介绍，其他系统请自行google。</p>

<h5>NUMA Node</h5>

<p>第一种方法使用numactl查看
<code>
numactl --hardware
available: 2 nodes (0-1)  //当前机器有2个NUMA node,编号0&amp;amp;1
node 0 size: 12091 MB  //node 0 物理内存大小
node 0 free: 988 MB    //node 0 当前free内存大小
node 1 size: 12120 MB
node 1 free: 1206 MB
node distances:        //node 距离，可以简单认为是CPU本node内存访问和跨node内存访问的成本。从下表可知跨node的内存访问成本（20）是本地node内存（10）的2倍。
node   0   1
  0:  10  20
  1:  20  10
</code></p>

<p>第二种方法是通过sysfs查看，这种方式可以查看到更多的信息
<code>
ls /sys/devices/system/node/
1
</code>
node0  node1 //两个目标表示本机有2个node，每个目录内部有多个文件和子目录描述node内cpu，内存等信息。比如说node0/meminfo描述了node0内存相关信息。</p>

<h5>Socket</h5>

<p>可以直接通过/proc/cpuinfo查看，cpuinfo里的physical id描述的就是Socket的编号，
<code>
cat /proc/cpuinfo | grep "physical id"
physical id     : 0
physical id     : 0
physical id     : 0
physical id     : 0
physical id     : 1
physical id     : 1
physical id     : 1
physical id     : 1
physical id     : 0
physical id     : 0
physical id     : 0
physical id     : 0
physical id     : 1
physical id     : 1
physical id     : 1
physical id     : 1
</code>
由上可知本机有2个Socket，编号为0和1。
还可以简单的使用如下命令直接查看Socket个数
<code>
cat /proc/cpuinfo|grep "physical id" | sort -u | wc –l
2   //本机有2个物理CPU封装
</code></p>

<h5>Core</h5>

<p>仍然是可以通过/proc/cpuinfo查看，cpuinfo中跟core相关的信息有2行。
<code>
cpu cores : 4 //一个socket有4个核，
core id : 1 //一个core在socket内的编号
</code>
通过如下命令可以直接查看core的数量
<code>
cat /proc/cpuinfo | grep "cpu cores" | uniq | cut -d: -f2
4  //1个socket有4个core
</code></p>

<ul>
<li>本机有2个socket，每个有4个core，所以一共有8个core</li>
</ul>


<p>还可以查看core在Socket里的编号
<code>
cat /proc/cpuinfo | grep "core id" | sort -u
core id         : 0
core id         : 1
core id         : 10
core id         : 9
</code></p>

<p>一个socket里面4个core的编号为0,1,9,10。是的，core id是不连续的。如果谁知道为啥麻烦通知我，先谢了。</p>

<h5>Logical Processor</h5>

<p>仍然是可以通过/proc/cpuinfo查看在OS的眼里有多少个Logical Processor
<code>
cat /proc/cpuinfo | grep processor | wc –l
16
</code>
Ok，8个core变成了16个Logical Processor，所以本机开启了HT。</p>

<p>问题来了，cpuinfo里面16个Processor编号为0-15，Core的id为0,1,9,10，Socket的id为0,1。这些编号是如何对应的呢？</p>

<p>我们查看一个Processor完整的cpuinfo就比较清楚了，我剔除了不相关的行：
<code>
processor : 0   processor : 5
physical id : 0
siblings : 8
core id : 0
cpu cores : 4   physical id : 1
siblings : 8
core id : 1
cpu cores : 4
</code>
明白了？<br/>
Processor 0:在socket 0的core 0 里。<br/>
Processor 5：在socket 1的core 1 里。</p>

<h5>Cache</h5>

<p>仍然可以通过/proc/cpuinfo查看，OMG， cpuinfo难道是万能的？
<code>
processor       : 0
cache size      : 12288 KB //cpu cache 大小
cache_alignment : 64
</code></p>

<p>问题又来了，我们知道CPU cache分为L1，L2，L3, L1一般还分为独立的指令cache和数据cache。Cpuinfo里这个cache size指的是？</p>

<p>好吧，cpuinfo也不是万能的。详细的cache信息可以通过sysfs查看
<code>
ls /sys/devices/system/cpu/cpu0/cache/
index0  index1  index2  index3
</code></p>

<p>4个目录 <br/>
index0: 1级数据cache<br/>
index1: 1级指令cache<br/>
index2: 2级cache<br/>
index3: 3级cache ,对应cpuinfo里的cache</p>

<p>目录里的文件是cache信息描述，以本机的cpu0/index0为例简单解释一下：</p>

<table border="1">
<tr>
<td>文件</td>
<td>内容</td>
<td>说明</td>
</tr>
<tr>
<td>type</td>
<td>Data</td>
<td>数据cache，如果查看index1就是Instruction</td>
</tr>
<tr>
<td>Level</td>
<td>1</td>
<td>L1</td>
</tr>
<tr>
<td>Size</td>
<td>32K</td>
<td>大小为32K</td>
</tr>
<tr>
<td>coherency_line_size</td>
<td>64</td>
<th rowspan="4">64*4*128=32K</th>
</tr>
<tr>
<td>physical_line_partition</td>
<td>1</td>
</tr>
<tr>
<td>ways_of_associativity</td>
<td>4</td>
</tr>
<tr>
<td>number_of_sets</td>
<td>128</td>
</tr>
<tr>
<td>shared_cpu_map</td>
<td>00000101</td>
<td>表示这个cache被CPU0和CPU8 share</td>
</tr>
</table>


<p>解释一下shared_cpu_map内容的格式：<br />
表面上看是2进制，其实是16进制表示，每个bit表示一个cpu，1个数字可以表示4个cpu<br />
截取00000101的后4位，转换为2进制表示</p>


<table border="1">
<tr>
<td>CPU id</td>
<td>15</td>
<td>14</td>
<td>13</td>
<td>12</td>
<td>11</td>
<td>10</td>
<td>9</td>
<td>8</td>
<td>7</td>
<td>6</td>
<td>5</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>0&#215;0101的2进制表示</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</table>


<p>0101表示cpu8和cpu0，即cpu0的L1 data cache是和cpu8共享的。<br/>
验证一下？
<code>
cat /sys/devices/system/cpu/cpu8/cache/index0/shared_cpu_map
00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000101
</code>
再看一下index3 shared_cpu_map的例子
<code>
cat /sys/devices/system/cpu/cpu0/cache/index3/shared_cpu_map
00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000f0f
</code></p>

<table border="1">
<tr>
<td>CPU id</td>
<td>15</td>
<td>14</td>
<td>13</td>
<td>12</td>
<td>11</td>
<td>10</td>
<td>9</td>
<td>8</td>
<td>7</td>
<td>6</td>
<td>5</td>
<td>4</td>
<td>3</td>
<td>2</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>0x0f0f的2进制表示</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</table>


<p>cpu0,1,2,3和cpu8,9,10,11共享L3 cache</p>

<h4>小结</h4>

<p>综合以上信息可以绘制出以下的cpu topology图:</p>

<p><img src="/images/kernel/2015-02-09-13.jpg" alt="" /></p>

<p>抱歉，图比较大，网页上看不清楚，下面放大单node图，另一个node基本上可以类推。</p>

<p><img src="/images/kernel/2015-02-09-14.jpg" alt="" /></p>

<h5>使用CPU Topology</h5>

<p>好吧，现在我们知道了如何查看CPU topology。那么这与各位攻城狮的工作有什么关系呢？</p>

<p>以淘宝搜索常见的服务模型为例，服务端把离线处理的数据load到内存中，开始监听某个服务端口，接收到客户端请求后从线程池中分配一个工作线程，该线程解析请求，读取内存中对应的数据，进行一些计算，然后把结果返回给客户端。</p>

<p>把这个过程简化简化再简化，抽象抽象再抽象，可以得到一个简单的测试程序，程序流程为：<br/>
1. 主线程申请2块256M的内存，使用memset初始化这两块内存的每个byte<br/>
2. 启动2个子线程，每个线程内循环16M次，在每次循环中随机读取2块内存中的各1K数据，对每个byte进行简单加和，返回。<br/>
3. 主线程等待子线程结束，打印每个线程的结果，结束。<br/>
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#include &lt;stdio.h&gt;
</span><span class='line'>#include &lt;pthread.h&gt;
</span><span class='line'>#include &lt;stdlib.h&gt;
</span><span class='line'>#include &lt;string.h&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;char *p1, *p2;
</span><span class='line'>
</span><span class='line'>int run(unsigned r)
</span><span class='line'>{
</span><span class='line'>    int i,j,k,ret=0;
</span><span class='line'>    unsigned r1,r2;
</span><span class='line'>    srand(r);
</span><span class='line'>    for (i=0;i&lt;(16&lt;&lt;20);i++) {
</span><span class='line'>            r1 = (unsigned)(rand() % ((256&lt;&lt;20)-(1&lt;&lt;10)));
</span><span class='line'>            r2 = (unsigned)(rand() % ((256&lt;&lt;20)-(1&lt;&lt;10)));
</span><span class='line'>            k = 0;
</span><span class='line'>            for (j=0;j&lt;(1&lt;&lt;10);j++) {
</span><span class='line'>                    k += *(p1+r1+j);
</span><span class='line'>                    k += *(p2+r2+j);
</span><span class='line'>            }
</span><span class='line'>            ret += k;
</span><span class='line'>    }
</span><span class='line'>    return ret;
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>int main()
</span><span class='line'>{
</span><span class='line'>    int i,j;
</span><span class='line'>    pthread_t pth1, pth2;
</span><span class='line'>    p1 = (char*)malloc(256&lt;&lt;20);
</span><span class='line'>    p2 = (char*)malloc(256&lt;&lt;20);
</span><span class='line'>    memset(p1, sizeof(p1), 0);
</span><span class='line'>    memset(p2, sizeof(p2), 0);
</span><span class='line'>    pthread_create(&amp;pth1, NULL, run, 123);
</span><span class='line'>    pthread_create(&amp;pth2, NULL, run, 456);
</span><span class='line'>    pthread_join(pth1, NULL);
</span><span class='line'>    pthread_join(pth2, NULL);
</span><span class='line'>    return 0;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;```&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;使用-O2编译出可执行文件test，分别使用下面2个命令运行该程序。运行时间和机器配置以及当前load有关，绝对值没有意义，这里仅比较相对值。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;table border="1"&gt;
</span><span class='line'>&lt;tr&gt;
</span><span class='line'>&lt;td&gt;命令&lt;/td&gt;
</span><span class='line'>&lt;td&gt;time ./test&lt;/td&gt;
</span><span class='line'>&lt;td&gt;time numactl -m 0 &#8211;physcpubind=2,3  ./test&lt;/td&gt;
</span><span class='line'>&lt;/tr&gt;
</span><span class='line'>&lt;tr&gt;
</span><span class='line'>&lt;td&gt;用时&lt;/td&gt;
</span><span class='line'>&lt;td&gt;&lt;strong&gt;real    0m38.678s&lt;/strong&gt;&lt;br /&gt;
</span><span class='line'>user    1m6.270s&lt;br /&gt;
</span><span class='line'>sys     0m5.569s
</span><span class='line'>&lt;/td&gt;
</span><span class='line'>&lt;td&gt;&lt;strong&gt;real    0m28.410s&lt;/strong&gt;&lt;br /&gt;
</span><span class='line'>user    0m54.997s&lt;br /&gt;
</span><span class='line'>sys     0m0.961s
</span><span class='line'>&lt;/td&gt;
</span><span class='line'>&lt;/tr&gt;
</span><span class='line'>&lt;/table&gt;
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>&lt;p&gt;发生了什么？为什么有这么大的差异？
</span><span class='line'>第一个命令直观，那么我们看一下第二个命令具体做了什么：
</span><span class='line'>&lt;code&gt;
</span><span class='line'>numactl -m 0 --physcpubind=2,3 ./test
</span><span class='line'>-m 0：在node 0上分配内存
</span><span class='line'>--physcpubind=2,3：在cpu 2和3上运行程序，即一个线程运行在cpu2上，另一个运行在cpu3上。
</span><span class='line'>&lt;/code&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;参考上面的CPUtopology图就很容易理解了，由于线程绑定cpu2和3执行，共享了L3 cache，且全部内存都是本node访问，运行效率自然比随机选择cpu运行，运行中还有可能切换cpu，内存访问有可能跨node的第一种方式要快了。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;接下来，让我们看看完整的表格，读者可以看看有没有惊喜：&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;table border="1"&gt;
</span><span class='line'>&lt;tr&gt;
</span><span class='line'>&lt;td&gt;情况&lt;/td&gt;
</span><span class='line'>&lt;td&gt;命令&lt;/td&gt;
</span><span class='line'>&lt;td&gt;用时&lt;/td&gt;
</span><span class='line'>&lt;td&gt;解释&lt;/td&gt;
</span><span class='line'>&lt;/tr&gt;
</span><span class='line'>&lt;tr&gt;
</span><span class='line'>&lt;td&gt;完全由OS控制&lt;/td&gt;
</span><span class='line'>&lt;td&gt;time ./test&lt;/td&gt;
</span><span class='line'>&lt;td&gt;real    0m38.678s&lt;br /&gt;
</span><span class='line'>user    1m6.270s&lt;br /&gt;
</span><span class='line'>sys     0m5.569s
</span><span class='line'>&lt;/td&gt;
</span><span class='line'>&lt;td&gt;乐观主义者，甩手掌柜型&lt;/td&gt;
</span><span class='line'>&lt;/tr&gt;
</span><span class='line'>&lt;tr&gt;
</span><span class='line'>&lt;td&gt;绑定跨node的Cpu执行&lt;/td&gt;
</span><span class='line'>&lt;td&gt;time numactl &#8211;physcpubind=2,6  ./test&lt;/td&gt;
</span><span class='line'>&lt;td&gt;real    0m38.657s&lt;br /&gt;
</span><span class='line'>user    1m7.126s&lt;br /&gt;
</span><span class='line'>sys     0m5.045s
</span><span class='line'>&lt;/td&gt;
</span><span class='line'>&lt;td&gt;Cpu 2和6不在同一个node，不能share L3 cache&lt;/td&gt;
</span><span class='line'>&lt;/tr&gt;
</span><span class='line'>&lt;tr&gt;
</span><span class='line'>&lt;td&gt;绑定单node的Cpu执行&lt;/td&gt;
</span><span class='line'>&lt;td&gt;time numactl &#8211;physcpubind=2,3  ./test&lt;/td&gt;
</span><span class='line'>&lt;td&gt;real    0m28.605s&lt;br /&gt;
</span><span class='line'>user    0m55.161s&lt;br /&gt;
</span><span class='line'>sys     0m0.856s
</span><span class='line'>&lt;/td&gt;
</span><span class='line'>&lt;td&gt;Cpu 2和3在同一个node，share L3 cache。内存使用由OS控制，一般来说node 0和1内存都会使用。&lt;/td&gt;
</span><span class='line'>&lt;/tr&gt;
</span><span class='line'>&lt;tr&gt;
</span><span class='line'>&lt;td&gt;跨node内存访问+绑定单node CPU执行&lt;/td&gt;
</span><span class='line'>&lt;td&gt;time numactl -m 1 &#8211;physcpubind=2,3  ./test&lt;/td&gt;
</span><span class='line'>&lt;td&gt;real    0m33.218s&lt;br /&gt;
</span><span class='line'>user    1m4.494s&lt;br /&gt;
</span><span class='line'>sys     0m0.911s
</span><span class='line'>&lt;/td&gt;
</span><span class='line'>&lt;td&gt;内存全使用node1，2个cpu在node0，内存访问比较吃亏&lt;/td&gt;
</span><span class='line'>&lt;/tr&gt;
</span><span class='line'>&lt;tr&gt;
</span><span class='line'>&lt;td&gt;单node内存访问+绑定本node CPU执行&lt;/td&gt;
</span><span class='line'>&lt;td&gt;time numactl -m 0 &#8211;physcpubind=2,3  ./test&lt;/td&gt;
</span><span class='line'>&lt;td&gt;real    0m28.367s&lt;br /&gt;
</span><span class='line'>user    0m55.062s&lt;br /&gt;
</span><span class='line'>sys     0m0.825s
</span><span class='line'>&lt;/td&gt;
</span><span class='line'>&lt;td&gt;内存&amp;cpu都使用node0&lt;/td&gt;
</span><span class='line'>&lt;/tr&gt;
</span><span class='line'>&lt;tr&gt;
</span><span class='line'>&lt;td&gt;单node内存访问+绑定本node 单core执行&lt;/td&gt;
</span><span class='line'>&lt;td&gt;time numactl -m 0 &#8211;physcpubind=2,10  ./test&lt;/td&gt;
</span><span class='line'>&lt;td&gt;real    0m58.062s&lt;br /&gt;
</span><span class='line'>user    1m55.520s&lt;br /&gt;
</span><span class='line'>sys     0m0.270s
</span><span class='line'>&lt;/td&gt;
</span><span class='line'>&lt;td&gt;CPU2和10不但在同一个node，且在同一个core，本意是希望共享L1，L2cache，提升性能。但是不要忘了，CPU2和10是HT出来的logical Processor，在本例cpu密集型的线程中硬件争用严重，效率急剧下降。有没有发现和上一个case的时间比率很有意思？&lt;/td&gt;
</span><span class='line'>&lt;/tr&gt;
</span><span class='line'>&lt;/table&gt;
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>&lt;p&gt;现在谁还能说了解点cpu topology没用呢？☺&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h4&gt;Tips&lt;/h4&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;补充几个小tips，方便有兴趣的同学分析上面表格的各个case&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h5&gt;1.查看进程的内存numa node分布&lt;/h5&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;简单的说可以查看进程的numa_maps文件
</span><span class='line'>&lt;code&gt;
</span><span class='line'>cat /proc/pid/numa_maps
</span><span class='line'>&lt;/code&gt;
</span><span class='line'>文件格式可以直接：man numa_maps&lt;br/&gt;
</span><span class='line'>为了避免输入数字pid，我使用如下命令查看：
</span><span class='line'>&lt;code&gt;
</span><span class='line'>cat /proc/$(pidof test|cut –d” ” -f1)/numa_maps
</span><span class='line'>&lt;/code&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h5&gt;2.查看线程run在哪个processor&lt;/h5&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;可以使用top命令查看一个进程的各个线程分别run在哪个processor上&lt;br/&gt;
</span><span class='line'>同样，为了避免输入数字pid，我使用如下命令启动top：
</span><span class='line'>&lt;code&gt;
</span><span class='line'>top -p$(pidof test |sed -e ‘s/ /,/g’)
</span><span class='line'>&lt;/code&gt;
</span><span class='line'>在默认配置下不显示线程信息，需要进入Top后按“shift+H”，打开线程显示。&lt;br/&gt;
</span><span class='line'>另外，如果没有P列，还需要按“f”，按“j”，添加，这一列显示的数字就是这个线程上次run的processor id。&lt;br/&gt;
</span><span class='line'>关于top的使用，请读者自行man top&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h5&gt;3.另一种绑定cpu执行的方法&lt;/h5&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;如果读者的程序不涉及大量内存的访问，可以通过taskset绑定cpu执行。别怪我没提醒你，仔细判断是否应该绑定到同一个core的processor上哦。&lt;br/&gt;
</span><span class='line'>关于命令的使用，请读者自行Man taskset&lt;/p&gt;
</span><span class='line'>]]&gt;&lt;/content&gt;
</span><span class='line'>  &lt;/entry&gt;
</span><span class='line'>  
</span><span class='line'>  &lt;entry&gt;
</span><span class='line'>&lt;title type="html"&gt;&lt;![CDATA[Linux的IPC命令 查看共享内存]]&gt;&lt;/title&gt;
</span><span class='line'>&lt;link href="http://abcdxyzk.github.io/blog/2015/02/09/kernel-mm-shm3/"/&gt;
</span><span class='line'>&lt;updated&gt;2015-02-09T15:46:00+08:00&lt;/updated&gt;
</span><span class='line'>&lt;id&gt;http://abcdxyzk.github.io/blog/2015/02/09/kernel-mm-shm3&lt;/id&gt;
</span><span class='line'>&lt;content type="html"&gt;&lt;![CDATA[&lt;p&gt;&lt;a href="http://www.cnblogs.com/cocowool/archive/2012/05/22/2513027.html"&gt;http://www.cnblogs.com/cocowool/archive/2012/05/22/2513027.html&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h4&gt;进程间通信概述&lt;/h4&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;进程间通信有如下的目的：&lt;br/&gt;
</span><span class='line'>1、数据传输，一个进程需要将它的数据发送给另一个进程，发送的数据量在一个字节到几M之间；&lt;br/&gt;
</span><span class='line'>2、共享数据，多个进程想要操作共享数据，一个进程对数据的修改，其他进程应该立刻看到；&lt;br/&gt;
</span><span class='line'>3、通知事件，一个进程需要向另一个或一组进程发送消息，通知它们发生了某件事情；&lt;br/&gt;
</span><span class='line'>4、资源共享，多个进程之间共享同样的资源。为了做到这一点，需要内核提供锁和同步机制；&lt;br/&gt;
</span><span class='line'>5、进程控制，有些进程希望完全控制另一个进程的执行（如Debug进程），此时控制进程希望能够拦截另一个进程的所有陷入和异常，并能够及时知道它的状态改变。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Linux进程间通信由以下几部分发展而来：&lt;br/&gt;
</span><span class='line'>早期UNIX进程间通信：包括管道、FIFO、信号。&lt;br/&gt;
</span><span class='line'>基于System V的进程间通信：包括System V消息队列、System V信号灯（Semaphore）、System V共享内存。&lt;br/&gt;
</span><span class='line'>基于Socket进程间通信。&lt;br/&gt;
</span><span class='line'>基于POSIX进程间通信：包括POSIX消息队列、POSIX信号灯、POSIX共享内存。&lt;br/&gt;
</span><span class='line'>Linux中，与IPC相关的命令包括：ipcs、ipcrm（释放IPC）、&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;IPCS命令是Linux下显示进程间通信设施状态的工具。我们知道，系统进行进程间通信（IPC）的时候，可用的方式包括信号量、共享内存、消息队列、管道、信号（signal）、套接字等形式[2]。使用IPCS可以查看共享内存、信号量、消息队列的状态。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;例如在CentOS6.0上执行ipcs&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;img src="/images/kernel/2015-02-09-2.png" alt="" /&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;具体的用法总结如下：</span></code></pre></td></tr></table></div></figure>
    1、显示所有的IPC设施
    # ipcs -a</p>

<pre><code>2、显示所有的消息队列Message Queue
# ipcs -q

3、显示所有的信号量
# ipcs -s

4、显示所有的共享内存
# ipcs -m

5、显示IPC设施的详细信息
# ipcs -q -i id
id 对应shmid、semid、msgid等。-q对应设施的类型（队列），查看信号量详细情况使用-s，查看共享内存使用-m。

6、显示IPC设施的限制大小
# ipcs -m -l
-m对应设施类型，可选参数包括-q、-m、-s。

7、显示IPC设施的权限关系
# ipcs -c
# ipcs -m -c
# ipcs -q -c
# ipcs -s -c

8、显示最近访问过IPC设施的进程ID。
# ipcs -p
# ipcs -m -p
# ipcs -q -p

9、显示IPC设施的最后操作时间
# ipcs -t
# ipcs -q -t
# ipcs -m -t
# ipcs -s -t

10、显示IPC设施的当前状态
# ipcs -u
</code></pre>

<p>```</p>

<p>Linux上的ipcs命令，不支持UNIX上的-b、-o指令，同样UNIX中不支持-l、-u指令，所以在编写跨平台的脚本时，需要注意这个问题。</p>

<h4>参考资料：</h4>

<p>1、<a href="http://wenku.baidu.com/view/58048caddd3383c4bb4cd26f.html">Linux下IPCS的用法详解</a><br/>
2、<a href="http://www.cnblogs.com/linshui91/archive/2010/09/29/1838770.html">Linux进程间通信</a><br/>
3、<a href="http://blog.csdn.net/bonny95/article/details/6442821">Linux下IPCS的10种用法</a><br/>
4、<a href="http://www.linuxdiyf.com/viewarticle.php?id=6783">Linux IPC小结</a><br/>
5、<a href="http://www.cnblogs.com/wangkangluo1/archive/2012/05/14/2498786.html">Linux IPC总结</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[修改共享内存大小]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/02/09/kernel-mm-shm2/"/>
    <updated>2015-02-09T15:33:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/02/09/kernel-mm-shm2</id>
    <content type="html"><![CDATA[<p><a href="http://blog.csdn.net/l_yangliu/article/details/11193187">http://blog.csdn.net/l_yangliu/article/details/11193187</a></p>

<pre><code>beijibing@bjb-desktop:/proc/sys/kernel$ cat shmmax 
33554432
beijibing@bjb-desktop:/proc/sys/kernel$ cat shmmni
4096
beijibing@bjb-desktop:/proc/sys/kernel$ cat msgmax
8192
beijibing@bjb-desktop:/proc/sys/kernel$ cat msgmni
622
beijibing@bjb-desktop:/proc/sys/kernel$ cat msgmnb
16384
</code></pre>

<h4>System V IPC 参数</h4>

<table border="1">
<tr>
    <th>名字</th> <th>描述</th> <th>合理取值</th>
</tr>
<tr>
    <td>SHMMAX</td> <td>最大共享内存段尺寸（字节）</td> <td>最少若干兆（见文本）</td>
</tr>
<tr>
    <td>SHMMIN</td> <td>最小共享内存段尺寸（字节）</td> <td>1</td>
</tr>
<tr>
    <td>SHMALL</td> <td>可用共享内存的总数量（字节或者页面）</td> <td>如果是字节，就和 SHMMAX 一样；如果是页面，ceil(SHMMAX/PAGE_SIZE)</td>
</tr>
<tr>
    <td>SHMSEG</td> <td>每进程最大共享内存段数量</td> <td>只需要 1 个段，不过缺省比这高得多。</td>
</tr>
<tr>
    <td>SHMMNI</td> <td>系统范围最大共享内存段数量</td> <td>类似 SHMSEG 加上用于其他应用的空间</td>
</tr>
<tr>
    <td>SEMMNI</td> <td>信号灯标识符的最小数量（也就是说，套）</td> <td>至少 ceil(max_connections / 16)</td>
</tr>
<tr>
    <td>SEMMNS</td> <td>系统范围的最大信号灯数量</td> <td>ceil(max_connections / 16) * 17 加上用于其他应用的空间</td>
</tr>
<tr>
    <td>SEMMSL</td> <td>每套信号灯最小信号灯数量</td> <td>至少 17</td>
</tr>
<tr>
    <td>SEMMAP</td> <td>信号灯映射里的记录数量</td> <td>参阅文本</td>
</tr>
<tr>
    <td>SEMVMX</td> <td>信号灯的最大值</td> <td>至少 1000 （缺省通常是32767，除非被迫，否则不要修改）</td>
</tr>
</table>


<p>  最重要的共享内存参数是 SHMMAX ， 以字节记的共享内存段可拥有的最大尺寸。如果你收到来自shmget 的类似Invalid argument 这样的错误信息，那么很有可能是你超过限制了。</p>

<p>  有些系统对系统里面共享内存的总数（SHMALL ）还有限制。 请注意这个数值必须足够大。（注意：SHMALL 在很多系统上是用页面数，而不是字节数来计算的。）</p>

<p>  系统里的最大信号灯数目是由SEMMNS 设置的，因此这个值应该至少和 max_connections 设置一样大，并且每十六个联接还要另外加一个。  参数SEMMNI 决定系统里一次可以存在的信号灯集的数目。 因此这个参数至少应该为 ceil(max_connections % 16) 。降低允许的联接数目是一个临时的绕开失败的方法，这个启动失败通常被来自函数semget 的错误响应 No space left on device 搞得很让人迷惑。</p>

<p>  有时候还可能有必要增大SEMMAP ，使之至少按照 SEMMNS 配置。这个参数定义信号灯资源映射的尺寸，可用的每个连续的信号灯块在这个映射中存放一条记录。每当一套信号灯被释放，那么它要么会加入到该映射中一条相连的已释放的块的入口中，要么注册成一条新的入口。如果映射填满了碎片，那么被释放的信号灯就丢失了（除非重起）。因此时间长信号灯空间的碎片了会导致可用的信号灯比应该有的信号灯少。</p>

<p>SEMMSL 参数，决定一套信号灯里可以有多少信号灯，</p>

<h4>更改方法</h4>

<p>  缺省设置只适合小安装（缺省最大共享内存是 32 MB）。不过，其它的缺省值都相当大，通常不需要改变。最大的共享内存段设置可以用 sysctl 接口设置。 比如，要允许 128 MB，并且最大的总共享内存数为 2097152 页（缺省）：
<code>
    $ sysctl -w kernel.shmmax=134217728
    $ sysctl -w kernel.shmall=2097152
</code>
  你可以把这些设置放到 /etc/sysctl.conf 里，在重启后保持有效。</p>

<p>  老版本里可能没有 sysctl 程序，但是同样的改变可以通过操作 /proc 文件系统来做：
<code>
    $ echo 134217728 &gt; /proc/sys/kernel/shmmax
    $ echo 2097152 &gt; /proc/sys/kernel/shmall
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[共享内存]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/02/09/kernel-mm-shm1/"/>
    <updated>2015-02-09T15:23:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/02/09/kernel-mm-shm1</id>
    <content type="html"><![CDATA[<p><a href="http://blog.csdn.net/wc7620awjh/article/details/7721331">http://blog.csdn.net/wc7620awjh/article/details/7721331</a></p>

<p>  共享内存是被多个进程共享的一部分物理内存。共享内存是进程间共享数据的一种最快的方法，一个进程向共享内存区域写入了数据，共享这个内存区域的所有进程就可以立刻看到其中的内容。原理图如下：</p>

<p><img src="/images/kernel/2015-02-09-1.jpg" alt="" /></p>

<p>共享内存的实现分为两个步骤：<br/>
一、 创建共享内存，使用shmget函数。
二、 映射共享内存，将这段创建的共享内存映射到具体的进程空间去，使用shmat函数。</p>

<h4>创建共享内存</h4>

<pre><code>    int shmget(key_t key ,int size,int shmflg)
</code></pre>

<p>key标识共享内存的键值：0/IPC_PRIVATE。当key的取值为IPC_PRIVATE,则函数shmget将创建一块新的共享内存；如果key的取值为0，而参数中又设置了IPC_PRIVATE这个标志，则同样会创建一块新的共享内存。</p>

<p>返回值：如果成功，返回共享内存表示符，如果失败，返回-1。</p>

<h4>映射共享内存</h4>

<pre><code>    int shmat(int shmid,char *shmaddr，int flag)
</code></pre>

<p>参数：<br/>
shmid:shmget函数返回的共享存储标识符<br/>
flag：决定以什么样的方式来确定映射的地址(通常为0)</p>

<p>返回值：<br/>
如果成功，则返回共享内存映射到进程中的地址；如果失败，则返回-1。<br/>
共享内存解除映射</p>

<p>当一个进程不再需要共享内存时，需要把它从进程地址空间中多里。
<code>
int shmdt(char *shmaddr)
</code>
贡献内存实例如下：<br/>
实验要求：创建两个进程，在A进程中创建一个共享内存，并向其写入数据，通过B进程从共享内存中读取数据。</p>

<h5>chm_com.h函数</h5>

<pre><code>    #define TEXT_SZ 2048  

    struct shared_use_st  
    {  
        int written_by_you;  
        char some_text[TEXT_SZ];  
    };  
</code></pre>

<h5>读取进程：</h5>

<pre><code>    #include &lt;unistd.h&gt;  
    #include &lt;stdlib.h&gt;  
    #include &lt;stdio.h&gt;  
    #include &lt;string.h&gt;  
    #include &lt;sys/types.h&gt;  
    #include &lt;sys/ipc.h&gt;  
    #include &lt;sys/shm.h&gt;  
    #include "shm_com.h"  

    /* 
     * 程序入口 
     * */  
    int main(void)  
    {  
        int running=1;  
        void *shared_memory=(void *)0;  
        struct shared_use_st *shared_stuff;  
        int shmid;  
        /*创建共享内存*/  
        shmid=shmget((key_t)1234,sizeof(struct shared_use_st),0666|IPC_CREAT);  
        if(shmid==-1)  
        {  
            fprintf(stderr,"shmget failed\n");  
            exit(EXIT_FAILURE);  
        }  

        /*映射共享内存*/  
        shared_memory=shmat(shmid,(void *)0,0);  
        if(shared_memory==(void *)-1)  
        {  
            fprintf(stderr,"shmat failed\n");  
            exit(EXIT_FAILURE);  
        }  
        printf("Memory attached at %X\n",(int)shared_memory);  

        /*让结构体指针指向这块共享内存*/  
        shared_stuff=(struct shared_use_st *)shared_memory;  

        /*控制读写顺序*/  
        shared_stuff-&gt;written_by_you=0;  
        /*循环的从共享内存中读数据，直到读到“end”为止*/  
        while(running)  
        {  
           if(shared_stuff-&gt;written_by_you)  
           {  
               printf("You wrote:%s",shared_stuff-&gt;some_text);  
               sleep(1);  //读进程睡一秒，同时会导致写进程睡一秒，这样做到读了之后再写  
               shared_stuff-&gt;written_by_you=0;  
               if(strncmp(shared_stuff-&gt;some_text,"end",3)==0)  
               {  
                   running=0; //结束循环  
               }  
           }  
        }  
        /*删除共享内存*/  
        if(shmdt(shared_memory)==-1)  
        {  
            fprintf(stderr,"shmdt failed\n");  
            exit(EXIT_FAILURE);  
        }  
           exit(EXIT_SUCCESS);  
    }  
</code></pre>

<h5>写入进程：</h5>

<pre><code>    #include &lt;unistd.h&gt;  
    #include &lt;stdlib.h&gt;  
    #include &lt;stdio.h&gt;  
    #include &lt;string.h&gt;  
    #include &lt;sys/types.h&gt;  
    #include &lt;sys/ipc.h&gt;  
    #include &lt;sys/shm.h&gt;  
    #include "shm_com.h"  

    /* 
     * 程序入口 
     * */  
    int main(void)  
    {  
        int running=1;  
        void *shared_memory=(void *)0;  
        struct shared_use_st *shared_stuff;  
        char buffer[BUFSIZ];  
        int shmid;  
        /*创建共享内存*/  
        shmid=shmget((key_t)1234,sizeof(struct shared_use_st),0666|IPC_CREAT);  
        if(shmid==-1)  
        {  
            fprintf(stderr,"shmget failed\n");  
            exit(EXIT_FAILURE);  
        }  

        /*映射共享内存*/  
        shared_memory=shmat(shmid,(void *)0,0);  
        if(shared_memory==(void *)-1)  
        {  
            fprintf(stderr,"shmat failed\n");  
            exit(EXIT_FAILURE);  
        }  
        printf("Memory attached at %X\n",(int)shared_memory);  

        /*让结构体指针指向这块共享内存*/  
        shared_stuff=(struct shared_use_st *)shared_memory;  
        /*循环的向共享内存中写数据，直到写入的为“end”为止*/  
        while(running)  
        {  
            while(shared_stuff-&gt;written_by_you==1)  
            {  
                sleep(1);//等到读进程读完之后再写  
                printf("waiting for client...\n");  
            }  
            printf("Ener some text:");  
            fgets(buffer,BUFSIZ,stdin);  
            strncpy(shared_stuff-&gt;some_text,buffer,TEXT_SZ);  
            shared_stuff-&gt;written_by_you=1;  
            if(strncmp(buffer,"end",3)==0)  
            {  
                running=0;  //结束循环  
            }  
        }  
        /*删除共享内存*/  
        if(shmdt(shared_memory)==-1)  
        {  
            fprintf(stderr,"shmdt failed\n");  
            exit(EXIT_FAILURE);  
        }  
        exit(EXIT_SUCCESS);  
    }  
</code></pre>

<h5>运行</h5>

<p>  在一个终端中运行shm1，在另一个终端中运行shm2.当shm1运行起来之后，由于共享内存中没有数据可读，会处于等待状态
```
    [root@localhost 2-4-4]# ./shm1
    Memory attached at B7F9A000</p>

<pre><code>/***阻塞***/
</code></pre>

<pre><code>
再向shm2运行的终端输入字符串
</code></pre>

<pre><code>[root@localhost 2-4-4]# ./shm2
Memory attached at B7FD8000
Enter some text：Impossible is nothing
waiting for client。。。
waiting for client。。。
Enter some text：Anything is possible
waiting for client。。。
Ener some text：end
[root@localhost 2-4-4]#
</code></pre>

<pre><code>
shm1能够逐个从共享内存中巴他们读出来，知道双方晕倒字符串"end"后，两个程序都退出。
</code></pre>

<pre><code>[root@localhost 2-4-4]# ./shm1
Memory attached at B7F9A000
You write：Impossible is nothing
You write：Anything is possible
You write：end
[root@localhost 2-4-4]#
</code></pre>

<p>```
以上运行过程中，红色表示在终端1中运行的结果，蓝色表示在终端2里面运行的结果。</p>
]]></content>
  </entry>
  
</feed>
