<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: kernel | kk Blog —— 通用基础]]></title>
  <link href="http://abcdxyzk.github.io/blog/cats/kernel/atom.xml" rel="self"/>
  <link href="http://abcdxyzk.github.io/"/>
  <updated>2015-05-29T15:55:20+08:00</updated>
  <id>http://abcdxyzk.github.io/</id>
  <author>
    <name><![CDATA[kk]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[字符设备驱动和等待队列样例]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/05/21/kernel-sched-waitqueue-sample/"/>
    <updated>2015-05-21T15:58:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/05/21/kernel-sched-waitqueue-sample</id>
    <content type="html"><![CDATA[<p>前两篇的样例</p>

<p><a href="/blog/2015/05/21/kernel-base-chardev/">字符设备驱动程序</a><br/>
<a href="/blog/2015/05/21/kernel-sched-waitqueue/">Linux内核中的等待队列</a></p>

<h4>waitqueue.c</h4>

<pre><code>    #include &lt;linux/module.h&gt;
    #include &lt;linux/init.h&gt;
    #include &lt;linux/fs.h&gt;
    #include &lt;asm/uaccess.h&gt;
    #include &lt;linux/wait.h&gt;
    #include &lt;linux/semaphore.h&gt;
    #include &lt;linux/kernel.h&gt;
    #include &lt;linux/proc_fs.h&gt;

    #include &lt;linux/socket.h&gt;
    #include &lt;linux/tcp.h&gt;
    #include &lt;linux/proc_fs.h&gt;
    #include &lt;net/net_namespace.h&gt;

    #include &lt;net/tcp.h&gt;


    static ssize_t globalvar_read(struct file *, char *, size_t, loff_t*);
    static ssize_t globalvar_write(struct file *, const char *, size_t, loff_t*);

    struct file_operations globalvar_fops =
    {
        .owner   = THIS_MODULE,
        .read = globalvar_read,
        .write = globalvar_write,
    };

    #define LEN 1024
    static char global_var[LEN];
    static int read_index = 0;
    static int write_index = 0;
    static spinlock_t var_lock;
    static wait_queue_head_t waitq;
    static int flag = 0;
    static int major;

    static const char procname[] = "testvar";

    static int __init globalvar_init(void)
    {
        init_waitqueue_head(&amp;waitq);
        spin_lock_init(&amp;var_lock);
    //  if (!proc_net_fops_create(&amp;init_net, procname, S_IRUSR, &amp;globalvar_fops)) {
        if (!(major = register_chrdev(0, "globalvar", &amp;globalvar_fops))) {
            printk("globalvar register failure\n");
            return -1;
        }
        printk("major = %d\n", major);
        return 0;
    }

    static void __exit globalvar_exit(void)
    {
    //  proc_net_remove(&amp;init_net, procname);
        unregister_chrdev(major, "globalvar");
    }

    static ssize_t globalvar_read(struct file *filp, char *buf, size_t len, loff_t *off)
    {
        int read_len;
        //等待数据可获得
        if (wait_event_interruptible(waitq, flag != 0))
            return -ERESTARTSYS;

        spin_lock(&amp;var_lock);
        read_len = write_index - read_index;
        if (copy_to_user(buf, global_var+read_index, read_len)) {
            spin_unlock(&amp;var_lock);
            return -EFAULT;
        }
        read_index = write_index;
        flag = 0;
        spin_unlock(&amp;var_lock);
        return read_len;
    }

    static ssize_t globalvar_write(struct file *filp, const char *buf, size_t len, loff_t *off)
    {
        spin_lock(&amp;var_lock);
        if (copy_from_user(global_var+write_index, buf, len)) {
            spin_unlock(&amp;var_lock);
            return -EFAULT;
        }
        write_index += len;
        spin_unlock(&amp;var_lock);

        flag = 1;
        //通知数据可获得
        wake_up_interruptible(&amp;waitq);
        return len;
    }

    module_init(globalvar_init);
    module_exit(globalvar_exit);
    MODULE_LICENSE("GPL");
</code></pre>

<h4>Makefile</h4>

<pre><code>    obj-m += waitqueue.o

    PWD = $(shell pwd)
    KERNEL := /lib/modules/`uname -r`/build

    all:
        make -C $(KERNEL) M=$(PWD) modules
</code></pre>

<h5>安装模块</h5>

<pre><code>    insmod ./waitqueue.ko
</code></pre>

<h5>查看对应的设备号</h5>

<pre><code>    $ cat /proc/devices | grep globalvar
    $ 249 globalvar
</code></pre>

<h5>建立文件</h5>

<pre><code>    mknod /dev/globalvar c 249 0
</code></pre>

<h5>终端1: cat文件</h5>

<pre><code>    cat /dev/globalvar
</code></pre>

<h5>终端2: echo数据到文件</h5>

<pre><code>    echo 123 &gt; /dev/globalvar
    echo 1234567 &gt; /dev/globalvar
    echo 123 &gt; /dev/globalvar
</code></pre>

<p>这时就能看见终端1读到了内容。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux内核中的等待队列]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/05/21/kernel-sched-waitqueue/"/>
    <updated>2015-05-21T15:58:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/05/21/kernel-sched-waitqueue</id>
    <content type="html"><![CDATA[<p><a href="http://blog.sina.com.cn/s/blog_49d5604e010008bn.html">http://blog.sina.com.cn/s/blog_49d5604e010008bn.html</a></p>

<p>等待队列可以参考net/ipv4/tcp_probe.c的实现</p>

<p><a href="/blog/2015/05/21/kernel-sched-waitqueue-sample/">简单样例</a></p>

<h4>Linux内核中的等待队列</h4>

<p>  Linux内核的等待队列是以双循环链表为基础数据结构，与进程调度机制紧密结合，能够用于实现核心的异步事件通知机制。在Linux2.4.21中，等待队列在源代码树include/linux/wait.h中，这是一个通过list_head连接的典型双循环链表，</p>

<p>如下图所示。</p>

<p><img src="/images/kernel/2015-05-21.jpg" alt="" /></p>

<p>  在这个链表中，有两种数据结构：等待队列头（wait_queue_head_t）和等待队列项（wait_queue_t）。等待队列头和等待队列项中都包含一个list_head类型的域作为"连接件"。由于我们只需要对队列进行添加和删除操作，并不会修改其中的对象（等待队列项），因此，我们只需要提供一把保护整个基础设施和所有对象的锁，这把锁保存在等待队列头中，为wq_lock_t类型。在实现中，可以支持读写锁（rwlock）或自旋锁（spinlock）两种类型，通过一个宏定义来切换。如果使用读写锁，将wq_lock_t定义为rwlock_t类型；如果是自旋锁，将wq_lock_t定义为spinlock_t类型。无论哪种情况，分别相应设置wq_read_lock、wq_read_unlock、wq_read_lock_irqsave、wq_read_unlock_irqrestore、wq_write_lock_irq、wq_write_unlock、wq_write_lock_irqsave和wq_write_unlock_irqrestore等宏。</p>

<h5>等待队列头</h5>

<pre><code>    struct __wait_queue_head {
        wq_lock_t lock;
        struct list_head task_list;
    };
    typedef struct __wait_queue_head wait_queue_head_t;
</code></pre>

<p>  前面已经说过，等待队列的主体是进程，这反映在每个等待队列项中，是一个任务结构指针（struct task_struct * task）。flags为该进程的等待标志，当前只支持互斥。</p>

<h5>等待队列项</h5>

<pre><code>    struct __wait_queue {
        unsigned int flags;
    #define WQ_FLAG_EXCLUSIVE 0x01
        struct task_struct * task;
        struct list_head task_list;
    };
    typedef struct __wait_queue wait_queue_t;
</code></pre>

<h5>声明和初始化</h5>

<pre><code>    #define DECLARE_WAITQUEUE(name, tsk)            \
        wait_queue_t name = __WAITQUEUE_INITIALIZER(name, tsk)
    #define __WAITQUEUE_INITIALIZER(name, tsk) {    \
        task:  tsk,                                 \
        task_list: { NULL, NULL },                  \
        __WAITQUEUE_DEBUG_INIT(name)}
</code></pre>

<p>  通过DECLARE_WAITQUEUE宏将等待队列项初始化成对应的任务结构，并且用于连接的相关指针均设置为空。其中加入了调试相关代码。
<code>
    #define DECLARE_WAIT_QUEUE_HEAD(name)                    \
        wait_queue_head_t name = __WAIT_QUEUE_HEAD_INITIALIZER(name)
    #define __WAIT_QUEUE_HEAD_INITIALIZER(name) {            \
        lock:  WAITQUEUE_RW_LOCK_UNLOCKED,                   \
        task_list: { &amp;(name).task_list, &amp;(name).task_list }, \
        __WAITQUEUE_HEAD_DEBUG_INIT(name)}
</code></p>

<p>  通过DECLARE_WAIT_QUEUE_HEAD宏初始化一个等待队列头，使得其所在链表为空，并设置链表为"未上锁"状态。其中加入了调试相关代码。
<code>
    static inline void init_waitqueue_head(wait_queue_head_t *q)
</code></p>

<p>该函数初始化一个已经存在的等待队列头，它将整个队列设置为"未上锁"状态，并将链表指针prev和next指向它自身。
<code>
    {
        q-&gt;lock = WAITQUEUE_RW_LOCK_UNLOCKED;
        INIT_LIST_HEAD(&amp;q-&gt;task_list);
    }
    static inline void init_waitqueue_entry(wait_queue_t *q, struct task_struct *p)
</code></p>

<p>该函数初始化一个已经存在的等待队列项，它设置对应的任务结构，同时将标志位清0。
<code>
    {
        q-&gt;flags = 0;
        q-&gt;task = p;
    }
    static inline int waitqueue_active(wait_queue_head_t *q)
</code>
该函数检查等待队列是否为空。
<code>
    {
        return !list_empty(&amp;q-&gt;task_list);
    }
    static inline void __add_wait_queue(wait_queue_head_t *head, wait_queue_t *new)
</code></p>

<p>将指定的等待队列项new添加到等待队列头head所在的链表头部，该函数假设已经获得锁。
<code>
    {
        list_add(&amp;new-&gt;task_list, &amp;head-&gt;task_list);
    }
    static inline void __add_wait_queue_tail(wait_queue_head_t *head, wait_queue_t *new)
</code></p>

<p>将指定的等待队列项new添加到等待队列头head所在的链表尾部，该函数假设已经获得锁。
<code>
    {
        list_add_tail(&amp;new-&gt;task_list, &amp;head-&gt;task_list);
    }
    static inline void __remove_wait_queue(wait_queue_head_t *head, wait_queue_t *old)
</code>
将函数从等待队列头head所在的链表中删除指定等待队列项old，该函数假设已经获得锁，并且old在head所在链表中。
<code>
    {
        list_del(&amp;old-&gt;task_list);
    }
</code></p>

<h4>睡眠和唤醒操作</h4>

<p>对等待队列的操作包括睡眠和唤醒（相关函数保存在源代码树的/kernel/sched.c和include/linux/sched.h中）。思想是更改当前进程（CURRENT）的任务状态，并要求重新调度，因为这时这个进程的状态已经改变，不再在调度表的就绪队列中，因此无法再获得执行机会，进入"睡眠"状态，直至被"唤醒"，即其任务状态重新被修改回就绪态。</p>

<p>常用的睡眠操作有interruptible_sleep_on和sleep_on。两个函数类似，只不过前者将进程的状态从就绪态（TASK_RUNNING）设置为TASK_INTERRUPTIBLE，允许通过发送signal唤醒它（即可中断的睡眠状态）；而后者将进程的状态设置为TASK_UNINTERRUPTIBLE，在这种状态下，不接收任何singal。</p>

<p>以interruptible_sleep_on为例，其展开后的代码是：
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>void interruptible_sleep_on(wait_queue_head_t &lt;em&gt;q)
</span><span class='line'>{
</span><span class='line'>    unsigned long flags;
</span><span class='line'>    wait_queue_t wait;
</span><span class='line'>    /&lt;/em&gt; 构造当前进程对应的等待队列项 */
</span><span class='line'>    init_waitqueue_entry(&amp;wait, current);&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    /* 将当前进程的状态从TASK_RUNNING改为TASK_INTERRUPTIBLE */
</span><span class='line'>current-&gt;state = TASK_INTERRUPTIBLE;
</span><span class='line'>
</span><span class='line'>/* 将等待队列项添加到指定链表中 */
</span><span class='line'>wq_write_lock_irqsave(&amp;q-&gt;lock,flags);
</span><span class='line'>__add_wait_queue(q, &amp;wait); 
</span><span class='line'>wq_write_unlock(&amp;q-&gt;lock);
</span><span class='line'>
</span><span class='line'>/* 进程重新调度，放弃执行权 */
</span><span class='line'>schedule();
</span><span class='line'>
</span><span class='line'>/* 本进程被唤醒，重新获得执行权，首要之事是将等待队列项从链表中删除 */
</span><span class='line'>wq_write_lock_irq(&amp;q-&gt;lock);
</span><span class='line'>__remove_wait_queue(q, &amp;wait);
</span><span class='line'>wq_write_unlock_irqrestore(&amp;q-&gt;lock,flags);
</span><span class='line'>/* 至此，等待过程结束，本进程可以正常执行下面的逻辑 */
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>对应的唤醒操作包括wake_up_interruptible和wake_up。wake_up函数不仅可以唤醒状态为TASK_UNINTERRUPTIBLE的进程，而且可以唤醒状态为TASK_INTERRUPTIBLE的进程。
</span><span class='line'>
</span><span class='line'>wake_up_interruptible只负责唤醒状态为TASK_INTERRUPTIBLE的进程。这两个宏的定义如下：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;#define wake_up(x)   __wake_up((x),TASK_UNINTERRUPTIBLE | TASK_INTERRUPTIBLE, 1)
</span><span class='line'>#define wake_up_interruptible(x) __wake_up((x),TASK_INTERRUPTIBLE, 1)
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>__wake_up函数主要是获取队列操作的锁，具体工作是调用__wake_up_common完成的。
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;void __wake_up(wait_queue_head_t *q, unsigned int mode, int nr)
</span><span class='line'>{
</span><span class='line'>if (q) {
</span><span class='line'>    unsigned long flags;
</span><span class='line'>    wq_read_lock_irqsave(&amp;q-&gt;lock, flags);
</span><span class='line'>    __wake_up_common(q, mode, nr, 0);
</span><span class='line'>    wq_read_unlock_irqrestore(&amp;q-&gt;lock, flags);
</span><span class='line'>}
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>/* The core wakeup function.  Non-exclusive wakeups (nr_exclusive == 0) just wake everything up.  If it's an exclusive wakeup (nr_exclusive == small +ve number) then we wake all the non-exclusive tasks and one exclusive task.
</span><span class='line'>There are circumstances in which we can try to wake a task which has already started to run but is not in state TASK_RUNNING.  try_to_wake_up() returns zero in this (rare) case, and we handle it by contonuing to scan the queue. */
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;static inline void __wake_up_common (wait_queue_head_t *q, unsigned int mode, int nr_exclusive, const int sync)
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>参数q表示要操作的等待队列，mode表示要唤醒任务的状态，如TASK_UNINTERRUPTIBLE或TASK_INTERRUPTIBLE等。nr_exclusive是要唤醒的互斥进程数目，在这之前遇到的非互斥进程将被无条件唤醒。sync表示？？？
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;{
</span><span class='line'>struct list_head *tmp;
</span><span class='line'>struct task_struct *p;
</span><span class='line'>
</span><span class='line'>CHECK_MAGIC_WQHEAD(q);
</span><span class='line'>WQ_CHECK_LIST_HEAD(&amp;q-&gt;task_list);
</span><span class='line'>
</span><span class='line'>/* 遍历等待队列 */
</span><span class='line'>list_for_each(tmp,&amp;q-&gt;task_list) {
</span><span class='line'>    unsigned int state;
</span><span class='line'>    /* 获得当前等待队列项 */
</span><span class='line'>    wait_queue_t *curr = list_entry(tmp, wait_queue_t, task_list);
</span><span class='line'>
</span><span class='line'>    CHECK_MAGIC(curr-&gt;__magic);
</span><span class='line'>    /* 获得对应的进程 */
</span><span class='line'>    p = curr-&gt;task;
</span><span class='line'>    state = p-&gt;state;
</span><span class='line'>
</span><span class='line'>    /* 如果我们需要处理这种状态的进程 */
</span><span class='line'>    if (state &amp; mode) {
</span><span class='line'>        WQ_NOTE_WAKER(curr);
</span><span class='line'>        if (try_to_wake_up(p, sync) &amp;&amp; (curr-&gt;flags&amp;WQ_FLAG_EXCLUSIVE) &amp;&amp; !--nr_exclusive)
</span><span class='line'>            break;
</span><span class='line'>    }
</span><span class='line'>}
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>/* 唤醒一个进程，将它放到运行队列中，如果它还不在运行队列的话。"当前"进程总是在运行队列中的（except when the actual re-schedule is in progress)，and as such you're allowed to do the simpler "current-&gt;state = TASK_RUNNING" to mark yourself runnable without the overhead of this. */
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;static inline int try_to_wake_up(struct task_struct * p, int synchronous)
</span><span class='line'>{
</span><span class='line'>unsigned long flags;
</span><span class='line'>int success = 0;
</span><span class='line'>
</span><span class='line'>/* 由于我们需要操作运行队列，必须获得对应的锁 */
</span><span class='line'>spin_lock_irqsave(&amp;runqueue_lock, flags);
</span><span class='line'>/* 将进程状态设置为TASK_RUNNING */
</span><span class='line'>p-&gt;state = TASK_RUNNING;
</span><span class='line'>/* 如果进程已经在运行队列中，释放锁退出 */
</span><span class='line'>if (task_on_runqueue(p))
</span><span class='line'>    goto out;
</span><span class='line'>/* 否则将进程添加到运行队列中 */
</span><span class='line'>add_to_runqueue(p);
</span><span class='line'>
</span><span class='line'>/* 如果设置了同步标志 */
</span><span class='line'>if (!synchronous || !(p-&gt;cpus_allowed &amp; (1UL &lt;&lt; smp_processor_id())))
</span><span class='line'>    reschedule_idle(p);
</span><span class='line'>/* 唤醒成功，释放锁退出 */
</span><span class='line'>success = 1;
</span><span class='line'>out:
</span><span class='line'>spin_unlock_irqrestore(&amp;runqueue_lock, flags);
</span><span class='line'>return success;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>#### 等待队列应用模式
</span><span class='line'>
</span><span class='line'>等待队列的的应用涉及两个进程，假设为A和B。A是资源的消费者，B是资源的生产者。A在消费的时候必须确保资源已经生产出来，为此定义一个资源等待队列。这个队列同时要被进程A和进程B使用，我们可以将它定义为一个全局变量。
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;DECLARE_WAIT_QUEUE_HEAD(rsc_queue); /* 全局变量 */
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>在进程A中，执行逻辑如下：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;while (resource is unavaiable) {
</span><span class='line'>interruptible_sleep_on( &amp;wq );
</span><span class='line'>}
</span><span class='line'>consume_resource();
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>在进程B中，执行逻辑如下：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;produce_resource();
</span><span class='line'>wake_up_interruptible( &amp;wq );
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;```&lt;/p&gt;
</span><span class='line'>]]&gt;&lt;/content&gt;
</span><span class='line'>  &lt;/entry&gt;
</span><span class='line'>  
</span><span class='line'>  &lt;entry&gt;
</span><span class='line'>&lt;title type="html"&gt;&lt;![CDATA[字符设备驱动程序]]&gt;&lt;/title&gt;
</span><span class='line'>&lt;link href="http://abcdxyzk.github.io/blog/2015/05/21/kernel-base-chardev/"/&gt;
</span><span class='line'>&lt;updated&gt;2015-05-21T15:58:00+08:00&lt;/updated&gt;
</span><span class='line'>&lt;id&gt;http://abcdxyzk.github.io/blog/2015/05/21/kernel-base-chardev&lt;/id&gt;
</span><span class='line'>&lt;content type="html"&gt;&lt;![CDATA[&lt;p&gt;&lt;a href="http://techlife.blog.51cto.com/212583/39225"&gt;http://techlife.blog.51cto.com/212583/39225&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a href="/blog/2015/05/21/kernel-sched-waitqueue-sample/"&gt;简单样例&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;实现如下的功能:&lt;br/&gt;
</span><span class='line'>  -字符设备驱动程序的结构及驱动程序需要实现的系统调用&lt;br/&gt;
</span><span class='line'>  -可以使用cat命令或者自编的readtest命令读出"设备"里的内容&lt;br/&gt;
</span><span class='line'>  -以8139网卡为例，演示了I/O端口和I/O内存的使用&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;本文中的大部分内容在Linux Device Driver这本书中都可以找到，这本书是Linux驱动开发者的唯一圣经。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;hr /&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;先来看看整个驱动程序的入口，是char8139_init()这个函数，如果不指定MODULE_LICENSE(&ldquo;GPL&rdquo;), 在模块插入内核的时候会出错，因为将非"GPL"的模块插入内核就沾污了内核的"GPL"属性。</span></code></pre></td></tr></table></div></figure>
    module_init(char8139_init);
    module_exit(char8139_exit);</p>

<pre><code>MODULE_LICENSE("GPL");
MODULE_AUTHOR("ypixunil");
MODULE_DESCRIPTION("Wierd char device driver for Realtek 8139 NIC");
</code></pre>

<pre><code>
接着往下看char8139_init()
</code></pre>

<pre><code>static int __init char8139_init(void)
{
    int result;

    PDBG("hello. init.\n");

    /* register our char device */
    result = register_chrdev(char8139_major, "char8139", &amp;char8139_fops);
    if (result &lt; 0) {
        PDBG("Cannot allocate major device number!\n");
        return result;
    }
    /* register_chrdev() will assign a major device number and return if it called
     * with "major" parameter set to 0 */
    if(char8139_major == 0)
        char8139_major=result;

    /* allocate some kernel memory we need */
    buffer = (unsigned char*)(kmalloc(CHAR8139_BUFFER_SIZE, GFP_KERNEL));
    if (!buffer) {
        PDBG("Cannot allocate memory!\n");
        result = -ENOMEM;
        goto init_fail;
    }
    memset(buffer, 0, CHAR8139_BUFFER_SIZE);
    p_buf = buffer;

    return 0; /* everything's ok */

init_fail:
    char8139_exit();
    return result;
}
</code></pre>

<pre><code>
这个函数首先的工作就是使用register_chrdev()注册我们的设备的主设备号和系统调用。系统调用对于字符设备驱动程序来说就是file_operations接口。

我们先来看看char8139_major的定义，
</code></pre>

<pre><code>#define DEFAULT_MAJOR 145         /* data structure used by our driver */
int char8139_major=DEFAULT_MAJOR; /* major device number. if initial value is 0,
                                   * the kernel will dynamically assign a major device
                                   * number in register_chrdev() */
</code></pre>

<pre><code>
这里我们指定我们的设备的主设备号是145,你必须找到一个系统中没有用的主设备号，可以通过"cat /proc/devices"命令来查看系统中已经使用的主设备号。
</code></pre>

<pre><code>[michael@char8139]$ cat /proc/devices
Character devices:
1 mem
2 pty
3 ttyp
4 ttyS
5 cua
7 vcs
10 misc
14 sound
116 alsa
128 ptm
136 pts
162 raw
180 usb
195 nvidia
226 drm

Block devices:
2 fd
3 ide0
22 ide1
[michael@char8139]$
</code></pre>

<pre><code>
可见在我的系统中，145还没有被使用。

指定主设备号值得考虑。像上面这样指定一个主设备号显然缺乏灵活性，而且不能保证一个驱动程序在所有的机器上都能用。可以在调用register_chrdev()时将第一个参数，即主设备号指定为0,这样register_chrdev()会分配一个空闲的主设备号作为返回值。 但是这样也有问题，我们只有在将模块插入内核之后才能得到我们设备的主设备号(使用 "cat /proc/devices")，但是要操作设备需要在系统/dev目录下建立设备结点，而建立结点时要指定主设备号。当然，你可以写一个脚本来自动完成这些事情。

总之，作为一个演示，我们还是指定主设备号为145，这样我们可以在/dev/目录下建立几个设备节点。
</code></pre>

<pre><code>[root@char8139]$ mknod /dev/char8139_0 c 145 0
[root@char8139]$ mknod /dev/char8139_0 c 145 17
[root@char8139]$ mknod /dev/char8139_0 c 145 36
[root@char8139]$ mknod /dev/char8139_0 c 145 145
</code></pre>

<pre><code>
看一下我们建立的节点
</code></pre>

<pre><code>[michael@char8139]$ ll /dev/char8139*
crw-r--r-- 1 root root 145, 0 2004-12-26 20:33 /dev/char8139_0
crw-r--r-- 1 root root 145, 17 2004-12-26 20:34 /dev/char8139_1
crw-r--r-- 1 root root 145, 36 2004-12-26 20:34 /dev/char8139_2
crw-r--r-- 1 root root 145, 145 2004-12-26 20:34 /dev/char8139_3
[michael@char8139]$
</code></pre>

<pre><code>
我们建立了四个节点，使用了四个次设备号，后面我们会说明次设备号的作用。


再来看看我们的file_operations的定义。这里其实只实现了read()，open()，release()三个系统调用，ioctl()只是简单返回。更有write()等函数甚至根本没有声明，没有声明的函数系统可能会调用默认的操作。
</code></pre>

<pre><code>struct file_operations char8139_fops =
{
    owner: THIS_MODULE,
    read: char8139_read,
    ioctl: char8139_ioctl,
    open: char8139_open,
    release: char8139_release,
};
</code></pre>

<pre><code>
file_operations是每个字符设备驱动程序必须实现的系统调用，当用户对/dev中我们的设备对应结点进行操作时，linux就会调用我们驱动程序中提供的系统调用。比如用户敲入"cat /dev/char8139_0"命令，想想cat这个应用程序的实现，首先它肯定调用C语言库里的open()函数去打开/dev/char8139_0这个文件，到了系统这一层，系统会看到/dev/char8139_0不是普通磁盘文件，而是一个代表字符设备的节点，所以系统会根据/dev/char8139_0的主设备号来查找是不是已经有驱动程序使用这个相同的主设备号进行了注册，如果有，就调用驱动程序的open()实现。

为什么要这样干？因为要提供抽象，提供统一的接口，别忘了操作系统的作用之一就是这个。因为我们的设备提供的统一的接口，所以cat这个应用程序使用一般的文件操作就能从我们的设备中读出数据，
而且more, less这些应用程序都能从我们的设备中读出数据。

现在来看看我们的设备
</code></pre>

<pre><code>#define CHAR8139_BUFFER_SIZE 2000
unsigned char *buffer=NULL; /* driver data buffer */
unsigned char *p_buf;
unsigned int data_size=0;
</code></pre>

<pre><code>我们的设备很简单，一个2000字节的缓冲区， data_size指定缓冲区中有效数据的字节数。我们的设备只支持读不支持写。我们在char8139_init()中为缓冲区分配空间。

char8139_exit()里面的操作就是char8139_init()里面操作的反向操作。

现在我们来看看，假如用户调用了"cat /dev/char8139_3"这个命令会发生什么事情。

根据前面的介绍，我们驱动程序中的open()函数会被调用。
</code></pre>

<pre><code>int char8139_open(struct inode *node, struct file *flip)
{
    int type = MINOR(node-&gt;i_rdev)&gt;&gt;4;
    int num = MINOR(node-&gt;i_rdev) &amp; 0x0F;

    /* put some char in buffer to reflect the minor device number */
    *buffer=(unsigned char)('0');
    *(buffer+1)=(unsigned char)('x');
    *(buffer+2)=(unsigned char)('0'+type);
    *(buffer+3)=(unsigned char)('0'+num);
    *(buffer+4)=(unsigned char)('\n');
    data_size+=5;

    PDBG("Ok. Find treasure! 8139 I/O port base: %x\n", detect_8139_io_port());
    PDBG("OK. Find treasure! 8139 I/O memory base address: %lx\n",
    detect_8139_io_mem());

    MOD_INC_USE_COUNT;

    return 0;
}
</code></pre>

<pre><code>
这里演示了次设备号的作用，它让我们知道用户操作的是哪一个"次设备"，是/dev/char8139_0还是/dev/char8139_3，因为对不同的"次设备"，具体的操作方法可能是不一样的，这样就为一个驱动程序控制多个类似的设备提供了可能。

我们根据次设备号的不同，在buffer中填入不同的字符(次设备号的16进制表示)。

接着驱动程序中的read()函数会被调用，因为cat程序的实现就是读取文件中的内容。
</code></pre>

<pre><code>ssize_t char8139_read (struct file *filp, char *buf, size_t count, loff_t *f_pos)
{
    ssize_t ret=0;

    PDBG("copy to user. count=%d, f_pos=%ld\n", (int)count, (long)*f_pos);
    if (*f_pos&gt;= data_size)
        return ret;
    if (*f_pos + count &gt; data_size)
        count = data_size-*f_pos;
    if (copy_to_user(buf, p_buf, count))
    {
        PDBG("OOps, copy to user error.\n");
        return -EFAULT;
    }

    p_buf += count;
    *f_pos += count;
    ret = count;

    return ret;
}
</code></pre>

<p>```</p>

<p>要正确的实现一个read()调用，你得想一想一个应用程序是如何调用read()从文件中读取数据的。如果你想明白了就很简单，驱动程序所要做的就是把恰当的数据传递给应用程序，这是使用copy_to_user()函数完成的。</p>

<p>另外，我们必须得意识到，这里只是一个很简单的演示。还有很多复杂的问题有待考虑，比如两个应用程序可能同时打开我们设备，我们的设备应该怎样反应(这取决于具体的设备应有的行为)，还有互斥的问题。</p>

<p>然后我们看看I/O端口和I/O内存的操作。这里使用8139网卡作为一个硬件实例来演示I/O端口和I/O内存的操作。没有什么特别的，都是标准的步骤。在使用时需要注意，如果你的系统中已经有8139网卡的驱动程序，必须先关掉网络设备，卸载驱动，然后再使用本驱动程序。</p>

<p>使用程序包的步骤：(在我的Debian系统上如此，你的可能不同)<br/>
1. 解压<br/>
2. 编译(/usr/src/linux处必须要有内核源代码)<br/>
3. ifconfig eth0 down 关掉网络设备<br/>
rmmod 8139too 卸载原来的8139网卡驱动<br/>
insmod char8139.o 插入我们的模块<br/>
(insmod会出错， 如果你现在运行的linux版本不是你编译本驱动程序时使用的内核源代码的版本，insmod时会报告模块版本与内核版本不一致。这时，你得看看内核源代码中/include/linux/version.h文件，这个文件中的UTS_RELEASE定义了内核的版本号，你可以在驱动程序中预先定义这个宏为当前运行的内核的版本号，这样就能避免上述错误。)<br/>
4. mknode(见本文前述)<br/>
5. 试试我们的设备<br/>
./readtest<br/>
或者<br/>
cat /dev/char8139_0或<br/>
cat /dev/char8139_1或<br/>
cat /dev/char8139_2或<br/>
cat /dev/char8139_3<br/>
6. 恢复系统<br/>
rmmod char8139<br/>
modprobe 8139too<br/>
ifconfig eth0 up<br/>
如果你使用dhcp可能还需要运行dhclient</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ipv6初始化和处理流程分析]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/05/15/kernel-net-ipv6/"/>
    <updated>2015-05-15T15:57:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/05/15/kernel-net-ipv6</id>
    <content type="html"><![CDATA[<p><a href="/download/kernel/ipv6%E5%88%9D%E5%A7%8B%E5%8C%96%E5%92%8C%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B%E5%88%86%E6%9E%90.pdf">ipv6初始化和处理流程分析.pdf</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TCP的URG标志和内核实现]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/05/15/kernel-net-tcp_urg/"/>
    <updated>2015-05-15T13:51:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/05/15/kernel-net-tcp_urg</id>
    <content type="html"><![CDATA[<p><a href="http://blog.csdn.net/phenix_lord/article/details/42012931">TCP的URG标志和内核实现之一：协议</a><br/>
<a href="http://blog.csdn.net/phenix_lord/article/details/42046125">TCP的URG标志和内核实现之二：发送的实现</a><br/>
<a href="http://blog.csdn.net/phenix_lord/article/details/42065897">TCP的URG标志和内核实现之三：接收的实现</a></p>

<hr />

<h3>TCP的URG标志和内核实现之一：协议</h3>

<p>定义urgent数据的目的：<br/>
urgent机制，是用于通知应用层需要接收urgent data，在urgent data接收完成后，通知应用层urgent data数据接收完毕。相关协议文本RFC793 RFC1122 RFC6093</p>

<h4>哪些数据是urgent data？</h4>

<h5>协议规定</h5>

<p>在TCP报头的URG位有效的时候，通过TCP报头中的urgent pointer来标识urgent data的位置，但是在urgent pointer的解析方式上各个协议文本的描述有差异：</p>

<p>解读一：RFC793  P17，描述是“The urgent pointer points to the sequence number of the octet following the urgent data.”，在P41有描述“This mechanism permits a point in the data stream to be designated as the end of urgent information. Whenever this point is in advance of the receive sequence number (RCV.NXT) at the receiving TCP, that TCP must tell the user to go into &ldquo;urgent mode&rdquo;; when the receive sequence number catches up to the urgent pointer, the TCP must tell user to go”，可以认为是：当前接收的报文中SEQ在SEG.SEQ+Urgent Pointer之前的都是,而urgent pointer是第一个非urgent data（ TCP已经接受，但是还没有提交给应用的数据是不是呢？）</p>

<p>解读二：在P56的描述是“If the urgent flag is set, then SND.UP &lt;-SND.NXT-1 and set the urgent pointer in the outgoing segments”，也就是urgent pointer是最后一个urgent data字节。而在RFC1122中消除了这一歧义：在P84中说明“the urgent pointer points to the sequence number of the LAST octet (not LAST+1) in a sequence of urgent data”</p>

<h5>linux实现</h5>

<p>虽然在RFC1122中消除了这一歧义，linux仍然使用了解读一的解析方式，如果要使用解读二定义的方式，需要使用tcp_stdurg这个配置项。</p>

<h4>urgent data数据能有多长？</h4>

<h5>协议规定</h5>

<p>按照RFC793 P41的描述，长度不受限，RFC1122 P84中，更是明确了“A TCP MUST support a sequence of urgent data of any length”</p>

<h5>linux实现</h5>

<p>其实，linux只支持1BYTE的urgent data</p>

<h4>urgent data与OOB数据</h4>

<p>OOB数据说的是带外数据，也就是这些数据不是放到TCP流供读取的，而是通过额外的接口来获取，linux默认把urgent data实现为OOB数据；而按照协议的规定，urgent data不是out of band data</p>

<p>由于OOB数据的协议和实现上存在很多不确定因素，因此现在已经不建议使用了</p>

<hr />

<h3>TCP的URG标志和内核实现之二：发送的实现</h3>

<p>Linxu内核在默认情况下，把urgent data实现为OOB数据</p>

<h4>发送URG数据的接口</h4>

<p>在内核态，使用kernel_sendmsg/kernel_sendpage完成发送，只不过需要加上MSG_OOB标志，表示要发送的URG数据。</p>

<h4>URG数据发送接口的实现</h4>

<p>分片主要在kernel_sendmsg中完成，在OOB数据的处理上，它和kernel_sendpage是一致
```
    int tcp_sendmsg(struct kiocb <em>iocb, struct sock </em>sk, struct msghdr <em>msg,<br/>
            size_t size)<br/>
    {<br/>
        。。。。。。。。。。。。。。<br/>
        /</em>如果flags设置了MSG_OOB该接口其实返回的mss_now关闭了TSO功能<em>/<br/>
        mss_now = tcp_send_mss(sk, &amp;size_goal, flags);<br/>
        。。。。。。。。。。。。。。<br/>
        while (&ndash;iovlen >= 0) {<br/>
            size_t seglen = iov->iov_len;<br/>
            unsigned char __user </em>from = iov->iov_base;</p>

<pre><code>        iov++;  

        while (seglen &gt; 0) {  
            int copy = 0;  
            int max = size_goal;  

            skb = tcp_write_queue_tail(sk);  
            if (tcp_send_head(sk)) {  
                if (skb-&gt;ip_summed == CHECKSUM_NONE)  
                    max = mss_now;  
                copy = max - skb-&gt;len;  
            }  

            if (copy &lt;= 0) {  
new_segment:  
                /* Allocate new segment. If the interface is SG, 
                 * allocate skb fitting to single page. 
                 */  
                if (!sk_stream_memory_free(sk))  
                    goto wait_for_sndbuf;  

                skb = sk_stream_alloc_skb(sk,  
                              select_size(sk, sg),  
                              sk-&gt;sk_allocation);  
                if (!skb)  
                    goto wait_for_memory;  

                /* 
                 * Check whether we can use HW checksum. 
                 */  
                if (sk-&gt;sk_route_caps &amp; NETIF_F_ALL_CSUM)  
                    skb-&gt;ip_summed = CHECKSUM_PARTIAL;  

                skb_entail(sk, skb);  
                copy = size_goal;  
                max = size_goal;  
            }  

            /* Try to append data to the end of skb. */  
            if (copy &gt; seglen)  
                copy = seglen;  

            /* Where to copy to? */  
            if (skb_availroom(skb) &gt; 0) {  
                /* We have some space in skb head. Superb! */  
                copy = min_t(int, copy, skb_availroom(skb));  
                err = skb_add_data_nocache(sk, skb, from, copy);  
                if (err)  
                    goto do_fault;  
            } else {  
                int merge = 0;  
                int i = skb_shinfo(skb)-&gt;nr_frags;  
                struct page *page = sk-&gt;sk_sndmsg_page;  
                int off;  

                if (page &amp;&amp; page_count(page) == 1)  
                    sk-&gt;sk_sndmsg_off = 0;  

                off = sk-&gt;sk_sndmsg_off;  

                if (skb_can_coalesce(skb, i, page, off) &amp;&amp;  
                    off != PAGE_SIZE) {  
                    /* We can extend the last page 
                     * fragment. */  
                    merge = 1;  
                } else if (i == MAX_SKB_FRAGS || !sg) {  
                    /* Need to add new fragment and cannot 
                     * do this because interface is non-SG, 
                     * or because all the page slots are 
                     * busy. */  
                    tcp_mark_push(tp, skb);  
                    goto new_segment;  
                } else if (page) {  
                    if (off == PAGE_SIZE) {  
                        put_page(page);  
                        sk-&gt;sk_sndmsg_page = page = NULL;  
                        off = 0;  
                    }  
                } else  
                    off = 0;  

                if (copy &gt; PAGE_SIZE - off)  
                    copy = PAGE_SIZE - off;  
                if (!sk_wmem_schedule(sk, copy))  
                    goto wait_for_memory;  

                if (!page) {  
                    /* Allocate new cache page. */  
                    if (!(page = sk_stream_alloc_page(sk)))  
                        goto wait_for_memory;  
                }  

                /* Time to copy data. We are close to 
                 * the end! */  
                err = skb_copy_to_page_nocache(sk, from, skb,  
                                   page, off, copy);  
                if (err) {  
                    /* If this page was new, give it to the 
                     * socket so it does not get leaked. 
                     */  
                    if (!sk-&gt;sk_sndmsg_page) {  
                        sk-&gt;sk_sndmsg_page = page;  
                        sk-&gt;sk_sndmsg_off = 0;  
                    }  
                    goto do_error;  
                }  

                /* Update the skb. */  
                if (merge) {  
                    skb_frag_size_add(&amp;skb_shinfo(skb)-&gt;frags[i - 1], copy);  
                } else {  
                    skb_fill_page_desc(skb, i, page, off, copy);  
                    if (sk-&gt;sk_sndmsg_page) {  
                        get_page(page);  
                    } else if (off + copy &lt; PAGE_SIZE) {  
                        get_page(page);  
                        sk-&gt;sk_sndmsg_page = page;  
                    }  
                }  

                sk-&gt;sk_sndmsg_off = off + copy;  
            }  

            if (!copied)  
                TCP_SKB_CB(skb)-&gt;tcp_flags &amp;= ~TCPHDR_PSH;  

            tp-&gt;write_seq += copy;  
            TCP_SKB_CB(skb)-&gt;end_seq += copy;  
            skb_shinfo(skb)-&gt;gso_segs = 0;  

            from += copy;  
            copied += copy;  
            if ((seglen -= copy) == 0 &amp;&amp; iovlen == 0)  
                goto out;  
            /*对于OOB数据，即使一个分片用光，如果还有 
            send_buff和OOB数据，就继续积累分片*/  
            if (skb-&gt;len &lt; max || (flags &amp; MSG_OOB))  
                continue;  

            if (forced_push(tp)) {  
                tcp_mark_push(tp, skb);  
                __tcp_push_pending_frames(sk, mss_now, TCP_NAGLE_PUSH);  
            } else if (skb == tcp_send_head(sk))  
                tcp_push_one(sk, mss_now);  
            continue;  

wait_for_sndbuf:  
            set_bit(SOCK_NOSPACE, &amp;sk-&gt;sk_socket-&gt;flags);  
wait_for_memory:  
            if (copied)  
                tcp_push(sk, flags &amp; ~MSG_MORE, mss_now, TCP_NAGLE_PUSH);  

            if ((err = sk_stream_wait_memory(sk, &amp;timeo)) != 0)  
                goto do_error;  

            mss_now = tcp_send_mss(sk, &amp;size_goal, flags);  
        }  
    }  

out:  
    if (copied)  
        tcp_push(sk, flags, mss_now, tp-&gt;nonagle);  
    release_sock(sk);  
    return copied;  

do_fault:  
    if (!skb-&gt;len) {  
        tcp_unlink_write_queue(skb, sk);  
        /* It is the one place in all of TCP, except connection 
         * reset, where we can be unlinking the send_head. 
         */  
        tcp_check_send_head(sk, skb);  
        sk_wmem_free_skb(sk, skb);  
    }  

do_error:  
    if (copied)  
        goto out;  
out_err:  
    err = sk_stream_error(sk, flags, err);  
    release_sock(sk);  
    return err;  
}  
</code></pre>

<pre><code>
tcp_sendmsg中，涉及对OOB数据的处理主要有：

##### 1、在调用tcp_send_mss确定分片大小的时候：
</code></pre>

<pre><code>static int tcp_send_mss(struct sock *sk,int *size_goal, int flags)
{
    intmss_now;
    mss_now= tcp_current_mss(sk);

    /*如果是OOB数据，large_allowed=0，关闭TSO*/
    *size_goal= tcp_xmit_size_goal(sk, mss_now, !(flags &amp; MSG_OOB));
    returnmss_now;
}
</code></pre>

<pre><code>如果是OOB数据，其实是关闭了TSO功能，这样做的原因是：天知道各个网卡芯片在执行分片的时候咋个处理TCP报头中的URG标志和urgent point

##### 2、在确定何时开始执行分片的发送的时候：

如果是OOB数据，即使当前已经积累了一整个分片，也不会想普通的数据一样执行发送(tcp_push)，而是继续积累直到用户下发的数据全部分片或者snd_buf/内存用尽。

##### 3、执行tcp_push的时候：

在用户下发的数据全部分片或者snd_buf/内存用尽后，进入tcp_push执行发送操作(所有的OOB数据，都会通过这个接口来执行发送)
</code></pre>

<pre><code>static inline void tcp_push(struct sock*sk, int flags, int mss_now,
                         int nonagle)
{
    if(tcp_send_head(sk)) {
        structtcp_sock *tp = tcp_sk(sk);
        if(!(flags &amp; MSG_MORE) || forced_push(tp))
            tcp_mark_push(tp,tcp_write_queue_tail(sk));    
              /*tcp_mark_urg设置tp-&gt;snd_up，标识进入OOB数据发送模式，设置urgent point
              指向urgentdata接受后的第一个字符*/
        tcp_mark_urg(tp,flags);
        __tcp_push_pending_frames(sk,mss_now,
                      (flags &amp; MSG_MORE) ? TCP_NAGLE_CORK :nonagle);
    }
}
</code></pre>

<pre><code>
#### 发送处理

使用struct tcp_sock中的snd_up来标识当前的urgent point，同时也使用该数据来判断当前是否处于urgent data发送模式，在普通数据的发送模式中tcp_sock::snd_up总是和tcp_sock::snd_una相等，只有在有urgent data发送的时候，才在tcp_push---&gt;tcp_mark_urg中设置为urgentpoint，进入到urgent data的处理模式

在tcp_transmit_skb中的以下代码段负责urgent data相关的处理：
</code></pre>

<pre><code>if (unlikely(tcp_urg_mode(tp) &amp;&amp; before(tcb-&gt;seq, tp-&gt;snd_up))) {  
    if (before(tp-&gt;snd_up, tcb-&gt;seq + 0x10000)) {  
        th-&gt;urg_ptr = htons(tp-&gt;snd_up - tcb-&gt;seq);  
        th-&gt;urg = 1;  
    } else if (after(tcb-&gt;seq + 0xFFFF, tp-&gt;snd_nxt)) {  
        th-&gt;urg_ptr = htons(0xFFFF);  
        th-&gt;urg = 1;  
    }  
}  
</code></pre>

<pre><code>
只要当前待发送的skb的seq在tcp_sock记录的urgent point前面，就需要在报头中对URG标志置位，同时如果tcp_sock记录的urgent point。如果该报文的seq距离大于16为能表示的最大值，就置TCP报头中的urgent point为65535。

#### 切换回普通模式：

在收到对方ACK的处理流程tcp_ack---&gt;tcp_clean_rtx_queue中：
</code></pre>

<pre><code>if (likely(between(tp-&gt;snd_up, prior_snd_una, tp-&gt;snd_una)))  
    tp-&gt;snd_up = tp-&gt;snd_una;  
</code></pre>

<pre><code>
#### 报文体现
根据对发送代码的分析，可以看到：如果用户使用MSG_OOB数据发送一段比较长(若干个MSS)的数据，那么线路上的报文应该是分成了若干组，每组由若干个长度为MSS的报文构成，组内的每个报文有一样的urgent pointer，指向下一组报文的起始seq，每一组的长度最长为65535。

----------
### TCP的URG标志和内核实现之三：接收的实现

大致的处理过程

TCP的接收流程：在tcp_v4_do_rcv中的相关处理(网卡收到报文触发)中，会首先通过tcp_check_urg设置tcp_sock的urg_data为TCP_URG_NOTYET(urgent point指向的可能不是本报文，而是后续报文或者前面收到的乱序报文)，并保存最新的urgent data的sequence和对于的1 BYTE urgent data到tcp_sock的urg_data (如果之前的urgent data没有读取，就会被覆盖)。

用户接收流程：在tcp_recvmsg流程中，如果发现当前的skb的数据中有urgent data，首先拷贝urgent data之前的数据，然后tcp_recvmsg退出，提示用户来接收OOB数据；在用户下一次调用tcp_recvmsg来接收数据的时候，会跳过urgent data，并设置urgent data数据接收完成。
相关的数据结构和定义

tcp_sock结构：

1、 urg_data成员，其高8bit为urgent data的接收状态；其低8位为保存的1BYTE urgent数据。urgent data的接收状态对应的宏的含义描述：
</code></pre>

<pre><code>#defineTCP_URG_VALID    0x0100  /*urgent data已经读到了tcp_sock::urg_data*/

#defineTCP_URG_NOTYET   0x0200  /*已经发现有urgent data，还没有读取到tcp_sock::urg_data*/

#defineTCP_URG_READ     0x0400  /*urgent data已经被用户通过MSG_OOB读取了*/
</code></pre>

<pre><code>
2、 urg_seq成员，为当前的urgent data的sequence

流程详情

#### TCP的接收过程

在tcp_rcv_established的slow_path中
</code></pre>

<pre><code>slow_path:  
    if (len &lt; (th-&gt;doff &lt;&lt; 2) || tcp_checksum_complete_user(sk, skb))  
        goto csum_error;  
    /* 
     *  Standard slow path. 
     */  
    if (!tcp_validate_incoming(sk, skb, th, 1))  
        return 0;  
step5:  
    if (th-&gt;ack &amp;&amp;  
        tcp_ack(sk, skb, FLAG_SLOWPATH | FLAG_UPDATE_TS_RECENT) &lt; 0)  
        goto discard;  
    tcp_rcv_rtt_measure_ts(sk, skb);  
    /* 处理紧急数据. */  
    tcp_urg(sk, skb, th);  
</code></pre>

<pre><code>
也就是在报文的CRC验证和sequence验证完成后，就会通过tcp_urg来处理接收到的urgent data ：
</code></pre>

<pre><code>static void tcp_urg(struct sock *sk, struct sk_buff *skb, const struct tcphdr *th)  
{  
    struct tcp_sock *tp = tcp_sk(sk);  

    /*收到了urgent data,则检查和设置urg_data和urg_seq成员*/  
    if (th-&gt;urg)  
        tcp_check_urg(sk, th);  

    /* Do we wait for any urgent data? - normally not... 
    发现了有urgent data，但是还没有保存到tp-&gt;urg_data*/  
    if (tp-&gt;urg_data == TCP_URG_NOTYET) {  
        u32 ptr = tp-&gt;urg_seq - ntohl(th-&gt;seq) + (th-&gt;doff * 4) -  
              th-&gt;syn;  

        /* Is the urgent pointer pointing into this packet? */  
        if (ptr &lt; skb-&gt;len) {  
            u8 tmp;  
            if (skb_copy_bits(skb, ptr, &amp;tmp, 1))  
                BUG();  
            tp-&gt;urg_data = TCP_URG_VALID | tmp;  
            if (!sock_flag(sk, SOCK_DEAD))  
                sk-&gt;sk_data_ready(sk, 0);  
        }  
    }  
}  
</code></pre>

<pre><code>
检查和设置urg_data和urg_seq成员的处理函数tcp_check_urg的具体流程
</code></pre>

<pre><code>static void tcp_check_urg(struct sock *sk, const struct tcphdr *th)  
{  
    struct tcp_sock *tp = tcp_sk(sk);  
    u32 ptr = ntohs(th-&gt;urg_ptr);  
    /*两种urgent point的解析方式: 
    一是指向urgent data之后的第一个字节 
    二是执行urgent data的结束字节(RFC1122) 
    sysctl_tcp_stdurg被设置表示当前采用的是第二种模式 
    不需要把urgent point -1来指向urgent data的结束字节*/  
    if (ptr &amp;&amp; !sysctl_tcp_stdurg)  
        ptr--;  
    ptr += ntohl(th-&gt;seq);  

    /* Ignore urgent data that we've already seen and read.  
    如果copied_seq已经大于urgent point，那么对于从tcp_rcv_established 
    来执行的，前面的tcp_validate_incoming已经拒绝了这种报文( 
    接收窗口外)，这里要处理的是哪种情形?*/  
    if (after(tp-&gt;copied_seq, ptr))  
        return;  

    /* Do not replay urg ptr. 
     * 
     * NOTE: interesting situation not covered by specs. 
     * Misbehaving sender may send urg ptr, pointing to segment, 
     * which we already have in ofo queue. We are not able to fetch 
     * such data and will stay in TCP_URG_NOTYET until will be eaten 
     * by recvmsg(). Seems, we are not obliged to handle such wicked 
     * situations. But it is worth to think about possibility of some 
     * DoSes using some hypothetical application level deadlock. 
     */  
    /*  这种情况什么时候发生?没搞明白*/  
    if (before(ptr, tp-&gt;rcv_nxt))  
        return;  

    /* Do we already have a newer (or duplicate) urgent pointer?  
    如果当前已经进入urg数据读取模式，且urgent point不大于当前 
    保存的值，那么之前已经开始了读取tp-&gt;urg_seq对应的 
    urgent 数据，无需重复处理了*/  
    if (tp-&gt;urg_data &amp;&amp; !after(ptr, tp-&gt;urg_seq))  
        return;  

    /* Tell the world about our new urgent pointer.*/  
    sk_send_sigurg(sk);  

    /* We may be adding urgent data when the last byte read was 
     * urgent. To do this requires some care. We cannot just ignore 
     * tp-&gt;copied_seq since we would read the last urgent byte again 
     * as data, nor can we alter copied_seq until this data arrives 
     * or we break the semantics of SIOCATMARK (and thus sockatmark()) 
     * 
     * NOTE. Double Dutch. Rendering to plain English: author of comment 
     * above did something sort of  send("A", MSG_OOB); send("B", MSG_OOB); 
     * and expect that both A and B disappear from stream. This is _wrong_. 
     * Though this happens in BSD with high probability, this is occasional. 
     * Any application relying on this is buggy. Note also, that fix "works" 
     * only in this artificial test. Insert some normal data between A and B and we will 
     * decline of BSD again. Verdict: it is better to remove to trap 
     * buggy users. 
     */  
     /*用户下一次要读取的数据就是用户还没有读取的urgent数据 
    且当前存在新的用户未读取数据*/  
    if (tp-&gt;urg_seq == tp-&gt;copied_seq &amp;&amp; tp-&gt;urg_data &amp;&amp;  
        !sock_flag(sk, SOCK_URGINLINE) &amp;&amp; tp-&gt;copied_seq != tp-&gt;rcv_nxt) {  
        struct sk_buff *skb = skb_peek(&amp;sk-&gt;sk_receive_queue);  
        tp-&gt;copied_seq++;  
        if (skb &amp;&amp; !before(tp-&gt;copied_seq, TCP_SKB_CB(skb)-&gt;end_seq)) {  
            __skb_unlink(skb, &amp;sk-&gt;sk_receive_queue);  
            __kfree_skb(skb);  
        }  
    }  

    tp-&gt;urg_data = TCP_URG_NOTYET;  
    tp-&gt;urg_seq = ptr;  

    /* Disable header prediction. */  
    tp-&gt;pred_flags = 0;  
}  
</code></pre>

<pre><code>
#### 用户接收数据接口
##### 用户接收URG数据的接口
在用户接收数据的tcp_recvmsg函数中，如果用户通过MSG_OOB来接收数据，会进入tcp_recv_urg处理
</code></pre>

<pre><code>static int tcp_recv_urg(struct sock *sk, struct msghdr *msg, int len, int flags)  
{  
    struct tcp_sock *tp = tcp_sk(sk);  

    /* No URG data to read.  
    用户已经读取过了*/  
    if (sock_flag(sk, SOCK_URGINLINE) || !tp-&gt;urg_data ||  
        tp-&gt;urg_data == TCP_URG_READ)  
        return -EINVAL; /* Yes this is right ! */  

    if (sk-&gt;sk_state == TCP_CLOSE &amp;&amp; !sock_flag(sk, SOCK_DONE))  
        return -ENOTCONN;  
    /*当前的tp-&gt;urg_data为合法的数据，可以读取*/  
    if (tp-&gt;urg_data &amp; TCP_URG_VALID) {  
        int err = 0;  
        char c = tp-&gt;urg_data;  
        /*标识urgent data已读*/  
        if (!(flags &amp; MSG_PEEK))  
            tp-&gt;urg_data = TCP_URG_READ;  

        /* Read urgent data. */  
        msg-&gt;msg_flags |= MSG_OOB;  

        if (len &gt; 0) {  
            if (!(flags &amp; MSG_TRUNC))  
                err = memcpy_toiovec(msg-&gt;msg_iov, &amp;c, 1);  
            len = 1;  
        } else  
            msg-&gt;msg_flags |= MSG_TRUNC;  

        return err ? -EFAULT : len;  
    }  

    if (sk-&gt;sk_state == TCP_CLOSE || (sk-&gt;sk_shutdown &amp; RCV_SHUTDOWN))  
        return 0;  

    /* Fixed the recv(..., MSG_OOB) behaviour.  BSD docs and 
     * the available implementations agree in this case: 
     * this call should never block, independent of the 
     * blocking state of the socket. 
     * Mike &lt;pall@rz.uni-karlsruhe.de&gt; 
     */  
    return -EAGAIN;  
}  
</code></pre>

<pre><code>
##### 用户接收普通数据的接口中的相关处理

在用户接收数据的tcp_recvmsg函数中，在查找到待拷贝的skb后，首先拷贝urgent data数据前的数据，然后退出接收过程，在用户下一次执行tcp_recvmsg的时候跳过urgent data，设置urgent data读取结束

查找到准备拷贝的skb后的处理：
</code></pre>

<pre><code>found_ok_skb:  
/* Ok so how much can we use? */  
used = skb-&gt;len - offset;  
if (len &lt; used)  
    used = len;  

/* 当前有urg_data数据*/  
if (tp-&gt;urg_data) {  
    u32 urg_offset = tp-&gt;urg_seq - *seq;  
    /*urgent data在当前待拷贝的数据范围内*/  
    if (urg_offset &lt; used) {  
        if (!urg_offset) {/*待拷贝的数据就是urgent data，跨过该urgent data， 
        只给用户读取后面的数据*/  
            if (!sock_flag(sk, SOCK_URGINLINE)) {  
                ++*seq;  
                urg_hole++;  
                offset++;  
                used--;  
                if (!used)  
                    goto skip_copy;  
            }  
        }   
        } else/*指定只拷贝urgent data数据之前的，完成后在下一次循环 
        开始的位置，会退出循环，返回用户；下一次用户调用tcp_recvmsg 
        就进入到上面的分支了*/  
            used = urg_offset;  
    }  
}   
</code></pre>

<pre><code></code></pre>

<pre><code>skip_copy:  
        /*用户读取的数据跨过了urgent point，设置读取结束 
        开启fast path*/  
        if (tp-&gt;urg_data &amp;&amp; after(tp-&gt;copied_seq, tp-&gt;urg_seq)) {  
            tp-&gt;urg_data = 0;  
            tcp_fast_path_check(sk);  
        }  
        if (used + offset &lt; skb-&gt;len)  
            continue;  
</code></pre>

<pre><code>
在接收完urgent data数据前的所有数据之后， tcp_recvmsg的以下代码片段得到执行，这段代码退出当前接收过程，提示用户有urgent data数据到来，需要用MSG_OOB来接收
</code></pre>

<pre><code>if (tp-&gt;urg_data &amp;&amp; tp-&gt;urg_seq == *seq) {  
    if (copied)  
        break;  
    if (signal_pending(current)) {  
        copied = timeo ? sock_intr_errno(timeo) : -EAGAIN;  
        break;  
    }  
}  
</code></pre>

<p>```</p>

<h3>后记</h3>

<p>TCP的urg数据，由于定义和实现上的混乱，当前已经不建议使用，但是为了兼容之前已经已经存在的实现，该机制会长期在内核中存在，如果不了解该机制及其内核行为，有可能就很难解释一些奇怪的问题：比如某段代码不小心地造成send接口事实上设置了MSG_OOB，就会造成接收端少了一个BYTE。</p>
]]></content>
  </entry>
  
</feed>
