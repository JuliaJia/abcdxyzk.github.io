<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: debug~mark | kk Blog —— 通用基础]]></title>
  <link href="http://abcdxyzk.github.io/blog/cats/debug~mark/atom.xml" rel="self"/>
  <link href="http://abcdxyzk.github.io/"/>
  <updated>2015-05-07T16:25:21+08:00</updated>
  <id>http://abcdxyzk.github.io/</id>
  <author>
    <name><![CDATA[kk]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[拥塞控制模块注意]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/04/15/debug-mark-cong/"/>
    <updated>2015-04-15T14:24:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/04/15/debug-mark-cong</id>
    <content type="html"><![CDATA[<h4>应用改变sock的拥塞控制算法</h4>

<pre><code>    #define SOL_TCP 6
    #define TCP_CONGESTION  13

    strcpy(name, "cubic");
    setsockopt (connfd, SOL_TCP, TCP_CONGESTION, name, strlen(name));
</code></pre>

<h5>net/socket.c</h5>

<pre><code>    SYSCALL_DEFINE5(setsockopt, int, fd, int, level, int, optname,
            char __user *, optval, int, optlen)
    {
        ...
                err =
                    sock-&gt;ops-&gt;setsockopt(sock, level, optname, optval,
                              optlen);
        ...
    }
</code></pre>

<p>对于ipv4的tcp，sock->ops指向 net/ipv4/af_inet.c 中的 inet_stream_ops，所以setsockopt等于sock_common_setsockopt。</p>

<h5>net/core/sock.c</h5>

<pre><code>    int sock_common_setsockopt(struct socket *sock, int level, int optname,
                   char __user *optval, unsigned int optlen)
    {
        struct sock *sk = sock-&gt;sk;

        return sk-&gt;sk_prot-&gt;setsockopt(sk, level, optname, optval, optlen);
    }
</code></pre>

<p>sk_prot 指向 net/ipv4/tcp_ipv4.c 中的 tcp_prot，所以setsockopt等于tcp_setsockopt</p>

<h5>net/ipv4/tcp.c</h5>

<pre><code>    int tcp_setsockopt(struct sock *sk, int level, int optname, char __user *optval,
               unsigned int optlen)
    {
        struct inet_connection_sock *icsk = inet_csk(sk);

        if (level != SOL_TCP)
            return icsk-&gt;icsk_af_ops-&gt;setsockopt(sk, level, optname,
                                 optval, optlen);
        return do_tcp_setsockopt(sk, level, optname, optval, optlen);
    }
</code></pre>

<p>因为level = SOL_TCP, optname = TCP_CONGESTION, 所以直接到do_tcp_setsockopt的第一个if里。</p>

<pre><code>    static int do_tcp_setsockopt(struct sock *sk, int level,
            int optname, char __user *optval, unsigned int optlen)
    {
        struct tcp_sock *tp = tcp_sk(sk);
        struct inet_connection_sock *icsk = inet_csk(sk); 
        int val;      
        int err = 0;

        /* This is a string value all the others are int's */
        if (optname == TCP_CONGESTION) {      
            char name[TCP_CA_NAME_MAX]; 

            if (optlen &lt; 1)
                return -EINVAL;

            val = strncpy_from_user(name, optval,
                        min_t(long, TCP_CA_NAME_MAX-1, optlen));
            if (val &lt; 0)
                return -EFAULT;
            name[val] = 0;

            lock_sock(sk);
            err = tcp_set_congestion_control(sk, name);
            release_sock(sk);
            return err;
        }

    ...
</code></pre>

<h4>net/ipv4/tcp_cong.c</h4>

<pre><code>    /* Change congestion control for socket */
    int tcp_set_congestion_control(struct sock *sk, const char *name)
    {
        struct inet_connection_sock *icsk = inet_csk(sk);
        struct tcp_congestion_ops *ca;
        int err = 0;

        rcu_read_lock();
        ca = tcp_ca_find(name);

        /* no change asking for existing value */
        if (ca == icsk-&gt;icsk_ca_ops)
            goto out;

    #ifdef CONFIG_MODULES
        /* not found attempt to autoload module */
        if (!ca &amp;&amp; capable(CAP_NET_ADMIN)) {
            rcu_read_unlock();
            request_module("tcp_%s", name);
            rcu_read_lock();
            ca = tcp_ca_find(name);
        }
    #endif
        if (!ca)
            err = -ENOENT;

        else if (!((ca-&gt;flags &amp; TCP_CONG_NON_RESTRICTED) || capable(CAP_NET_ADMIN)))
            err = -EPERM;

        else if (!try_module_get(ca-&gt;owner))
            err = -EBUSY;

        else {
            tcp_cleanup_congestion_control(sk);
            icsk-&gt;icsk_ca_ops = ca;

            if (sk-&gt;sk_state != TCP_CLOSE &amp;&amp; icsk-&gt;icsk_ca_ops-&gt;init) // 如果sk-&gt;sk_state = TCP_CLOSE, 那么不会调用拥塞控制模块的初始化
                icsk-&gt;icsk_ca_ops-&gt;init(sk);
        }
     out:
        rcu_read_unlock();
        return err;
    }
</code></pre>

<p>可以看到，如果sk->sk_state = TCP_CLOSE, 那么不会调用拥塞控制模块的初始化。</p>

<hr />

<h4>那么什么时候sk->sk_state == TCP_CLOSE，并且还能调用setsockopt呢？</h4>

<h5>举一种情况：当收到RST包的时候，tcp_rcv_established()->tcp_validate_incoming()->tcp_reset()->tcp_done()将sk置为TCP_CLOSE。</h5>

<h5>如果拥塞控制模块中init有申请内存，release中释放内存。那么在上述情况下将会出现没有申请而直接释放的情况，导致panic。</h5>

<pre><code>    BUG: unable to handle kernel paging request at ffffeba4000002a0

    [&lt;ffffffff8115b17e&gt;] kfree+0x6e/0x240
    [&lt;ffffffffa0068055&gt;] cong_release+0x35/0x50 [cong]
    [&lt;ffffffff81467953&gt;] tcp_cleanup_congestion_control+0x23/0x40
    [&lt;ffffffff81465bb9&gt;] tcp_v4_destroy_sock+0x29/0x2d0
    [&lt;ffffffff8144e9e3&gt;] inet_csk_destroy_sock+0x53/0x140
    [&lt;ffffffff814504c0&gt;] tcp_close+0x340/0x4a0
    [&lt;ffffffff814748de&gt;] inet_release+0x5e/0x90
    [&lt;ffffffff813f4359&gt;] sock_release+0x29/0x90
    [&lt;ffffffff813f43d7&gt;] sock_close+0x17/0x40
    [&lt;ffffffff81173ed3&gt;] __fput+0xf3/0x220
    [&lt;ffffffff8117401c&gt;] fput+0x1c/0x30
    [&lt;ffffffff8116df2d&gt;] filp_close+0x5d/0x90
    [&lt;ffffffff8117090c&gt;] sys_close+0xac/0x110
    [&lt;ffffffff8100af72&gt;] system_call_fastpath+0x16/0x1b
</code></pre>

<h4>测试代码</h4>

<p><a href="/download/debug/congestion_mod_panic.tar.gz">congestion_mod_panic</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mod_timer会切换cpu]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/01/14/debug-mod-timer/"/>
    <updated>2015-01-14T23:59:01+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/01/14/debug-mod-timer</id>
    <content type="html"><![CDATA[<p><a href="https://lkml.org/lkml/2009/4/16/45">https://lkml.org/lkml/2009/4/16/45</a></p>

<blockquote><p>Ingo, Thomas, all,</p>

<p>In an SMP system, tasks are scheduled on different CPUs by the
scheduler, interrupts are managed by irqbalancer daemon, but timers
are still stuck to the CPUs that they have been initialised.  Timers
queued by tasks gets re-queued on the CPU where the task gets to run
next, but timers from IRQ context like the ones in device drivers are
still stuck on the CPU they were initialised.  This framework will
help move all &lsquo;movable timers&rsquo; using a sysctl interface.</p></blockquote>

<p>kernel/timer.c 中 __mod_timer函数的部分patch：
<code>
+   cpu = smp_processor_id();
+   if (get_sysctl_timer_migration() &amp;&amp; idle_cpu(cpu) &amp;&amp; !pinned) {
+#if defined(CONFIG_NO_HZ) &amp;&amp; (CONFIG_SMP)
+       preferred_cpu = get_nohz_load_balancer();
+#endif
+       if (preferred_cpu &gt;= 0)
+           cpu = preferred_cpu;
+   }
+
+   new_base = per_cpu(tvec_bases, cpu);
+
</code></p>

<hr />

<p>也就是说：如果当前进程是idle（函数idle_cpu(cpu)判定），那么在mod_timer时会根据cpu的struct rq runqueues;中的 struct sched_domain *sd; 来选一个不是idle的cpu，然后把timer移到他上去。如果都是idle，就还在本cpu。<br/>
禁用该功能可以 echo 0 > /proc/sys/kernel/timer_magration，默认的启用是1。</p>

<p>也就是说：系统默认状态下mod_timer有可能会mod_timer到其他cpu上。</p>

<hr />

<p>但是基本只有softirq时（如 <a href="/blog/2015/01/14/debug-softirq-time-count/">/blog/2015/01/14/debug-softirq-time-count/</a>），这时会的当前进程就是idle，但cpu实际并不空闲。这样的话softirq的timer在mod_timer时，会被加到其他cpu的定时器队列。如果这些timer是不允许切换cpu的（如对per_cpu变量的操作），那么就会产生bug。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[中断时间统计]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/01/14/debug-softirq-time-count/"/>
    <updated>2015-01-14T23:59:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/01/14/debug-softirq-time-count</id>
    <content type="html"><![CDATA[<p>软中断运行在中断上下文，不会被抢占调度，只会被硬中断打断，但硬中断退出时还是继续执行没结束的软中断。</p>

<p>因为软中断不是运行在进程上下文，不具备被调度的前提，也不具备统计运行时间。系统是将softirq的时间加到当前被他打断的进程上（还是不统计softirq时间？？？有待学习）。</p>

<p>如果当前系统只运行数据包的接收服务，那么系统很可能显示的是100%idle，因为被softirq打断的进程就是idle。</p>

<p>如果softirq足够多，导致启动了ksoftirqd进程来协助处理，那么softirq的时间会被记到ksoftirqd的进程上，显示有“有点正常”了。</p>

<p>这样就会出现：当cpu个数充足时显示100%idle，然后减少到一半cpu就显示X%si。也就是说显示100%idle是不对，应该是近似的(x/2)%si</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[高精度定时器 high-cpu-load]]></title>
    <link href="http://abcdxyzk.github.io/blog/2014/11/06/debug-mark-sleep/"/>
    <updated>2014-11-06T14:30:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2014/11/06/debug-mark-sleep</id>
    <content type="html"><![CDATA[<p><a href="http://stackoverflow.com/questions/1125297/nanosleep-high-cpu-usage">http://stackoverflow.com/questions/1125297/nanosleep-high-cpu-usage</a></p>

<p>I noticed that a little test program which calls nanosleep is showing a huge difference in CPU usage when run on Linux machines with a kernel newer than 2.6.22.
<code>
    #include &lt;time.h&gt;
    int main (void)
    {
        struct timespec sleepTime;
        struct timespec returnTime;
        sleepTime.tv_sec = 0;
        sleepTime.tv_nsec = 1000;
        while (1)
        {
            nanosleep(&amp;sleepTime, &amp;returnTime); // usleep(1); 同样异常
        }
        return 0;
    }
</code>
(Yes, I realise this program does nothing)</p>

<p>  If I compile this and run it on an openSUSE 10.3 machine (2.6.22.19-0.2-default), the program does not even show up on the process list generated by &ldquo;top&rdquo;, indicating to me that it is using very little CPU time.  If I run it on an openSUSE 11.1 machine (2.6.27.23-0.1-default), top shows the program taking 40% of the CPU time.  Running on Fedora 9 (2.6.25-14.fc9.i686) and Fedora 10 also showed the same high CPU usage in &ldquo;top&rdquo;.</p>

<p>Has there been a change in the kernel that affects this?</p>

<hr />

<h4>Answers</h4>

<p>This is due to the introduction of NO_HZ into the mainline scheduler.</p>

<p>Previously, your 1,000 ns sleep was usually sleeping for a whole tick - 1,000,000 ns.  Now, when the machine is otherwise idle, it&rsquo;s actually only sleeping for what you asked for.  So it&rsquo;s running the while() loop and syscall around 1,000 times more frequently - hence a lot more CPU usage.  If you increase tv_nsec you should see a reduction in the CPU usage.</p>

<hr />

<pre><code>    int nanosleep(const struct timespec *req, struct timespec *rem);

    struct timespec
    {
        time_t  tv_sec;         /* seconds */
        long    tv_nsec;        /* nanoseconds */
    };
</code></pre>

<p> 这个函数功能是暂停某个进程直到你规定的时间后恢复，参数req就是你要暂停的时间，其中req->tv_sec是以秒为单位，而tv_nsec以毫 微秒为单位（10的-9次方秒）。由于调用nanosleep是是进程进入TASK_INTERRUPTIBLE,这种状态是会相应信号而进入 TASK_RUNNING状态的，这就意味着有可能会没有等到你规定的时间就因为其它信号而唤醒，此时函数返回-1，切还剩余的时间会被记录在rem中。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Bash软件安全漏洞检测及解决方案]]></title>
    <link href="http://abcdxyzk.github.io/blog/2014/09/26/debug-mark-bash/"/>
    <updated>2014-09-26T10:16:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2014/09/26/debug-mark-bash</id>
    <content type="html"><![CDATA[<p><a href="http://www.techweb.com.cn/ucweb/news/id/2079505">http://www.techweb.com.cn/ucweb/news/id/2079505</a></p>

<h4>redhat官方提供漏洞详情</h4>

<p>A flaw was found in the way Bash evaluated certain specially crafted environment variables. An attacker could use this flaw to override or bypass environment restrictions to execute shell commands. Certain services and applications allow remote unauthenticated attackers to provide environment variables, allowing them to exploit this issue.</p>

<h4>redhat官方提供检测方式</h4>

<p>运行命令：<br/>
<code>
  $ env x='() { :;}; echo vulnerable'  bash -c "echo this is a test"
</code>
如果返回以下内容：则请尽快升级。
<code>
 vulnerable
this is a test
</code></p>

<hr />

<p><a href="http://seclists.org/oss-sec/2014/q3/650">http://seclists.org/oss-sec/2014/q3/650</a></p>

<p>The technical details of the vulnerability follow.</p>

<p>Bash supports exporting not just shell variables, but also shell
functions to other bash instances, via the process environment to
(indirect) child processes.  Current bash versions use an environment
variable named by the function name, and a function definition
starting with “() {” in the variable value to propagate function
definitions through the environment.  The vulnerability occurs because
bash does not stop after processing the function definition; it
continues to parse and execute shell commands following the function
definition.  For example, an environment variable setting of
<code>
  VAR=() { ignored; }; /bin/id
</code>
will execute /bin/id when the environment is imported into the bash
process.  (The process is in a slightly undefined state at this point.
The PATH variable may not have been set up yet, and bash could crash
after executing /bin/id, but the damage has already happened at this
point.)</p>

<p>The fact that an environment variable with an arbitrary name can be
used as a carrier for a malicious function definition containing
trailing commands makes this vulnerability particularly severe; it
enables network-based exploitation.</p>

<p>So far, HTTP requests to CGI scripts have been identified as the major
attack vector.</p>

<p>A typical HTTP request looks like this:
<code>
GET /path?query-param-name=query-param-value HTTP/1.1  
Host: www.example.com  
Custom: custom-header-value  
</code>
The CGI specification maps all parts to environment variables.  With
Apache httpd, the magic string “() {” can appear in these places:</p>

<ul>
<li>Host (“www.example.com”, as REMOTE_HOST)</li>
<li>Header value (“custom-header-value”, as HTTP_CUSTOM in this example)</li>
<li>Server protocol (“HTTP/1.1”, as SERVER_PROTOCOL)</li>
</ul>


<p>The user name embedded in an Authorization header could be a vector as
well, but the corresponding REMOTE_USER variable is only set if the
user name corresponds to a known account according to the
authentication configuration, and a configuration which accepts the
magic string appears somewhat unlikely.</p>

<p>In addition, with other CGI implementations, the request method
(“GET”), path (“/path”) and query string
(“query-param-name=query-param-value”) may be vectors, and it is
conceivable for “query-param-value” as well, and perhaps even
“query-param-name”.</p>

<p>The other vector is OpenSSH, either through AcceptEnv variables, TERM
or SSH_ORIGINAL_COMMAND.</p>

<p>Other vectors involving different environment variable set by
additional programs are expected.</p>
]]></content>
  </entry>
  
</feed>
