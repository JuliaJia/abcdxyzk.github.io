<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: kernel~sched | kk Blog —— 通用基础]]></title>
  <link href="http://abcdxyzk.github.io/blog/cats/kernel~sched/atom.xml" rel="self"/>
  <link href="http://abcdxyzk.github.io/"/>
  <updated>2015-01-30T16:34:45+08:00</updated>
  <id>http://abcdxyzk.github.io/</id>
  <author>
    <name><![CDATA[kk]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[linux的调度分析（转）]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/01/22/kernel-sched-n2/"/>
    <updated>2015-01-22T17:42:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/01/22/kernel-sched-n2</id>
    <content type="html"><![CDATA[<p><a href="http://blog.csdn.net/cybertan/article/details/5686451">http://blog.csdn.net/cybertan/article/details/5686451</a></p>

<h3>调度</h3>

<h3>公平调度 (fair-share scheduling) 的进程调度算法：</h3>

<h4>一、公平分享的调度策略</h4>

<p>  Linux 的调度算法是相对独立的一个模块，而且较容易理解。因此很多系统高手都爱对调度算法做改进。但是可以说调度器是一个非常神秘，难以捉摸的精灵。可能通过改变一个关键参数你就可以大大提高系统的效率。<br/>
  对于一般进程， CPU 的使用时间都是系统平均分配给每一个进程的，因此这种公平分享都是从 进程的角度 出发的。 Bach 在 1986 年提出了公平分享调度策略（ Fair_Share scheduling ）来解决这个问题。和 Linux 三种内建策略比，公平分享调度策略是一种更抽象的调度策略。它认为 CPU 应该根据拥有进程的组（对 Linux 来说是用户）来分配时间，它实现了从 用户角度 考虑的公平原则。</p>

<p>由内核的结构来看，实现这个算法有很多种方式。我们可以在与调度相关的程序里做小小的改动来实现，如改动一些数据结构并改写 schedule() 函数。当然也可以做得很复杂，比如重写 schedule() 来实现所需要的结果。但是有一点我们是要必须牢记的，那就是大部分的 Linux 核心都是以短小高效为最高目标。所以，改进的算法必须尽量向这个目标靠拢。</p>

<h4>二、新调度策略的实现：分析</h4>

<p>1 、这里所说的 ‘ 组 ’ 的概念，在 Linux 中是一个用户。我们所关心的是 Linux 的用户，而不是 UNIX 系统下的用户组或是别的什么概念。因此 在公平共享调度策略中，一个进程能够分配到的时间与登录的系统用户数以及拥有该进程用户开辟进程数的多少有关。<br/>
2 、超级用户的进程是 独立于公平分享算法 的，因此它拥有的进程得到的调度时间应该和现在的进程调度算法分配时间相当。<br/>
3 、对于实时进程，调度算法仍旧给予比普通进程更高的优先权。不过也不用担心会花太多的时间去实现，只要在现在调度算法的基础上稍做改进就可以简单实现。<br/>
4 、新的调度算法对系统的吞吐量不能有太多的影响。比如说，如果定义的时间片少于 2 个 “ 滴答 ” ，那么新实现的调度器效率将变得很差。因为过于频繁的进程切换将耗费大部分的系统时间，而真正用于程序计算的时间则排在第二位了。 此条说明时间片的划分不能太小。<br/>
5 、我们所实现的算法并不需要绝对的公平，严格的平均是需要用效率为代价来换取的。如果算法过于精确，那就需要复杂的数据结构和耗时的计算过程，所以我们可以在以速度为第一原则的基础上实现 “ 模糊 ” 的公平分享。<br/>
6 、我们首先需要的是不断地思考和设计，只有将所有的问题都考虑清楚以后才可以开始动手。调度器是操作系统的核心，它将被频繁调用，因此其作用和影响也将是巨大的。我们要花费最小的代价实现算法，并且这种改动对系统核心的影响要降到最小。</p>

<h4>Linux 的进程调度机制：</h4>

<p>概述：<br/>
在多进程的操作系统中，进程调度是一个全局性的、关键性的问题。可以说，关于进程调度的研究是整个操作系统理论的核心，它对系统的总体设计、系统的实现、功能设置以及各方面的性能都有着决定性的影响。</p>

<h5>1、 150ms ：当系统中有大量进程共存时，根据测定，当每个用户可以接受的相应速度延迟超过１５０ ms 时，使用者就会明显地感觉到了。</h5>

<h5>2、 在设计一个进程调度机制时要考虑的具体问题主要有：</h5>

<p>调度的时机：什么情况下、什么时候进行调度；<br/>
调度的政策：根据什么准则挑选下一个进入运行的进程；<br/>
调度的方式：是 “ 可剥夺 ” 还是 “ 不可剥夺 ” 。当正在运行的进程并不自愿暂时放弃对ＣＰＵ的使用权时，是否可以强制性地暂时剥夺其使用权，停止其运行而给其他进程一个机会。如果是可剥夺的，那么是否在任何条件下都可剥夺，有没有例外？</p>

<h5>3、linux 内核的调度机制：</h5>

<h6>１）调度的时机：</h6>

<ul>
<li>首先，自愿的调度 ( 主动调度 ) 随时都可以进行：在内核里面，一个进程可以通过 schedule() 启动一次调度。也就是由当前进程自愿调用 schedule() 暂时放弃运行的情景。</li>
<li>除此之外，调度还可以非自愿的，即强制地发生在每次从系统调用返回的前夕，以及每次从中断或者异常处理 返回到用户空间 的前夕。</li>
</ul>


<p>上述红字说明：只有在用户空间（当ＣＰＵ在用户空间运行时）发生的中断或者异常才会引起调度。
<code>
    ret_from_exception:
        movl SYMBOL_NAME(bh_mask),%eax
        andl SYMBOL_NAME(bh_active),%eax
        jne handle_bottom_half
        ALIGN
    ret_from_intr:
        GET_CURRENT(%ebx)
        movl EFLAGS(%esp),%eax        # mix EFLAGS and CS
        movb CS(%esp),%al
        testl $(VM_MASK | 3),%eax    # return to VM86 mode or non-supervisor?
        jne ret_with_reschedule
        jmp restore_all
</code>
　　 从上述代码中 (arch/i386/kernel/entry.S) ，可以看出，转入 ret_with_reschedule 的条件为中断或异常发生前 CPU 的运行级别为３，即用户态。</p>

<p>这一点 ( 只有在用户空间发生的中断或者异常才会引起调度 ) 对于系统的设计和实现有很重要的意义：因为这意味着当 CPU 在内核中运行时无需考虑强制调度的可能性。发生在系统空间中的中断或异常当然是可能的，但是这种中断或者异常不会引起调度。这使得内核的实现简化了，早期的 Unix 内核正是靠这个前提来简化其设计与实现的。否则的话，内核中所有可能为一个以上进程共享的变量和数据结构就全都要通过互斥机制 ( 如信号量 ) 加以保护，或者说放在临界区里面。即在内核中由于不会发生调度而无需考虑互斥。但是在多处理器 SMP 系统中，这种简化正在失去重要性：因为我们不得不考虑在另一个处理器上运行的进程访问共享资源的可能性。这样，不管在同一个 CPU 上是否可能在内核中发生调度，所有可能为多个进程 ( 可能在不同的 CPU 上运行 ) 共享的变量和数据结构，都得保护起来。这就是为什么读者在阅读代码时看到那么多的 up() 、 down() 等信号量操作或者加锁操作的原因。</p>

<p>注意： “ 从系统空间返回到用户空间 ” 只是发生调度的必要条件，而不是充分条件。也就是说，这个条件满足了，调度并不是一定会发生的，具体是否发生调度还要判断当前进程的 task_struct 结构中的 need_resched 成员是否为非０，非０时才会转到 reschedule 处调用 schedule():
<code>
     ret_with_reschedule:
        cmpl $0, need_resched(%ebx)
        jne reschedule
        cmpl $0,sigpending(%ebx)
        jne signal_return
    ....
     reschedule:
        call SYMBOL_NAME( schedule )    # test
        jmp ret_from_sys_call
</code>
need_resched 成员是内核设置的，因为在用户空间是访问不到进程的 task_struct 结构的。除了当前进程通过系统调用自愿让出运行以及在系统调用中因某种原因受阻以外，主要就是当因某种原因唤醒一个进程的时候，以及在时钟中断服务程序发现当前进程已经连续运行太久的时候，内核会对
need_resched 成员进行设置 ( 非０ ) ，以重新调度。</p>

<h6>２）调度的方式：</h6>

<p>Linux 内核的调度方式可以说是 “ 有条件的可剥夺 ” 方式。
＊当进程在用户空间运行时，无论自愿不自愿，一旦有必要 ( 例如该进程已经运行了足够长的时间 ) ，内核就可以暂时剥夺其运行而调度其他进程进入运行。</p>

<p>＊但是，一旦进程进入了内核空间，或者说进入 “ 系统态 ” 。这时候，尽管内核知道应该要调度了，但是实际上调度并不会发生，直到该进程即将 “ 下台 ” ，也就是 回到用户空间的前夕 才能剥夺其运行权力。所以， linux 的调度方式从原则上来说是可剥夺的，可是实际上由于调度时机的限制而变成了有条件的。</p>

<h6>３）调度策略：</h6>

<p>  基本上是从 UNIX 继承下来的 以优先级为基础 的调度。内核为系统中的每个进程计算出一个反映其运行 “ 资格 ” 的权值，然后挑选权值最高的进程投入运行。在运行的过程中，当前进程的资格 ( 权值 ) 随时间而递减，从而在下一次调度的时候原来资格较低的进程可能就更有资格运行了。到所有的进程的资格都变为０时，就重新计算一次所有进程的资格。<br/>
  但是，为了适应各种不同应用的需要，内核 在此基础上 实现了三种不同的策略： SCHED_FIFO 、 SCHED_RR 、 SCHED_OTHER 。每个进程都有自己适用的调度策略，并且，进程还可以通过系统调用 sched_setscheduler() 设定自己适用的调度策略。下面介绍一下他们的区别：<br/>
   SCHED_FIFO ：适用于时间性要求比较强，但每次运行所需的时间比较短的进程，因此多用于实时进程；<br/>
   SCHED_RR:RR 表示 Round Robin ，是轮流的意思 ( 轮换调度 ) ，这种策略适合比较大、也就是每次运行时间较长的程序。使用 SCHED_RR 策略地进程在 schedule() 调度中有一点特殊的处理。　</p>

<p>  上两者的比较： SCHED_FIFO 、 SCHED_RR 都是基于优先级的调度策略，可是在怎样调度具有相同优先级的进程的问题上两者有区别：<br/>
   调度策略为 SCHED_FIFO 的进程一旦受到调度而开始运行之后，就要一直运行到自愿让出或者被优先级更高的进程剥夺为止。对于每次受到调度时要求运行时间不长的进程，这样并不会有多大的影响。可是， 如果是受到调度后可能执行很长时间的进程 ，这样就不公平了。这种不公正性是对具有相同优先级的进程而言的，同级的进程必须等待该进程自愿让出或者直到其运行结束。因为具有更高优先级的进程可以剥夺他的运行，而优先级则本来就没有机会运行，谈不上不公正。</p>

<p>　所以，对于执行时间可能会很长的进程来说，应该使用 SCHED_RR 调度策略，这种策略 在相同的优先级的进程上实行轮换调度。 也就是说：对调度策略为 SCHED_RR 的进程有个时间配额，用完这个配额就要让具有相同优先级的其他就绪进程先运行。看 schedule() 的５４０行对调度策略为 SCHED_RR 的当前进程的处理。</p>

<p> SCHED_OTHER ：是传统的调度策略，比较适合于交互式的分时应用。</p>

<p> 问题：既然每个进程都有自己的适用的调度策略，内核怎样来调用使用不同调度策略的进程的呢？是根据什么挑选出下一个要运行的进程呢？</p>

<p> 实际上，挑选的原则最后还是归结到每个进程的权值，只不过是在计算资格的时候将适用的策略也考虑进去了，就好像考大学时符合某些特殊条件的考生会获得加分一样。同时，对于适用不同策略地进程的优先级别也加了限制。</p>

<h5>4、调度程序 schedule() ：</h5>

<p>  调度程序 schedule() 是一个非常频繁地执行的函数，因此要将运行效率放在第一位，函数中使用了很多的 goto 语句。<br/>
  前面讲过，对 schedule() 只能由进程在内核中主动 调用，或者在当前进程从系统空间返回用户空间的前夕被动的 发生，而不能在一个中断服务程序的内部发生。即使一个中断服务程序有调度的要求，也只能通过把当前进程的 need_resched 字段设为１来表达这种要求，而不能直接调用 schedule() 。所以，如果在某个中断服务程序内部调用了 schedule() ，那一定是有问题的，所以转向 scheduling_in_interrupt.(kernel/sched.c)
<code>
        asmlinkage void schedule(void)
    509 {
    510 struct schedule_data * sched_data;
    511 struct task_struct *prev, *next, *p;
    512 struct list_head *tmp;
    513 int this_cpu, c;
    514
    515 if (!current&gt;
    active_mm) BUG();
    516 need_resched_back:
    517 prev = current;
    518 this_cpu = prev&gt;
    processor;
    519
    520 if (in_interrupt())
    521 goto scheduling_in_interrupt ;
    522
    523 release_kernel_lock(prev, this_cpu);
    524
    525 /* Do "administrative" work here while we don't hold any locks */
    526 if (softirq_active(this_cpu) &amp; softirq_mask(this_cpu))
    　　 /* 检查是否有内核软中断服务请求在等待，若有，就转入 handle_softirq 为这些请求服务 */
    527 goto handle_softirq;
    528 handle_softirq_back:
</code>
我们来看一下内核对这种问题的响应：
<code>
    [schedule()]
    686 scheduling_in_interrupt:
    687 　　 printk("Scheduling in interrupt/n");
    688 　　 BUG();
    689 　　 return;
</code>
内核对此的响应是显示或者在 /var/log/messages 文件末尾添上一条出错信息，然后执行一个宏操作 BUG 。</p>

<p>接着往下看 schedule() ：<br/>
如果有内核软中断服务请求在等待，那么就转入 handle_softirq ：
<code>
    　 [schedule()]
    675 handle_softirq:
    676 　　　 do_softirq();
    677 　　　 goto handle_softirq_back;
</code>
执行 softirq 队列完毕以后继续往下看：
<code>
    　　 ==================== kernel/sched.c 528 541 ====================
    [schedule()]
    528 handle_softirq_back:
    529
    530 /*
    531 * 'sched_data' is protected by the fact that we can run
    532 * only one process per CPU.
    533 */
    534 sched_data = &amp; aligned_data[this_cpu].schedule_data;
    535
    536 spin_lock_irq(&amp;runqueue_lock);
    537
    538 /* move an exhausted RR process to be last.. */
    539 if (prev&gt;policy == SCHED_RR)
    540 　　　 goto move_rr_last;
    541 move_rr_back:
</code>
指针 sched_data 指向一个 schedule_data 数据结构，用来保存供下一次调度时使用的信息。此数据结构的定义如下：
<code>
    ==================== kernel/sched.c 91 101 ====================
    91 /*
    92 * We align perCPU
    scheduling data on cacheline boundaries,
    93 * to prevent cacheline pingpong.
    94 */
    95 static union {
    96 　　 struct schedule_data {
    97 　　　　 struct task_struct * curr;
    98 　　　　 cycles_t last_schedule;
    99 　　　 } schedule_data;
    100 　　　 char __pad [SMP_CACHE_BYTES];
    101 } aligned_data [ NR_CPUS ] __cacheline_aligned = { };
</code>
这里的 cycles_t 实际上是无符号整数，用来记录调度发生的时间。这个数据结构是为多处理器 SMP 结构而设的，因此我们不必关心。数组中的第一个元素，即 CPU0 的 schedule_data 结构初始化为 {&amp;init_task,0} ，其余的则全为｛０，０｝。代码中的 __cacheline_aligned 表示数据结构的起点应与高速缓存中的缓冲线对齐。</p>

<p>下面就要涉及可执行进程队列了，所以先将这个队列锁住 (536 行 ) ，以防止其他处理器的干扰。从 538 行开始：如果当前进程 prev 的调度策略是 SCHED_RR ，也就是轮换调度，那就要先进行一点特殊的处理 ( 540 : goto move_rr_last; ) 。
（对使用 SCHED_RR 策略的当前进程的处理）
<code>
      ==================== kernel/sched.c 679 685 ====================
     [schedule()]
    679  move_rr_last:
    680   if (!prev&gt;counter) {
    681       prev&gt;counter = NICE_TO_TICKS (prev&gt;nice);
    682       move_last_runqueue(prev);
    683     }
    684 goto move_rr_back;
</code>
  这里的 prev>counter ：代表这当前进程的运行时间配额，其数值在每次时钟中断时都要递减 (update_process_times() 中实现的 ) 。因此，不管一个进程的时间配额有多高，随着运行时间的积累最终总会递减到０。对于调度策略为 SCHED_RR 的进程，一旦其时间配额降到０，就要从 可执行进程队列 runqueue 中当前的位置上移动到队列的末尾，同时恢复其最初的时间配额（ NICE_TO_TICKS ），以等待下一次的调度。对于具有相同优先级的进程，调度的时候排在前面的进程优先，所以这使队列中具有相同优先级的其他进程有了优势。<br/>
  宏操作 NICE_TO_TICKS 根据系统时钟的精度将进程的优先级别换算成可以运行的时间配额。在 kernel/sched.c 中定义。<br/>
　将一个进程的 task_struct 结构从可执行队列中的当前位置移到队列的末尾是由 move_last_runqueue() 完成的 (kernel/sched.c) 。把进程移到可执行进程队列的末尾意味着：如果队列中没有资格更高的进程，但是有一个资格与之相同的进程存在，那么，这个资格虽然相同而排在前面的进程会被选中。</p>

<p>继续看 schedule() ：
<code>
    ==================== kernel/sched.c 541 553 ====================
    [schedule()]
    541 move_rr_back:
    542
    543 switch ( prev&gt;state ) {
    544 case TASK_INTERRUPTIBLE:
    545 　　　 if (signal_pending(prev)) {
    546 　　　　　　 prev&gt;state = TASK_RUNNING;
    547 　　　　　　 break;
    548 　　　　 }
    549 default:
    550 　　　 del_from_runqueue(prev);
    551 case TASK_RUNNING:
    552 }
    553 prev&gt;need_resched = 0;
</code>
  当前进程，就是正在执行的进程，当进入 schedule() 时其状态却不一定是 TASK_RUNNING 。例如：当前进程如已经在 do_exit() 中将其状态改成 TASK_ZOMBIE ，又如当前进程在 sys_wait4() 中调用 schedule() 时的状态为 TASK_INTERRUPTIBLE 。所以，这里的 prev>state 与其说是当前进程的状态不如说是其意愿。当其意愿既不是继续执行也不是可中断的睡眠时，就要通过 del_from_runqueue() 把这个进程从可执行队列中撤下来。另一方面， 也可以看出 TASK_INTERRUPTIBLE 和 TASK_UNINTERRUPTIBLE 两种睡眠状态之间的区别： 前者在进程有信号等待处理时要将其改成 TASK_RUNNING ，让其处理完这些信号再说，而后者则不受信号的影响。</p>

<p>  最后，将 prev>need_resched 恢复为０，因为所需求的调度已经在进行了。 下面的任务就是要 挑选出一个进程来运行了 ( 这一部分是很重要的，通过对就绪进程队列进行扫描 ) 。
<code>
    ==================== kernel/sched.c 555 576 ====================
    [schedule()]
    555 /*
    556 * this is the scheduler proper:
    557 */
    558
    559 repeat_schedule:
    560 /*
    561 * Default process to select..
    562 */
    563 next = idle_task (this_cpu);
    564 c = 1000;
    565 if ( prev&gt;state == TASK_RUNNING )
    566      goto still_running;
    567
    568 still_running_back:
    569      list_for_each (tmp, &amp;runqueue_head) {
    570          p = list_entry(tmp, struct task_struct, run_list);
    571          if (can_schedule(p, this_cpu)) {
    572           int weight = goodness (p, this_cpu, prev&gt;active_mm);
    573           if ( weight &gt; c )
    574            c = weight, next = p;
    575          }
    576 }
</code>
在这段程序中， next 总是指向已知最佳的候选进程， c 则是这个进程的综合权值，或者是运行资格。</p>

<p>  挑选的过程是从 idle 进程即 0 号进程开始，其权值为－ 1000 ，这是可能的最低值，表示仅在没有其他进程可以运行时才会让他运行。<br/>
  然后，遍历可执行队列 runqueue 中的每个进程 ( 在单 CPU 系统中 can_schedule() 的返回值永远是 1) ，也就是一般操作系统书中所称的就绪进程。为每一个就绪进程通过函数 goodness () 计算出他当前所具有的权值，然后与当前的最高值 c 相比。注意这里的条件： weight > c ， 这意味着 “ 先入为大 ” 。也就是说，如果两个进程有相同的权值的话，排在队列前面的进程胜出，优先运行。</p>

<p>这里还有一个小插曲：如果当前进程的意图是继续运行，那么就要先执行一下 still_running(kernel/sched.c) ：
<code>
      ==================== kernel/sched.c 670 674 ====================
    [schedule()]
    670 still_running:
    671    c = goodness(prev, this_cpu, prev&gt;active_mm);
    672    next = prev;
    673    goto still_running_back;
    674
</code>
也就是说，如果当前进程想要继续运行，那么在挑选候选进程时以当前进程此刻的权值开始比较。而且这意味着，对于具有相同权值的其他进程来说，当前进程优先。</p>

<p>  那么，进程的当前权值是怎样计算的呢？也就是 goodness() 是怎样执行的呢？
<code>
    ==================== kernel/sched.c 123 187 ====================
    [schedule()&gt; goodness() ]
    123 /*
    124 * This is the function that decides how desirable a process is..
    125 * You can weigh different processes against each other depending
    126 * on what CPU they've run on lately etc to try to handle cache
    127 * and TLB miss penalties.
    128 *
    129 * Return values:
    130 * 1000:never select this
    131 * 0: out of time, recalculate counters (but it might still be
    132 * selected)
    133 * +ve: "goodness" value (the larger, the better)
    134 * +1000: realtime process, select this.
    135 */
    136
    137 static inline int goodness(struct task_struct * p, int this_cpu, struct mm_struct *this_mm)
    138 {
    139 int weight;
    140
    141 /*
    142 * select the current process after every other
    143 * runnable process, but before the idle thread.
    144 * Also, dont trigger a counter recalculation.
    145 */
    146 weight = -1 ;
    147 if (p&gt;policy &amp; SCHED_YIELD )
    148 goto out;
    149
    150 /*
    151 * Non RT process normal case first.
    152 */
    153 if ( p&gt;policy == SCHED_OTHER ) {
    154 /*
    155 * Give the process a firstapproximation goodness value
    156 * according to the number of clockticks it has left.
    157 *
    158 * Don't do any other calculations if the time slice is
    159 * over..
    160 */
    161    weight = p-&gt;counter;
    162    if (!weight)
    163    goto out;
    164
    165 #ifdef CONFIG_SMP
    166 /* Give a largish advantage to the same processor... */
    167 /* (this is equivalent to penalizing other processors) */
    168 if (p-&gt;processor == this_cpu)
    169    weight += PROC_CHANGE_PENALTY;
    170 #endif
    171
    172 /* .. and a slight advantage to the current MM */
    173   if (p-&gt;mm == this_mm || !p-&gt;mm)
    174       weight += 1;
    175    weight += 20- p&gt;nice;
    176    goto out;
    177 }
    178
    179 /*
    180 * Realtime process, select the first one on the
    181 * runqueue (taking priorities within processes
    182 * into account).
    183 */
    184      weight = 1000 + p-&gt;rt_priority;
    185 out:
    186      return weight;
    187 }
</code>
  ＊首先，如果一个进程通过系统调用 sched_yield() 明确表示了 “ 礼让 ” 后，就将其权值定位 -1 。这是很低的权值，一般就绪进程的权值至少是 0 。<br/>
  ＊对于没有实时要求的进程 ，即调度策略为 SCHED_OTHER 的进程，其权值主要取决于两个因素：一个是剩下的时间配额 p->counter ，如果用完了则权值为 0 。另一个是进程的优先级 nice ，这是从早期 Unix 沿用下来的负向优先级 ( 越负，优先级越高 ) ，其取值范围为 19~-20 ，只有特权用户才能把 nice 值设置为小于 0 。所以，综合的权值 weight 在时间配额尚未用完时基本上是二者之和。 此外，如果是内核线程，或者其用户 空间与当前进程的相同，因而无需切换用户空间，则会得到一点小 “ 奖励 ” ，将权值额外加 1 。<br/>
  ＊对于实时进程，即调度策略为 SCHED_FIFO 或者 SCHED_RR 的进程，则另有一种正向的优先级 ，那就是实时优先级 rt_priority ，而权值为 1000 + p->rt_priority 。可见， SCHED_FIFO 或者 SCHED_RR 两种有时间要求的策略赋予进程很高的权值 ( 相对于 SCHED_OTHER) 。这种进程的权值至少是 1000 。另一方面， rt_priority 的值对于实时进程之间的权值比较也起着重要的作用，其数值也是在 sched_setscheduler() 中与调度策略一起设置的。</p>

<p>从上面可以看出：对于这两种实时调度策略，一个进程已经运行了多久，即时间配额 p->counter 的当前值，对权值的计算不起所用。不过，前面讲到，对于使用 SCHED_RR 策略地进程，当 p->counter 达到 0 时会导致将进程移到队列尾部。<br/>
  实时进程的 nice 数值与优先级无关，但是对 使用 SCHED_RR 策略地进程的时间配额大小有关 ( 宏操作 NICE_TO_TICKS()) 。由于实时进程的权值有个很大的基数 (1000) ，因此当有实时进程就绪时，非实时进程是没有机会运行的。</p>

<p>由此可见， linux 内核中对权值的计算是很简单的，但是 goodness() 函数并不代表 linux 调度算法的全部，而要与前面讲到的 对 SCHED_RR 进程的特殊处理 、 对意欲继续运行的当前进程的特殊处理 ‘ 以及下面要讲到的 recalculate 结合起来分析。</p>

<p>上面 still_running_back 运行结束后，变量 c 的值有几种可能：一种可能是一个大于 0 的正数，此时 next 指向挑选出来的进程；另一种可能是 c 的值为 0 ，发生于就绪队列中所有进程的权值都是 0 的时候。由于除了 init 进程和调用了 sched_yield() 的进程以外，每个进程的权值最低为 0 ，所以只要队列中有其他就绪进程存在就不可能为负数。因此，队列中所有其他进程的权值都已经降到 0 了，说明这些进程的调度策略都是 SCHED_OTHER ，即系统中当前没有就绪的实时进程，因为如果有策略为 SCHED_FIFO 或者 SCHED_RR 的进程存在，其权值至少也有 1000 。</p>

<p>let`s go on ：回到 schedule()
<code>
==================== kernel/sched.c 578 580 ====================
[schedule()]
578 /* Do we need to recalculate
counters? */
579 if (!c)
580 goto recalculate;
</code>
如果当前已经选择的进程（权值最高的进程）的权值为 0 ，那就要重新计算各个进程的时间配额。如上所述，这说明系统中当前没有就绪的实时进程。而且，这种情况已经持续了一段时间，否则 SCHED_OTHER 进程的权值就没有机会消耗到 0 。
<code>
 ==================== kernel/sched.c 658 669 ====================
[schedule()]
658 recalculate:
659 {
660     struct task_struct *p;
661     spin_unlock_irq(&amp;runqueue_lock);
662     read_lock(&amp;tasklist_lock);
663     for_each_task (p)
664         p-&gt;counter = (p-&gt;counter &gt;&gt; 1) + NICE_TO_TICKS(p-&gt;nice);
665     read_unlock(&amp;tasklist_lock);
666     spin_lock_irq(&amp;runqueue_lock);
667 }
668  goto repeat_schedule;
</code>
  这里所作的运算是将每个进程的当前的时间配额 p->counter 除以 2 ，再在上面加上由该进程的 nice 值换算过来的 tick 数量。宏操作 NICE_TO_TICKS 的定义在前面已经见过，显然 nice 值对于非实时进程既表示优先级也决定着时间配额。<br/>
  注意：这里的 for_each_task() 是对所有进程的循环，而并不是仅对就绪进程队列的循环，对于不再就绪进程队列中的非实时进程 ，这里得到了提升其时间配额、从而提升其综合权值的机会。不过，这种对综合权值的提升是很有限的，每次重新计算都将原有的时间配额减半，再与 NICE_TO_TICKS(p->nice) 相加，这样就决定了重新计算以后的综合权值永远也不可能达到 NICE_TO_TICKS(p->nice) 的两倍。因此，即使经过很长时间的韬光养晦，也不可能达到可与实时进程竞争的地步，所以只是对非实时进程之间的竞争有意义。<br/>
  至于实时进程，时间配额的增加并不会提升其综合权值，而且对于 SCHED_FIFO 进程，时间配额就没有什么意义。
重新计算完权值以后，程序转回 repeat_schedule( 跳回前面，再次执行挑选进程 ) 处重新挑选。这样，当再次完成对就绪进程队列的扫描时，变量 c 的值就应该不为 0 了，此时 next 指向挑选出来的进程。<br/>
至此，已经挑选好进程了（权值最高的进程）。</p>

<p>还没有结束阿？哈哈<br/>
进程挑好之后，接下来要做的就是切换的事情了。
<code>
    [schedule()]
    581 /*
    582 * from this point on nothing can prevent us from
    583 * switching to the next task, save this fact in
    584 * sched_data.
    585 */
    586 sched_data&gt;curr = next;
    587 #ifdef CONFIG_SMP
    .....
    590 #endif
    591 spin_unlock_irq(&amp;runqueue_lock);
    592
    593 if ( prev == next )
    594     goto same_process;
    595
    596 #ifdef CONFIG_SMP
    ==================== kernel/sched.c 612 657 ====================
    612 #endif /* CONFIG_SMP */
    613
    614 kstat.context_swtch++;
    615 /*
    616 * there are 3 processes which are affected by a context switch:
    617 *
    618 * prev == .... ==&gt; (last =&gt; next)
    620 * It's the 'much more previous' 'prev' that is on next's stack,
    621 * but prev is set to (the just run) 'last' process by switch_to().
    622 * This might sound slightly confusing but makes tons of sense.
    623 */
    624 prepare_to_switch ();
    625 {
    626   struct mm_struct *mm = next-&gt;mm;
    627   struct mm_struct *oldmm = prev-&gt;active_mm;
    628   if (!mm) {
    629         if (next&gt;active_mm) BUG();
    630         next&gt;active_mm = oldmm;
    631         atomic_inc(&amp;oldmm&gt;mm_count);
    632          enter_lazy_tlb(oldmm, next, this_cpu);
    633 } else {
    634      if (next&gt;active_mm != mm) BUG();
    635     switch_mm(oldmm, mm, next, this_cpu);
    636 }
    637
    638 if (!prev&gt;mm) {
    639       prev&gt;active_mm = NULL;
    640       mmdrop(oldmm);
    641 }
    642 }
    643
    644 /*
    645 * This just switches the register state and the
    646 * stack.
    647 */
    648 switch_to(prev, next, prev);
    649 __schedule_tail(prev);
    650
    651 same_process:
    652     reacquire_kernel_lock(current);
    653     if (current&gt;need_resched)
    654        goto need_resched_back;
    655
    656    return;
</code>
跳过对 SMP 结构的条件编译部分。<br/>
  首先，如果挑选出来的进程 next 就是当前进程 prev ，就不用切换，直接跳转到 same_process 处就返回了。这里的 reacquire_kernel_lock() 对于 i386 单 CPU 结构而言是空语句。前面已经把当前进程的 need_resched 清 0 ，如果现在又成了非 0 ，则一定是发生了中断并且情况有了变化，所以转回 need_resched_back 再调度一次。<br/>
  否则，如果挑选出来的进程 next 与当前进程 prev 不同，那就要切换了。对于 i386 单 CPU 结构而言， prepare_to_switch() 也是空语句。而 649 行的 __schedule_tail() 则只是将当前进程 prev 的 task_struct 结构中的 policy 字段里的 SCHED_YIELD 标志位清成 0 。所以实际上只剩下了两件事：对用户虚存空间的处理；进程的切换 switch_to() 。</p>

<ol>
<li></li>
<li></li>
</ol>


<p>实验：<br/>
第二部分：如何在 sched.c 中实现算法？</p>

<p>首先，确定何时进行算法的计算过程。 是在 schedule() 中选择下一运行进程之前？<br/>
选择下一运行进程时？选择下一运行进程之后？还是直接修改 goodness() 函数以确定下一运行进程呢？<br/>
  在以上提到的各个位置都可以添加代码实现我们的算法，但是考虑到 schedule() 函数是被频繁调用的一个函数 ，它的运行效率直接影响到了系统的吞吐量，因此我们所添加的代码段应该是被调用的频率越小越好。<br/>
  在这种原则的指导之下，我们发现有一段代码只有在 CPU 的时间段（ epoch ）全部耗尽的时候才去调用，而在此时刻可以根据一些信息调度进程，达到给每个用户平均分配 CPU 时间的效果。在 schedule() 函数选择了一个进程之后，它将判断是否需要重新计算进程的 counter 值，这个过程只有在运行队列中所有进程的都用完了时间片时才被调用。在这段代码中加入我们的算法是最合适不过的了。</p>

<p>　原文为：<a href="http://www.cublog.cn/u2/69737/showart_1070708.html">http://www.cublog.cn/u2/69737/showart_1070708.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[linux 调度总结]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/01/22/kernel-sched-n1/"/>
    <updated>2015-01-22T16:56:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/01/22/kernel-sched-n1</id>
    <content type="html"><![CDATA[<p><a href="http://zzjlzx.blog.chinaunix.net/uid-29060569-id-4076183.html">http://zzjlzx.blog.chinaunix.net/uid-29060569-id-4076183.html</a></p>

<h4>调度：</h4>

<h5>操作系统的调度程序的两项任务：</h5>

<h6>1： 调度：</h6>

<p>实现调度策略，决定就绪的进程、线程竞争cpu的次序的裁决原则。说白了就是进程和线程何时应该放弃cpu和选择那个就绪进程、线程来执行。</p>

<h6>2： 分派：</h6>

<p>原来实现调度机制如何时分复用cpu，处理好上下文交换的细节、完成进程、线程和cpu的绑定和放弃的具工作。</p>

<h3>linux 2.4 调度：</h3>

<p>1：policy ：<br/>
进程的调度策略：<br/>
<code>
1）SCHED_FIFO : 实时进程使用的的先进先出策略，进程会一直占用cpu除非其自动放弃cpu。
2）SCHED_RR : 实时进程的轮转策略，当分配个u进程的时间片用完后，进程会插入到原来优先级的队列中。
3）SHED_OTHER：普通进程基于优先级的的时间片轮转调度。
</code>
2：priority：进程的静态优先级。<br/>
3：nice：进程用来控制优先级的因子。在-20～19间的整数。增加nice的值会使优先级降低。默认值为0。<br/>
4：rt_priority：实时进程的优先级。<br/>
5：counter：一个计时器，进程目前的剩余时间片。用来动态计算进程的动态优先级。系统将休眠次数多的进程的剩余时间叠会加起来。<br/>
6：schedule()的流程：<br/>
<code>
1）检查是否有软中断请求。有则先执行。
2）如果当前进程的调度策略为RR并且counter==0,将此进程移到运行进程队列的尾部。重新计算counter的值。
3）若当前进程的状态为 TASK_INTERRUPTIBLE 且有信号接收，则将进程状态设置为TASK_RUNNING，
   若当前进程的状态不是TASK_RUNNING,则将进程从可执行的队列中移出，将其进程描述符的need_resched置为0。
4）选择出可运行队列中最大权值，保存在变量c中，与之对应的进程描述符保存在变量next中。
5）检查c是否为0,c==0,则队列中的所有进程的时间片都用完了。此时对队列中所有进程的时间片重新计算。重新执行第5步。
6）如果netx==当前进程，则结束调度进程。否则，进行进程切换。
</code></p>

<p>过程：2.4的调度算法，将所有的就绪进程组织成一条可运行队列，不管是单核环境还是smp环境，cpu都只从这条可运行队列中循环遍历直到挑选到下一个要运行的进程。如果所有的进程的时间片都用完，就重新计算所有进程的时间片。</p>

<h4>2.4调度的数据结构：</h4>

<p><img src="/images/kernel/2015-01-22-1.png" alt="" /></p>

<h4>2.4调度的不足：</h4>

<p>1）一个明显的缺点就是时间复杂度为O(n)，每次都要遍历队列，效率低！。虽然说O(n)的复杂度看起来不是很糟糕，而且系统能容纳进程数量也不一定会很大，但复杂度为O(n)还是很难忍受的。<br/>
2）由于在smp环境下多个cpu还是使用同一条运行队列，所以进程在多个cpu间切换会使cpu的缓存效率降低，降低系统的性能。<br/>
3）多个cpu共享一条运行队列，使得每个cpu在对队列操作的时候需要对运行队列进行加锁，这时如果其他空闲cpu要访问运行队列，则只能等待了。由2、3两点可以看出2.4的调度算法对smp环境的伸缩性不高！不能很好地支持smp环境。<br/>
4）不支持内核抢占，内核不能及时响应实时任务，无法满足实时系统的要求（即使linux不是一个硬实时，但同样无法满足软实时性的要求）。<br/>
5）进程的剩余时间是除了nice值外对动态优先级影响最大的因素，并且系统将休眠次数多的进程的剩余时间叠加起来，从而得出更大的动态优先级。这体现了系统更倾向优先执行I/O型进程。内核就是通过这种方式来提高交互进程的优先级，使其优先执行。但休眠多的进程就代表是交互型的进程吗？并不是的，这只能说明它是I/O型进程。I/O型进程需要进行I/O交互，如读写磁盘时进程会经常处于休眠的状态。如果把这种进程当成是交互进程，反而会影响其他真正的交互进程。<br/>
6）简单的负载平衡。那个cpu空闲就把就绪的进程调度到这个cpu上去执行。或者某个cpu的进程的优先级比某个进程低，就调度到那个cpu上去执行。这样简单的负载平衡缺点不言而喻。进程迁移比较频繁，而且出现2、3的情况。这样的负载平衡弊大于利！</p>

<h3>linux 2.6 O(1)调度：</h3>

<p>1：policy：调度策略跟2.4的一样。<br/>
2：rt_priority：实时进程的优先级。在0～99之间。MAX_RT_PRIO为100。不参与优先级的计算。<br/>
3：static_prio：非实时进程的静态优先级，由nice值转换而来，-20 &lt;= nice &lt;= 19。static_prio = MAX_RT_PRIO + nice + 20。所以 100 &lt;= static_prio &lt;= 139。<br/>
4：sleep_avg：进程平均等待时间。进程等待时间与执行时间的差。反映进程的交互性，又表示了进程需要运行的紧急程度。这个值越大，进程的优先级就越高。<br/>
5：prio：进程的动态优先级。主要影响进程的prio的因素是sleep_avg。其计算时机为：<br/>
<code>
1）进程在创建时继承父进程的prio。
2）进程由睡眠到被唤醒时进行优先级修正。
3）时钟中断中重新计算进程的优先级并且进程进入相应的队列。
4）负载平衡/修改nice/修改调度策略等都有可能修改prio的值。
</code>
6：time_slice：进程的时间片余额。进程的默认时间片与static_prio有关。<br/>
7：load_weight：平衡负载用的权重。</p>

<h4>linux 2.6 O(1)调度的数据结构代码：</h4>

<p>1：运行队列：部分代码如图：
<img src="/images/kernel/2015-01-22-2.png" alt="" /></p>

<p>2：优先级数组代码如图：
<img src="/images/kernel/2015-01-22-3.png" alt="" /></p>

<pre><code>1）nr_active：数组内可运行的进程
2）DECLARE_BITMP(...)：优先级位图的宏。找出优先级最高的且有就绪进程的队列。
3）list_head queue：使用通用链表，优先级队列。
</code></pre>

<h4>linux 2.6 O(1)调度的数据结构（active or expired）：</h4>

<p><img src="/images/kernel/2015-01-22-4.png" alt="" /></p>

<p>每个cpu维护一个自己的运行队列，每个运行队列有分别维护自己的active队列与expried队列。当进程的时间片用完后就会被放入expired队列中。当active队列中所有进程的时间片都用完，进程执行完毕后，交换active队列和expried。这样expried队列就成为了active队列。这样做只需要指针的交换而已。当调度程序要找出下一个要运行的进程时，只需要根据上面提过的位图宏来找出优先级最高的且有就绪进程的队列。这样的数据组织下，2.6的调度程序的时间复杂度由原来2.4的O(n)提高到O(1)。而其对smp环境具有较好的伸缩性。</p>

<p>数据结构的组织如下：
<img src="/images/kernel/2015-01-22-5.png" alt="" /></p>

<h4>linux 2.6 O(1) 调度的进程优先级：</h4>

<p>2.6调度有140个优先级级别，由0～139, 0～99 为实时优先级，而100～139为非实时优先级。上面的图有说。</p>

<h5>特点：</h5>

<p>1）动态优先级是在静态优先级的基础上结合进程的运行状态和进程的交互性来计算。所以真正参与调度的是进程的动态优先级。而进程的交互性是通过进程的睡眠时间来判断的（这点从根本上来说还是和2.4思想的一样）。所以动态优先级是通过静态优先级和进程睡眠时间来计算的。这里要注意的是，动态优先级是非实时进程插入优先级队列的依据。但实时进程是根据rt_prioirty来插入队列的，实时进程的实时优先级由进程被创建到进程结束都是不会改变的。但其执行的时间片是根据静态优先级来计算的。<br/>
2）进程优先级越高，它每次执行的时间片就越长。<br/>
3）使用TASK_INTERACTIVE()宏来判断进程是否为交互进程，该宏是基于nice来判断的，nice值越高，优先级越低，这样交互性越低。<br/>
4）如果一个进程的交互性比较强，那么其执行完自身的时间片后不会移到expired队列中，而是插到原来队列的尾部。这样交互性进程可以快速地响应用户，交互性会提高。如果被移到expired队列，那么在交换队列指针前，交互性进程可能就会发生严重的饥饿，从而使交互性严重下降<br/>
5）在创建新的进程时，子进程会与父进程平分进程的剩余时间片。即在 fork()&mdash;&mdash;>do_fork() 后父子进程的时间片之和等于原来父进程的时间片大小。这样做的原因是为了防止父进程利用创建子进程来窃取时间片。如果子进程在退出时，从来没有被重新分配时间片，且还有时间片剩余，则其剩余的时间片会返还给父进程。这样父进程就不会因为创建子进程而受到时间片上的惩罚。</p>

<h4>2.6 O(1)调度动态优先级的计算代码：</h4>

<p>1）effective_prio(p)：<br/>
<img src="/images/kernel/2015-01-22-6.png" alt="" /></p>

<p>2）normal_prio：<br/>
<img src="/images/kernel/2015-01-22-7.png" alt="" /></p>

<p>3）__normal_prio：<br/>
<img src="/images/kernel/2015-01-22-8.png" alt="" /></p>

<h4>linux 2.6 O(1)调度的调度与抢占时机：</h4>

<h5>1：直接调度：当前进程因为阻塞而直接调用schedule()主动放弃cpu。</h5>

<pre><code>1）当前进程被放入相应的等待队列。
2）改变当前进程的进程状态。由TASK_RUNNING 改为TASK_UNINTERRUPTIBLE 或者 TASK_INTERRUPTIBLE。
3）选择新的进程运行。调用schedule() 来获得下一个需要运行的进程。
4）当资源可用时，把当前进程从等待队列中移除。
</code></pre>

<h4>2：被动调度：当前进程因为时间片用完，或者被更高优先级的进程抢占，而被逼放弃cpu。这时当前进程不会立刻被调度出去，而是通过设置TIF_NEED_RESCHED位为1来告知kernel需要调度了。在适当的时机kernel会重新调度。</h4>

<h5>1）问题：为什么不能立刻调度？</h5>

<p>进程在内核里运行时，可能要申请共享资源，如自旋锁，如果这个时候去抢占当前进程，使其立刻让出cpu，如果新进程也需要相同的共享资源的话，那么会导致死锁！所以这里进程只设置了标志位通知内核需要调度。</p>

<h5>2）问题：什么时候才是合适的时机？</h5>

<p>内核在即将返回用户空间时会检查TIF_NEED_RESCHED，如果设置了就调用schedule()，这样就会发生用户抢占。<br/>
a：从中断处理程序返回用户空间时。<br/>
b：从系统调用返回用户空间时。</p>

<h4>linux 2.6 O(1)调度的负载平衡：</h4>

<p>复杂！</p>

<h4>linux 2.6 O(1)调度的过渡：</h4>

<h5>1：SD调度器：</h5>

<p>O(1)调度的复杂性主要来至于动态优先级的计算。调度器根据一些难以理解的经验公式和平均休眠时间来决定、修改进程的优先级。这是O(1)调度一个比较大的缺点（甚至可以说是致命的。）。SD调度的特点：</p>

<p>1）数据结构跟O(1)调度差不多，不过少了expired队列。<br/>
2）进程在用完其时间片后不会放到expired队列，而是放到下一个优先级队列中（这就是为什么没有expired队列的原因）。当下降到最低一级时，时间片用完，就回到初始优先级队列去，重新降级的过程！每一次降级就像我们下楼梯的过程，所以这被称为楼梯算法。<br/>
3）两种时间片：粗粒度、细粒度。粗粒度由多个细粒度组成，当一个粗粒度时间片被用完，进程就开始降级，一个细粒度用完就进行轮回。这样cpu消耗型的进程在每个优先级上停留的时间都是一样的。而I/O消耗型的进程会在优先级最高的队列上停留比较长的时间，而且不一定会滑落到很低的优先级队列上去。<br/>
4）不会饥饿，代码比O(1)调度简单，最重要的意义在于证明了完全公平的思想的可行性。<br/>
5）相对与O(1)调度的算法框架还是没有多大的变化，每一次调整优先级的过程都是一次进程的切换过程，细粒度的时间片通常比O(1)调度的时间片短很多。这样不可避免地带来了较大的额外开销，使吞吐量下降的问题。这是SD算法不被采用的主要原因！</p>

<h5>2：RSDL调度器：</h5>

<p>对SD算法的改进，其核心思想是“完全公平”，并且没有复杂的动态优先级的调整策略。引进“组时间配额” → tg 每个优先级队列上所有进程可以使用的总时间 ，”优先级时间配额“ → tp, tp不等于进程的时间片，而是小于进程时间片。当进程的tp用完后就降级。与SD算法相类似。当每个队列的tg用完后不管队列中是否有tp没有用完，该队列的所有进程都会被强制降级。</p>

<h4>linux 2.6 O(1)调度的不足：</h4>

<p>1：复杂的难以理解的经验公式。<br/>
2：公平吗？<br/>
3：实时性？</p>

<h3>linux 杰出的调度算法 → cfs：</h3>

<p>按照cfs的作者的说法：”cfs的 80% 的工作可以用一句话来概括：cfs在真实的硬件上模拟了完全理想的多任务处理器。“ 在完全理想的多任务处理器下，每个进程都能够同时获得cpu的执行时间，当系统中有两个进程时，cpu时间被分成两份，每个进程占50%。</p>

<p>1：虚拟运行时间。进程的 vt 与其实际的运行时间成正比，与其权重成反比。权重是由进程优先级来决定的，而优先级又参照nice值的大小。进程优先级权重越高，在实际运行时间相同时，进程的vt就越小。所有的非实时的可运行的进程用红黑树来组织起来，调度时选择的vt最小的那个进程。因为这里的红黑树左子树的键值比右边的小，所以每次调度时都选择树的最左下角的那个进程（实体）就可以了。<br/>
2：完全公平的思想。cfs不再跟踪进程的休眠时间、也不再区分交互式进程，其将所有的进程统一对待，在既定的时间内每个进程都获得了公平的cpu占用时间，这就是cfs里的公平所在！<br/>
3：cfs 引入了模块化、完全公平调度、组调度等一系列特性。虽说是完全公平调度，但进程之间本来就不公平的（有些内核线程用于处理紧急情况），所以这种完全公平是不能够实现的。cfs使用weight 权重来区分进程间不平等的地位，这也是cfs实现公平的依据。权重由优先级来决定，优先级越高，权重越大。但优先级与权重之间的关系并不是简单的线性关系。内核使用一些经验数值来进行转化。
如果有a、b、c 三个进程，权重分别是1、2、3,那么所有的进程的权重和为6, 按照cfs的公平原则来分配，那么a的重要性为1/6, b、c 为2/6, 3/6。这样如果a、b、c 运行一次的总时间为6个时间单位，a占1个，b占2个，c占3个。</p>

<h4>cfs调度器：</h4>

<p>各个部分的数据结构关系图如下：<br/>
<img src="/images/kernel/2015-01-22-9.png" alt="" /></p>

<h4>虚拟运行时间</h4>

<p>  在完全理想的多任务处理器下，每个进程都能同时获得cpu的时间。但实际上当一个进程占用cpu时，其他的进程必须等待，这样就产生了不公平。所以linux 的cfs调度引入了虚拟运行时间。虚拟运行时间主要由两个因素决定，一个是实际的运行时间，一个是其权重，它随自己的实际运行时间增加而增加，但又不等于实际运行时间。上面提过内核采用红黑树来对虚拟运行时间来排序，这样红黑树最左边的进程（调度实体）就是受到了最不公平待遇的进程，需要作为下一个被调度的进程。
进程的虚拟运行时间由calc_delta_fair()来计算。在每次时钟中断后都会进行更新。公式为：
<code>
    if (se.load.weight != NICE_0_LOAD)
        vruntime += delta * NICE_0_LOAD / se.load.weight;
    else
        vruntime += delta;
</code>
delta是进程增加的实际的运行时间。 NICE_0_LOAD为nice 0进程的权重。虚拟运行时间与权重成反比，进程的权重越大虚拟运行时间就增加得越慢，位置就越左，越有可能被调度。</p>

<p>对cfs的理解最好就是看源代码了，下面贴出代码（网上有人整理得很好了）：<br/>
    各个函数的调用关系图：<br/>
（1）</p>

<p><img src="/images/kernel/2015-01-22-10.png" alt="" /></p>

<pre><code>    tick中断
    在tick中断处理函数中,会调用scheduler_tick()函数.该函数代码如下:
    在tick中断处理函数中，会调用scheduler_tick()函数。该函数代码如下:
    void scheduler_tick(void)
    {
      /*取得当前CPU*/
    int cpu = smp_processor_id();
    /*取得当前CPU对应的runqueue*/
        struct rq *rq = cpu_rq(cpu);
    /*当前运行的进程*/
        struct task_struct *curr = rq-&gt;curr;

        sched_clock_tick();

        spin_lock(&amp;rq-&gt;lock);
        /*更新rq的当前时间戳.即使rq-&gt;clock变为当前时间戳*/
        update_rq_clock(rq);scheduler_tick()
        /*更新rq的负载*/
        update_cpu_load(rq);
        /*调用调度模块的task_tick函数*/
        curr-&gt;sched_class-&gt;task_tick(rq, curr, 0);
        spin_unlock(&amp;rq-&gt;lock);

    #ifdef CONFIG_SMP
        rq-&gt;idle_at_tick = idle_cpu(cpu);
        trigger_load_balance(rq, cpu);
    #endif
    }
    我们从上面的代码中可以看到,经过一部份共同处理之后,流程会转入调度模块的task_tick()函数.
    对应CFS,它的sched_class结构如下:
    static const struct sched_class fair_sched_class = {
        .next = &amp;idle_sched_class,
        .enqueue_task = enqueue_task_fair,
        .dequeue_task = dequeue_task_fair,
        .yield_task = yield_task_fair,

        .check_preempt_curr = check_preempt_wakeup,

        .pick_next_task = pick_next_task_fair,
        .put_prev_task = put_prev_task_fair,

    #ifdef CONFIG_SMP
        .select_task_rq = select_task_rq_fair,

        .load_balance = load_balance_fair,
        .move_one_task = move_one_task_fair,
    #endif

        .set_curr_task = set_curr_task_fair,
        .task_tick = task_tick_fair,
        .task_new = task_new_fair,

        .prio_changed = prio_changed_fair,
        .switched_to = switched_to_fair,

    #ifdef CONFIG_FAIR_GROUP_SCHED
        .moved_group = moved_group_fair,
    #endif
    };
    即对应task_tick的处理函数为task_tick_fair().代码如下:
</code></pre>

<p>（2）<br/>
<img src="/images/kernel/2015-01-22-11.png" alt="" /></p>

<pre><code>    schedule()的执行过程
    当进程需要被抢占或者是进程主运让出处理器,则会调用schedule()函数.为了减小篇幅,在这里就不分析schedule()函数代码.只列出在该函数中调用模块的主要函数.如下示:
    Schedule()----&gt;
    sched_class-&gt;put_prev_task(rq,prev)----&gt;
    sched_class-&gt;pick_next_task()

    对应到CFS中,put_prev_task()函数为put_prev_task_fair(),该操作就是将进程放回队列.
</code></pre>

<p>（3）<br/>
<img src="/images/kernel/2015-01-22-12.png" alt="" /></p>

<pre><code>    新进程的调度过程
    在创建新进程的时候,在do_fork()中有如下过程:
    long do_fork(unsigned long clone_flags,
              unsigned long stack_start,
              struct pt_regs *regs,
              unsigned long stack_size,
              int __user *parent_tidptr,
              int __user *child_tidptr)
    {


    if (unlikely(clone_flags &amp; CLONE_STOPPED)) {
                /*
                 * We'll start up with an immediate SIGSTOP.
                 */
                sigaddset(&amp;p-&gt;pending.signal, SIGSTOP);
                set_tsk_thread_flag(p, TIF_SIGPENDING);
                __set_task_state(p, TASK_STOPPED);
            } else {
                wake_up_new_task(p, clone_flags);
            }

    ｝
    即在末带CLONE_STOPPED标志创建进程时,就会对新进程调用wake_up_new_task().
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[linux内核分析之调度算法（一）]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/01/14/kernel-sched-alg1/"/>
    <updated>2015-01-14T23:49:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/01/14/kernel-sched-alg1</id>
    <content type="html"><![CDATA[<p><a href="http://blog.csdn.net/bullbat/article/details/7160246">http://blog.csdn.net/bullbat/article/details/7160246</a></p>

<p>linux调度算法在2.6.32中采用调度类实现模块式的调度方式。这样，能够很好的加入新的调度算法。</p>

<p>linux调度器是以模块方式提供的，这样做的目的是允许不同类型的进程可以有针对性地选择调度算法。这种模块化结构被称为调度器类，他允许多种不同哦可动态添加的调度算法并存，调度属于自己范畴的进程。每个调度器都有一个优先级，调度代码会按照优先级遍历调度类，拥有一个可执行进程的最高优先级的调度器类胜出，去选择下面要执行的那个程序。</p>

<p>linux上主要有两大类调度算法，CFS(完全公平调度算法）和实时调度算法。宏SCHED_NOMAL主要用于CFS调度，而SCHED_FIFO和SCHED_RR主要用于实时调度。如下面的宏定义：
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
<span class='line-number'>217</span>
<span class='line-number'>218</span>
<span class='line-number'>219</span>
<span class='line-number'>220</span>
<span class='line-number'>221</span>
<span class='line-number'>222</span>
<span class='line-number'>223</span>
<span class='line-number'>224</span>
<span class='line-number'>225</span>
<span class='line-number'>226</span>
<span class='line-number'>227</span>
<span class='line-number'>228</span>
<span class='line-number'>229</span>
<span class='line-number'>230</span>
<span class='line-number'>231</span>
<span class='line-number'>232</span>
<span class='line-number'>233</span>
<span class='line-number'>234</span>
<span class='line-number'>235</span>
<span class='line-number'>236</span>
<span class='line-number'>237</span>
<span class='line-number'>238</span>
<span class='line-number'>239</span>
<span class='line-number'>240</span>
<span class='line-number'>241</span>
<span class='line-number'>242</span>
<span class='line-number'>243</span>
<span class='line-number'>244</span>
<span class='line-number'>245</span>
<span class='line-number'>246</span>
<span class='line-number'>247</span>
<span class='line-number'>248</span>
<span class='line-number'>249</span>
<span class='line-number'>250</span>
<span class='line-number'>251</span>
<span class='line-number'>252</span>
<span class='line-number'>253</span>
<span class='line-number'>254</span>
<span class='line-number'>255</span>
<span class='line-number'>256</span>
<span class='line-number'>257</span>
<span class='line-number'>258</span>
<span class='line-number'>259</span>
<span class='line-number'>260</span>
<span class='line-number'>261</span>
<span class='line-number'>262</span>
<span class='line-number'>263</span>
<span class='line-number'>264</span>
<span class='line-number'>265</span>
<span class='line-number'>266</span>
<span class='line-number'>267</span>
<span class='line-number'>268</span>
<span class='line-number'>269</span>
<span class='line-number'>270</span>
<span class='line-number'>271</span>
<span class='line-number'>272</span>
<span class='line-number'>273</span>
<span class='line-number'>274</span>
<span class='line-number'>275</span>
<span class='line-number'>276</span>
<span class='line-number'>277</span>
<span class='line-number'>278</span>
<span class='line-number'>279</span>
<span class='line-number'>280</span>
<span class='line-number'>281</span>
<span class='line-number'>282</span>
<span class='line-number'>283</span>
<span class='line-number'>284</span>
<span class='line-number'>285</span>
<span class='line-number'>286</span>
<span class='line-number'>287</span>
<span class='line-number'>288</span>
<span class='line-number'>289</span>
<span class='line-number'>290</span>
<span class='line-number'>291</span>
<span class='line-number'>292</span>
<span class='line-number'>293</span>
<span class='line-number'>294</span>
<span class='line-number'>295</span>
<span class='line-number'>296</span>
<span class='line-number'>297</span>
<span class='line-number'>298</span>
<span class='line-number'>299</span>
<span class='line-number'>300</span>
<span class='line-number'>301</span>
<span class='line-number'>302</span>
<span class='line-number'>303</span>
<span class='line-number'>304</span>
<span class='line-number'>305</span>
<span class='line-number'>306</span>
<span class='line-number'>307</span>
<span class='line-number'>308</span>
<span class='line-number'>309</span>
<span class='line-number'>310</span>
<span class='line-number'>311</span>
<span class='line-number'>312</span>
<span class='line-number'>313</span>
<span class='line-number'>314</span>
<span class='line-number'>315</span>
<span class='line-number'>316</span>
<span class='line-number'>317</span>
<span class='line-number'>318</span>
<span class='line-number'>319</span>
<span class='line-number'>320</span>
<span class='line-number'>321</span>
<span class='line-number'>322</span>
<span class='line-number'>323</span>
<span class='line-number'>324</span>
<span class='line-number'>325</span>
<span class='line-number'>326</span>
<span class='line-number'>327</span>
<span class='line-number'>328</span>
<span class='line-number'>329</span>
<span class='line-number'>330</span>
<span class='line-number'>331</span>
<span class='line-number'>332</span>
<span class='line-number'>333</span>
<span class='line-number'>334</span>
<span class='line-number'>335</span>
<span class='line-number'>336</span>
<span class='line-number'>337</span>
<span class='line-number'>338</span>
<span class='line-number'>339</span>
<span class='line-number'>340</span>
<span class='line-number'>341</span>
<span class='line-number'>342</span>
<span class='line-number'>343</span>
<span class='line-number'>344</span>
<span class='line-number'>345</span>
<span class='line-number'>346</span>
<span class='line-number'>347</span>
<span class='line-number'>348</span>
<span class='line-number'>349</span>
<span class='line-number'>350</span>
<span class='line-number'>351</span>
<span class='line-number'>352</span>
<span class='line-number'>353</span>
<span class='line-number'>354</span>
<span class='line-number'>355</span>
<span class='line-number'>356</span>
<span class='line-number'>357</span>
<span class='line-number'>358</span>
<span class='line-number'>359</span>
<span class='line-number'>360</span>
<span class='line-number'>361</span>
<span class='line-number'>362</span>
<span class='line-number'>363</span>
<span class='line-number'>364</span>
<span class='line-number'>365</span>
<span class='line-number'>366</span>
<span class='line-number'>367</span>
<span class='line-number'>368</span>
<span class='line-number'>369</span>
<span class='line-number'>370</span>
<span class='line-number'>371</span>
<span class='line-number'>372</span>
<span class='line-number'>373</span>
<span class='line-number'>374</span>
<span class='line-number'>375</span>
<span class='line-number'>376</span>
<span class='line-number'>377</span>
<span class='line-number'>378</span>
<span class='line-number'>379</span>
<span class='line-number'>380</span>
<span class='line-number'>381</span>
<span class='line-number'>382</span>
<span class='line-number'>383</span>
<span class='line-number'>384</span>
<span class='line-number'>385</span>
<span class='line-number'>386</span>
<span class='line-number'>387</span>
<span class='line-number'>388</span>
<span class='line-number'>389</span>
<span class='line-number'>390</span>
<span class='line-number'>391</span>
<span class='line-number'>392</span>
<span class='line-number'>393</span>
<span class='line-number'>394</span>
<span class='line-number'>395</span>
<span class='line-number'>396</span>
<span class='line-number'>397</span>
<span class='line-number'>398</span>
<span class='line-number'>399</span>
<span class='line-number'>400</span>
<span class='line-number'>401</span>
<span class='line-number'>402</span>
<span class='line-number'>403</span>
<span class='line-number'>404</span>
<span class='line-number'>405</span>
<span class='line-number'>406</span>
<span class='line-number'>407</span>
<span class='line-number'>408</span>
<span class='line-number'>409</span>
<span class='line-number'>410</span>
<span class='line-number'>411</span>
<span class='line-number'>412</span>
<span class='line-number'>413</span>
<span class='line-number'>414</span>
<span class='line-number'>415</span>
<span class='line-number'>416</span>
<span class='line-number'>417</span>
<span class='line-number'>418</span>
<span class='line-number'>419</span>
<span class='line-number'>420</span>
<span class='line-number'>421</span>
<span class='line-number'>422</span>
<span class='line-number'>423</span>
<span class='line-number'>424</span>
<span class='line-number'>425</span>
<span class='line-number'>426</span>
<span class='line-number'>427</span>
<span class='line-number'>428</span>
<span class='line-number'>429</span>
<span class='line-number'>430</span>
<span class='line-number'>431</span>
<span class='line-number'>432</span>
<span class='line-number'>433</span>
<span class='line-number'>434</span>
<span class='line-number'>435</span>
<span class='line-number'>436</span>
<span class='line-number'>437</span>
<span class='line-number'>438</span>
<span class='line-number'>439</span>
<span class='line-number'>440</span>
<span class='line-number'>441</span>
<span class='line-number'>442</span>
<span class='line-number'>443</span>
<span class='line-number'>444</span>
<span class='line-number'>445</span>
<span class='line-number'>446</span>
<span class='line-number'>447</span>
<span class='line-number'>448</span>
<span class='line-number'>449</span>
<span class='line-number'>450</span>
<span class='line-number'>451</span>
<span class='line-number'>452</span>
<span class='line-number'>453</span>
<span class='line-number'>454</span>
<span class='line-number'>455</span>
<span class='line-number'>456</span>
<span class='line-number'>457</span>
<span class='line-number'>458</span>
<span class='line-number'>459</span>
<span class='line-number'>460</span>
<span class='line-number'>461</span>
<span class='line-number'>462</span>
<span class='line-number'>463</span>
<span class='line-number'>464</span>
<span class='line-number'>465</span>
<span class='line-number'>466</span>
<span class='line-number'>467</span>
<span class='line-number'>468</span>
<span class='line-number'>469</span>
<span class='line-number'>470</span>
<span class='line-number'>471</span>
<span class='line-number'>472</span>
<span class='line-number'>473</span>
<span class='line-number'>474</span>
<span class='line-number'>475</span>
<span class='line-number'>476</span>
<span class='line-number'>477</span>
<span class='line-number'>478</span>
<span class='line-number'>479</span>
<span class='line-number'>480</span>
<span class='line-number'>481</span>
<span class='line-number'>482</span>
<span class='line-number'>483</span>
<span class='line-number'>484</span>
<span class='line-number'>485</span>
<span class='line-number'>486</span>
<span class='line-number'>487</span>
<span class='line-number'>488</span>
<span class='line-number'>489</span>
<span class='line-number'>490</span>
<span class='line-number'>491</span>
<span class='line-number'>492</span>
<span class='line-number'>493</span>
<span class='line-number'>494</span>
<span class='line-number'>495</span>
<span class='line-number'>496</span>
<span class='line-number'>497</span>
<span class='line-number'>498</span>
<span class='line-number'>499</span>
<span class='line-number'>500</span>
<span class='line-number'>501</span>
<span class='line-number'>502</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/&lt;em&gt;
</span><span class='line'> * Scheduling policies
</span><span class='line'> &lt;/em&gt;/
</span><span class='line'> /&lt;em&gt;支援Real-Time Task的排程,包括有SCHED_FIFO與SCHED_RR.
</span><span class='line'> &lt;/em&gt;/&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt; /*(也稱為SCHED_OTHER): 主要用以排程
</span><span class='line'> 一般目的的Task.*/
</span><span class='line'>#define SCHED_NORMAL        0
</span><span class='line'>#define SCHED_FIFO      1
</span><span class='line'>/*task預設的 Time Slice長度為100 msecs*/
</span><span class='line'>#define SCHED_RR        2
</span><span class='line'>/*主要用以讓Task可以延長執行的時間
</span><span class='line'>(Time Slice),減少被中斷發生Task Context-Switch
</span><span class='line'>的次數.藉此可以提高 Cache的利用率 
</span><span class='line'>(每次Context-Switch都會導致Cache-Flush). 比
</span><span class='line'>較適合用在固定週期執行的Batch Jobs任
</span><span class='line'>務主機上,而不適合用在需要使用者互
</span><span class='line'>動的產品 (會由於Task切換的延遲,而
</span><span class='line'>感覺到系統效能不佳或是反應太慢).*/
</span><span class='line'>#define SCHED_BATCH     3
</span><span class='line'>/* SCHED_ISO: reserved but not implemented yet */
</span><span class='line'>/*為系統中的Idle Task排程.*/
</span><span class='line'>#define SCHED_IDLE      5
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>
</span><span class='line'>linux调度算法实现的高层数据结构主要有运行实体、调度类、运行队列，下面我们主要看看这几个数据结构的字段和意义。  
</span><span class='line'>运行实体，rq结构体每个cpu有一个，主要存储一些基本的用于调度的信息，包括实时调度的和CFS调度的
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt; /*每个处理器都会配置一个rq*/
</span><span class='line'>struct rq {
</span><span class='line'>/* runqueue lock: */
</span><span class='line'>spinlock_t lock;
</span><span class='line'>
</span><span class='line'>/*
</span><span class='line'> * nr_running and cpu_load should be in the same cacheline because
</span><span class='line'> * remote CPUs use both these fields when doing load calculation.
</span><span class='line'> */
</span><span class='line'> /*用以记录目前处理器rq中执行task的数量*/
</span><span class='line'>unsigned long nr_running;
</span><span class='line'>#define CPU_LOAD_IDX_MAX 5
</span><span class='line'>/*用以表示处理器的负载，在每个处理器的rq中
</span><span class='line'>都会有对应到该处理器的cpu_load参数配置，在每次
</span><span class='line'>处理器触发scheduler tick时，都会呼叫函数
</span><span class='line'>update_cpu_load_active,进行cpu_load的更新。在系统初始化的时候
</span><span class='line'>会呼叫函数sched_init把rq的cpu_load array初始化为0.
</span><span class='line'>了解他的更新方式最好的方式是通过函数update_cpu_load,公式如下澹?
</span><span class='line'>cpu_load[0]会直接等待rq中load.weight的值。
</span><span class='line'>cpu_load[1]=(cpu_load[1]*(2-1)+cpu_load[0])/2
</span><span class='line'>cpu_load[2]=(cpu_load[2]*(4-1)+cpu_load[0])/4
</span><span class='line'>cpu_load[3]=(cpu_load[3]*(8-1)+cpu_load[0])/8
</span><span class='line'>cpu_load[4]=(cpu_load[4]*(16-1)+cpu_load[0]/16
</span><span class='line'>呼叫函数this_cpu_load时，所返回的cpu load值是cpu_load[0]
</span><span class='line'>而在进行cpu blance或migration时，就会呼叫函数
</span><span class='line'>source_load target_load取得对该处理器cpu_load index值，
</span><span class='line'>来进行计算*/
</span><span class='line'>unsigned long cpu_load[CPU_LOAD_IDX_MAX];
</span><span class='line'>#ifdef CONFIG_NO_HZ
</span><span class='line'>unsigned long last_tick_seen;
</span><span class='line'>unsigned char in_nohz_recently;
</span><span class='line'>#endif
</span><span class='line'>/* capture load from *all* tasks on this cpu: */
</span><span class='line'>/*load-&gt;weight值，会是目前所执行的schedule entity的
</span><span class='line'>load-&gt;weight的总和，也就是说rq的load-&gt;weight越高，
</span><span class='line'>也表示所负责的排程单元load-&gt;weight总和越高
</span><span class='line'>表示处理器所负荷的执行单元也越重*/
</span><span class='line'>struct load_weight load;
</span><span class='line'>/*在每次scheduler tick中呼叫update_cpu_load时，
</span><span class='line'>这个值就增加一，可以用来反馈目前cpu
</span><span class='line'>load更新的次数*/
</span><span class='line'>unsigned long nr_load_updates;
</span><span class='line'>/*用来累加处理器进行context switch的次数，会在
</span><span class='line'>函数schedule呼叫时进行累加，并可以通过函数
</span><span class='line'>nr_context_switches统计目前所有处理器总共的context switch
</span><span class='line'>次数，或是可以透过查看档案/proc/stat中的ctxt位得知目前
</span><span class='line'>整个系统触发context switch的次数*/
</span><span class='line'>u64 nr_switches;
</span><span class='line'>
</span><span class='line'>u64 nr_migrations_in;
</span><span class='line'>/*为cfs fair scheduling class 的rq*/
</span><span class='line'>struct cfs_rq cfs;
</span><span class='line'>/*为real-time scheduling class 的rq*/
</span><span class='line'>struct rt_rq rt;
</span><span class='line'>
</span><span class='line'>/*用以支援可以group cfs tasks的机制*/
</span><span class='line'>#ifdef CONFIG_FAIR_GROUP_SCHED
</span><span class='line'>/* list of leaf cfs_rq on this cpu: */
</span><span class='line'>/*在有设置fair group scheduling 的环境下，
</span><span class='line'>会基于原本cfs rq中包含有若干task的group
</span><span class='line'>所成的排程集合，也就是说当有一个group a
</span><span class='line'>就会有自己的cfs rq用来排程自己所属的tasks,
</span><span class='line'>而属于这group a的tasks所使用到的处理器时间
</span><span class='line'>就会以这group a总共所分的的时间为上限。
</span><span class='line'>基于cgroup的fair group scheduling 架构，可以创造出
</span><span class='line'>有阶层性的task组织，根据不同task的功能群组化
</span><span class='line'>在配置给该群主对应的处理器资源，让属于
</span><span class='line'>该群主下的task可以透过rq机制排程。使用属于
</span><span class='line'>该群主下的资源。
</span><span class='line'>这个变数主要是管理CFS RQ list，操作上可以透过函数
</span><span class='line'>list_add_leaf_cfs_rq把一个group cfs rq加入到list中，或透过
</span><span class='line'>函数list_del_leaf_cfs_rq把一个group cfs rq移除，并可以
</span><span class='line'>透过for_each_leaf_cfs_rq把一个rq上得所有leaf cfs_rq走一遍
</span><span class='line'>*/
</span><span class='line'>struct list_head leaf_cfs_rq_list;
</span><span class='line'>#endif
</span><span class='line'>/*用以支援可以group real-time tasks的机制*/
</span><span class='line'>#ifdef CONFIG_RT_GROUP_SCHED
</span><span class='line'>/*类似leaf_cfs_rq_list所扮演的角色，只是这里
</span><span class='line'>是针对属于real-time的task,在实际操作上可以
</span><span class='line'>透过函数list_add_leaf_rt_rq,list_del_leaf_rt_rq或
</span><span class='line'>巨集for_each_leaf_rt_rq*/
</span><span class='line'>struct list_head leaf_rt_rq_list;
</span><span class='line'>#endif
</span><span class='line'>
</span><span class='line'>/*
</span><span class='line'> * This is part of a global counter where only the total sum
</span><span class='line'> * over all CPUs matters. A task can increase this counter on
</span><span class='line'> * one CPU and if it got migrated afterwards it may decrease
</span><span class='line'> * it on another CPU. Always updated under the runqueue lock:
</span><span class='line'> */
</span><span class='line'> /*一般来说，linux kernel 的task状态可以为TASK_RUNNING
</span><span class='line'> TASK_INTERRUPTIBLE(sleep),
</span><span class='line'> TASK_UNINTERRUPTIBLE(Deactivate Task,此时Task会从rq中
</span><span class='line'> 移除)或TASK_STOPPED.
</span><span class='line'> 透过这个变数会统计目前rq中有多少task属于
</span><span class='line'> TASK_UNINTERRUPTIBLE的状态。当呼叫函数
</span><span class='line'> active_task时，会把nr_uninterruptible值减一，并透过 该函数
</span><span class='line'>enqueue_task把对应的task依据所在的scheduling class
</span><span class='line'>放在 对应的rq中，并把目前rq中nr_running值加一*/
</span><span class='line'>unsigned long nr_uninterruptible;
</span><span class='line'>/*curr:指向目前处理器正在执行的task;
</span><span class='line'>idle:指向属于idle-task scheduling class 的idle task;
</span><span class='line'>stop:指向目前最高等级属于stop-task scheduling class
</span><span class='line'>的task;*/
</span><span class='line'>struct task_struct *curr, *idle;
</span><span class='line'>/*基于处理器的jiffies值，用以记录下次进行处理器
</span><span class='line'>balancing 的时间点*/
</span><span class='line'>unsigned long next_balance;
</span><span class='line'>/*用以存储context-switch发生时，前一个task的memory management
</span><span class='line'>结构并可用在函数finish_task_switch中，透过函数mmdrop释放前一个
</span><span class='line'>task的记忆体资源*/    
</span><span class='line'>struct mm_struct *prev_mm;
</span><span class='line'>/*用以记录目前rq的clock值，基本上该值会等于透过sched_clock_cpu
</span><span class='line'>(cpu_of(rq))的回传值，并会在每次呼叫scheduler_tick时透过
</span><span class='line'>函数update_rq_clock更新目前rq clock值。
</span><span class='line'>在实作部分，函数sched_clock_cpu会透过sched_clock_local或
</span><span class='line'>ched_clock_remote取得对应的sched_clock_data,而处理的sched_clock_data
</span><span class='line'>值，会透过函数sched_clock_tick在每次呼叫scheduler_tick时进行更新；
</span><span class='line'>*/
</span><span class='line'>u64 clock;
</span><span class='line'>/*用以记录目前rq中有多少task处于等待i/o的sleep状态
</span><span class='line'>在实际的使用上，例如当driver接受来自task的调用，但处于等待i/o
</span><span class='line'>回复的阶段时，为了充分利用处理器的执行资源，这时
</span><span class='line'>就可以在driver中呼叫函数io_schedule，此时
</span><span class='line'>就会把目前rq中的nr_iowait加一，并设定目前task的io_wait为1
</span><span class='line'>然后触发scheduling 让其他task有机会可以得到处理器执行时间*/
</span><span class='line'>atomic_t nr_iowait;
</span><span class='line'>
</span><span class='line'>#ifdef CONFIG_SMP
</span><span class='line'>/*root domain是基于多核心架构下的机制，
</span><span class='line'>会由rq结构记住目前采用的root domain，其中包括了
</span><span class='line'>目前的cpu mask(包括span,online rt overload), reference count 跟cpupri
</span><span class='line'>当root domain有被rq参考到时，refcount 就加一，反之就减一。而cpu
</span><span class='line'>mask span表示rq可挂上的cpu mask,noline为rq目前已经排程的
</span><span class='line'>cpu mask cpu上执行real-time task.可以参考函数pull_rt_task，当一个rq中属于
</span><span class='line'>real-time的task已经执行完毕，就会透过函数pull_rt_task从该
</span><span class='line'>rq中属于rto_mask cpu mask 可以执行的处理器上，找出是否有一个处理器
</span><span class='line'>有大于一个以上的real-time task，若有就会转到目前这个执行完成
</span><span class='line'>real-time task 的处理器上
</span><span class='line'>而cpupri不同于Task本身有区分140個(0-139)
</span><span class='line'>Task Priority (0-99為RT Priority 而 100-139為Nice值 -20-19). 
</span><span class='line'>CPU Priority本身有102個Priority (包括,-1 為Invalid,
</span><span class='line'>0為Idle,1為Normal,2-101對應到Real-Time Priority 0-99).
</span><span class='line'>參考函式convert_prio, Task Priority如果是 140就會對應到
</span><span class='line'>CPU Idle,如果是大於等於100就會對應到CPU Normal,
</span><span class='line'>若是Task Priority介於0-99之間,就會對應到CPU Real-Time Priority 101-2之間.) 
</span><span class='line'>在實際的操作上,例如可以透過函式cpupri_find
</span><span class='line'>帶入一個要插入的Real-Time Task,此時就會依據cpupri中
</span><span class='line'>pri_to_cpu選擇一個目前執行Real-Time Task且該Task
</span><span class='line'>的優先級比目前要插入的Task更低的處理器,
</span><span class='line'>並透過CPU Mask(lowest_mask)返回目前可以選擇的處理器Mask.
</span><span class='line'>實作的部份可以參考檔案kernel/sched_cpupri.c.
</span><span class='line'>在初始化的過程中,會透過函式sched_init呼叫函式init_defrootdomain,
</span><span class='line'>對Root Domain與 CPU Priority機制進行初始化.
</span><span class='line'>*/
</span><span class='line'>struct root_domain *rd;
</span><span class='line'>/*Schedule Domain是基於多核心架構下的機制.
</span><span class='line'>每個處理器都會有一個基礎的Scheduling Domain,
</span><span class='line'>Scheduling Domain可以有階層性的架構,透過parent
</span><span class='line'>可以找到上一層的Domain,或是透過child找到
</span><span class='line'>下一層的 Domain (NULL表示結尾.).並可透過span
</span><span class='line'>栏位,表示這個Domain所能涵蓋的處理器範圍.
</span><span class='line'>通常Base Domain會涵蓋系統中所有處理器的個數,
</span><span class='line'>而Child Domain所能涵蓋的處理器個數不超過它的
</span><span class='line'>Parent Domain. 而當在進行Scheduling Domain 中的Task Balance
</span><span class='line'>時,就會以該Domain所能涵蓋的處理器為最大範圍.
</span><span class='line'>同時,每個Schedule Domain都會包括一個或一個以上的
</span><span class='line'>CPU Groups (結構為struct sched_group),並透過next變數把
</span><span class='line'>CPU Groups串連在一起(成為一個單向的Circular linked list),
</span><span class='line'>每個CPU Group都會有變數cpumask來定义這個CPU Group
</span><span class='line'>所涵蓋的處理器範圍.並且CPU Group所包括的處理器
</span><span class='line'>範圍,必需涵蓋在所屬的Schedule Domain處理器範圍中.
</span><span class='line'>當進行Scheduling Domain的Balancing時,會以其下的CPU Groups
</span><span class='line'>為單位,根據cpu_power （會是該Group所涵蓋的處理器
</span><span class='line'>Tasks Loading的總和）來比較不同的CPU Groups的負荷,
</span><span class='line'>以進行Tasks的移動,達到Balancing的目的.
</span><span class='line'>在有支援SMP的架構下,會在函式sched_init中,呼叫open_softirq,
</span><span class='line'>註冊 SCHED_SOFTIRQ Software IRQ与其对应的 Callback函式 
</span><span class='line'>run_rebalance_domains. 並會在每次呼叫函式scheduler_tick時,
</span><span class='line'>透過函式trigger_load_balance确认是否目前的jiffies值已經
</span><span class='line'>大於RunQueue下一次要觸發Load Balance的next_balance時間值,
</span><span class='line'>並透過函式raise_softirq觸發SCHED_SOFTIRQ Software IRQ. 
</span><span class='line'>在Software IRQ觸發後,就會呼叫函式run_rebalance_domains,
</span><span class='line'>並在函式rebalance_domains中,進行后续處理器上的
</span><span class='line'>Scheduling Domain Load Balance動作.
</span><span class='line'>有關Scheduling Domain進一步的內容,也可以參考
</span><span class='line'>Linux Kernel文件 Documentation/scheduler/sched-domains.txt.
</span><span class='line'>*/
</span><span class='line'>struct sched_domain *sd;
</span><span class='line'>/*這值會等於函式idle_cpu的返回值,如果為1表示
</span><span class='line'>目前CPU RunQueue中執行的為Idle Task. 反之為0,
</span><span class='line'>則表示處理器執行的不是Idle Task (也就是說
</span><span class='line'>處理器正在忙碌中.).*/
</span><span class='line'>unsigned char idle_at_tick;
</span><span class='line'>/* For active balancing */
</span><span class='line'>/*若這值不為0,表示會有在Schedule排程動作
</span><span class='line'>結束前,要呼叫的收尾函式. (实作為inline函式
</span><span class='line'>post_schedule in kernel/sched.c),目前只有Real-Time Scheduling 
</span><span class='line'>Class有支援這個機制(會呼叫函式has_pushable_tasks 
</span><span class='line'>in kernel/sched_rt.c).*/
</span><span class='line'>int post_schedule;
</span><span class='line'>/*當RunQueue中此值為1,表示這個RunQueue正在進行
</span><span class='line'>Fair Scheduling的Load Balance,此時會呼叫stop_one_cpu_nowait
</span><span class='line'>暫停該RunQueue所屬處理器的排程,並透過函式
</span><span class='line'>active_load_balance_cpu_stop,把Tasks從最忙碌的處理器,
</span><span class='line'>移到Idle的處理器上執行.*/
</span><span class='line'>int active_balance;
</span><span class='line'>/*用以儲存目前進入Idle且負責進行 Load Balance
</span><span class='line'>流程的處理器ID. 呼叫的流程為,在呼叫函式schedule時,
</span><span class='line'>若該處理器RunQueue的nr_running為0 (也就是目前沒有
</span><span class='line'>正在執行的Task),就會呼叫idle_balance,並觸發後續Load 
</span><span class='line'>Balance流程.*/
</span><span class='line'>int push_cpu;
</span><span class='line'>/* cpu of this runqueue: */
</span><span class='line'>/*用以儲存目前运作這個RunQueue的處理器ID*/
</span><span class='line'>int cpu;
</span><span class='line'>/*為1表示目前此RunQueue有在對應的處理器掛上
</span><span class='line'>並執行.*/
</span><span class='line'>int online;
</span><span class='line'>/*如果RunQueue中目前有Task正在執行,這個值會
</span><span class='line'>等於目前該RunQueue的Load Weight除以目前RunQueue
</span><span class='line'>中Task數目的均值. 
</span><span class='line'>(rq-&gt;avg_load_per_task = rq-&gt;load.weight / nr_running;).*/
</span><span class='line'>unsigned long avg_load_per_task;
</span><span class='line'>
</span><span class='line'>struct task_struct *migration_thread;
</span><span class='line'>struct list_head migration_queue;
</span><span class='line'>/*這個值會由Real-Time Scheduling Class呼叫函式
</span><span class='line'>update_curr_rt,用以統計目前Real-Time Task執行時間的
</span><span class='line'>均值,在這函式中會以目前RunQueue的clock_task
</span><span class='line'>減去目前Task執行的起始時間,取得執行時間的
</span><span class='line'>Delta值. (delta_exec = rq-&gt;clock_task – curr-&gt;se.exec_start; ).
</span><span class='line'>在透過函式sched_rt_avg_update把這Delta值跟原本
</span><span class='line'>RunQueue中的rt_avg值取平均值. 以運作的週期來看,
</span><span class='line'>這個值可反應目前系統中Real-Time Task平均被
</span><span class='line'>分配到的執行時間值.*/
</span><span class='line'>u64 rt_avg;
</span><span class='line'>/*這個值主要在函式sched_avg_update更新,以笔者手中
</span><span class='line'>的Linux Kernel 2.6.38.6的實作來說,當RunQueue Clock
</span><span class='line'>減去age_stamp大於 0.5秒 (=sched_avg_period),就會把這值
</span><span class='line'>累加0.5秒 (單位都是nanoseconds). 從函式scale_rt_power
</span><span class='line'>的實作來說,age_stamp值離RunQueue Clock越遠,表示total
</span><span class='line'>值越大,available值也越大,而函式scale_rt_power返回的
</span><span class='line'>div_u64計算結果也越大,最終 RunQueue的cpu_power
</span><span class='line'>與Scheduling Domain中的Scheduling Group的cpu_power
</span><span class='line'>值也就越大. (可參考函式update_cpu_power的實作).*/
</span><span class='line'>u64 age_stamp;
</span><span class='line'>/*這值會在觸發Scheduling時,若判斷目前處理器
</span><span class='line'>RunQueue沒有正在運作的Task,就會透過函式
</span><span class='line'>idle_balance更新這值為為目前RunQueue的clock值.
</span><span class='line'>可用以表示這個處理器是何時進入到Idle的
</span><span class='line'>狀態*/
</span><span class='line'>u64 idle_stamp;
</span><span class='line'>/*會在有Task運作且idle_stamp不為0 (表示前一個
</span><span class='line'>狀態是在Idle)時以目前RunQueue的clock減去
</span><span class='line'>idle_stmp所計算出的Delta值為依據,更新這個值
</span><span class='line'>. 可反應目前處理器進入Idle狀態的時間長短*/
</span><span class='line'>u64 avg_idle;
</span><span class='line'>#endif
</span><span class='line'>
</span><span class='line'>/* calc_load related fields */
</span><span class='line'>/*用以記錄下一次計算CPU Load的時間,初始值
</span><span class='line'>為目前的jiffies加上五秒與1次的Scheduling Tick的
</span><span class='line'>間隔 (=jiffies + LOAD_FREQ,且LOAD_FREQ=(5*HZ+1))*/
</span><span class='line'>unsigned long calc_load_update;
</span><span class='line'>/*會等於RunQueue中nr_running與nr_uninterruptible的
</span><span class='line'>總和.（可參考函式calc_load_fold_active）.*/
</span><span class='line'>long calc_load_active;
</span><span class='line'>
</span><span class='line'>#ifdef CONFIG_SCHED_HRTICK
</span><span class='line'>#ifdef CONFIG_SMP
</span><span class='line'>/*在函式init_rq_hrtick初始化RunQueue High-Resolution 
</span><span class='line'>Tick時,此值預設為0.
</span><span class='line'>在函式hrtick_start中,會判斷目前觸發的RunQueue
</span><span class='line'>跟目前處理器所使用的RunQueue是否一致,
</span><span class='line'>若是,就直接呼叫函式hrtimer_restart,反之就會
</span><span class='line'>依據RunQueue中hrtick_csd_pending的值,如果
</span><span class='line'>hrtick_csd_pending為0,就會透過函式
</span><span class='line'>__smp_call_function_single讓RunQueue所在的另一個
</span><span class='line'>處理器執行rq-&gt;hrtick_csd.func 所指到的函式 
</span><span class='line'>__hrtick_start. 並等待該處理器執行完畢後,
</span><span class='line'>才重新把hrtick_csd_pending設定為1.
</span><span class='line'>也就是說, RunQueue的hrtick_csd_pending是用來作為
</span><span class='line'>SMP架構下,由處理器A觸發處理器B執行
</span><span class='line'>_hrtick_start函式的一個保護機制.而有關在
</span><span class='line'>SMP下如何由一個處理器觸發另一個處理器
</span><span class='line'>執行函式的機制,可以參考kernel/smp.c中
</span><span class='line'>相關smp_call_function_xxxxxxx的實作.s*/
</span><span class='line'>int hrtick_csd_pending;
</span><span class='line'>/*用以儲存hrtick機制中,要跨處理器執行的
</span><span class='line'>函式結構.*/
</span><span class='line'>struct call_single_data hrtick_csd;
</span><span class='line'>#endif
</span><span class='line'>/*為High-Resolution Tick的结构,會透過函式
</span><span class='line'>hrtimer_init初始化.*/
</span><span class='line'>struct hrtimer hrtick_timer;
</span><span class='line'>#endif
</span><span class='line'>
</span><span class='line'>#ifdef CONFIG_SCHEDSTATS
</span><span class='line'>/* latency stats */
</span><span class='line'>/*為Scheduling Info.的統計結構,可以參考
</span><span class='line'>include/linux/sched.h中的宣告. 例如在每次觸發
</span><span class='line'>Schedule時,呼叫函式schedule_debug對上一個Task
</span><span class='line'>的lock_depth進行確認(Fork一個新的Process 時,
</span><span class='line'>會把此值預設為-1就是No-Lock,當呼叫
</span><span class='line'>Kernel Lock時, 就會把Current Task的lock_depth加一.),
</span><span class='line'>若lock_depth&gt;=0,就會累加Scheduling Info.的bkl_count值,
</span><span class='line'>用以代表Task Blocking的次數.*/
</span><span class='line'>struct sched_info rq_sched_info;
</span><span class='line'>/*可用以表示RunQueue中的Task所得到CPU執行
</span><span class='line'>時間的累加值.
</span><span class='line'>在發生Task Switch時,會透過sched_info_switch呼叫
</span><span class='line'>sched_info_arrive並以目前RunQueue Clock值更新
</span><span class='line'>Task 的sched_info.last_arrival時間,而在Task所分配時間
</span><span class='line'>結束後,會在函式sched_info_depart中以現在的
</span><span class='line'>RunQueue Clock值減去Task的sched_info.last_arrival
</span><span class='line'>時間值,得到的 Delta作為變數rq_cpu_time的累
</span><span class='line'>加值.*/
</span><span class='line'>unsigned long long rq_cpu_time;
</span><span class='line'>/* could above be rq-&gt;cfs_rq.exec_clock + rq-&gt;rt_rq.rt_runtime ? */
</span><span class='line'>
</span><span class='line'>/* sys_sched_yield() stats */
</span><span class='line'>/*用以統計呼叫System Call sys_sched_yield的次數.*/
</span><span class='line'>unsigned int yld_count;
</span><span class='line'>
</span><span class='line'>/* schedule() stats */
</span><span class='line'>unsigned int sched_switch;
</span><span class='line'>/*可用以統計觸發Scheduling的次數. 在每次觸發
</span><span class='line'>Scheduling時,會透過函式schedule呼叫schedule_debug,
</span><span class='line'>呼叫schedstat_inc對這變數進行累加.*/
</span><span class='line'>unsigned int sched_count;
</span><span class='line'>/*可用以統計進入到Idle Task的次數. 會在函式
</span><span class='line'>pick_next_task_idle中,呼叫schedstat_inc對這變數進行
</span><span class='line'>累加.*/
</span><span class='line'>unsigned int sched_goidle;
</span><span class='line'>
</span><span class='line'>/* try_to_wake_up() stats */
</span><span class='line'>/*用以統計Wake Up Task的次數.*/
</span><span class='line'>unsigned int ttwu_count;
</span><span class='line'>/*用以統計Wake Up 同一個處理器Task的次數.*/
</span><span class='line'>unsigned int ttwu_local;
</span><span class='line'>
</span><span class='line'>/* BKL stats */
</span><span class='line'>unsigned int bkl_count;
</span><span class='line'>#endif
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>
</span><span class='line'>调度类，sched_class为对模块编程的上层支持，对于每个linux新添加进来的调度算法都需要有自己的调度类实例。
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;/*CFS排程機制在設計時,考慮到排程機制的
</span><span class='line'>彈性,定義了Scheduler Class的機制,讓排程機制
</span><span class='line'>可以根據設計的需求,延伸不同的排程模
</span><span class='line'>組進來,每個新加入的排程機制都必須要
</span><span class='line'>提供Scheduler Class的實作,結構為 struct sched_class*/
</span><span class='line'>struct sched_class {
</span><span class='line'>/*會指向下一個Scheduling Class,以筆者所採用
</span><span class='line'>的Linux Kernel 2.6.38.6而言,Scheduling Class的順序為
</span><span class='line'>stop_sched_class-&gt;rt_sched_class-&gt;fair_sched_class-&gt;idle_sched_class*/
</span><span class='line'>const struct sched_class *next;
</span><span class='line'>/*當Task屬於Runnable狀態時,就會呼叫這個函式
</span><span class='line'>把Task配置到RunQueue RBTree中,進行排程動作,
</span><span class='line'>並呼叫inc_nr_running將RunQueue中nr_running的值
</span><span class='line'>加一.(nr_running用以代表目前RunQueue有多少
</span><span class='line'>Runnable Task進行排程)*/
</span><span class='line'>void (*enqueue_task) (struct rq *rq, struct task_struct *p, int wakeup);
</span><span class='line'>/*當Task不需要執行時,就會呼叫這個函式
</span><span class='line'>把Task從RunQueue RBTree中移除,並呼叫
</span><span class='line'>dec_nr_running將RunQueue中nr_running的值減一.*/
</span><span class='line'>void (*dequeue_task) (struct rq *rq, struct task_struct *p, int sleep);
</span><span class='line'>/*用以暫停目前正在執行中的Task,如果
</span><span class='line'>sysctl_sched_compat_yield有設定,就會找出目前
</span><span class='line'>RBTree中最右邊的Task(也就是vrruntime最多
</span><span class='line'>的Task),讓目前Task的vrruntime值等於最右邊
</span><span class='line'>Task值的vrruntime加一(可參考:
</span><span class='line'>se-&gt;vruntime = rightmost-&gt;vruntime + 1),如此在下次
</span><span class='line'>排程觸發時就會透過函式put_prev_task把目前
</span><span class='line'>的Task放到RBTree的最右邊,也就等同於暫停
</span><span class='line'>Task,讓該Task下次被執行到的機會最低.*/
</span><span class='line'>void (*yield_task) (struct rq *rq);
</span><span class='line'>/*用以決定一個Task是否可以中斷目前正在
</span><span class='line'>運作的Task,取得執行權.以CFS本身的實作來說
</span><span class='line'>(in sched_fair.c).如果想要取代目前Task的Task本身
</span><span class='line'>的Scheduling Policy為 Batch或是Idle時,會直接返回,
</span><span class='line'>不會用來取代目前正在執行中的Task.反之,
</span><span class='line'>如果目前正在執行中的Task的Scheduling Policy
</span><span class='line'>為Idle,就會直接由所傳入的Task取代目前正
</span><span class='line'>在執行的Task.*/
</span><span class='line'>void (*check_preempt_curr) (struct rq *rq, struct task_struct *p, int flags);
</span><span class='line'>/*用以在排程觸發時,從RunQueue RBTree中,
</span><span class='line'>取出符合目前Scheduling邏輯的下一個要
</span><span class='line'>被執行的Task.*/
</span><span class='line'>struct task_struct * (*pick_next_task) (struct rq *rq);
</span><span class='line'>/*用以在排程觸發時,把上一個執行完畢的
</span><span class='line'>Task放到目前RunQueue RBTree中對應的位置.*/
</span><span class='line'>void (*put_prev_task) (struct rq *rq, struct task_struct *p);
</span><span class='line'>
</span><span class='line'>#ifdef CONFIG_SMP
</span><span class='line'>/*通常用在執行一個新的程序,或是WakeUp
</span><span class='line'>一個Task時,會根據目前SMP下每個處理器的
</span><span class='line'>負荷,決定Task是否要切換到另一個處理器
</span><span class='line'>的RunQueue去執行,執行時會返回最後目標
</span><span class='line'>處理器的值.*/
</span><span class='line'>int  (*select_task_rq)(struct task_struct *p, int sd_flag, int flags);
</span><span class='line'>
</span><span class='line'>unsigned long (*load_balance) (struct rq *this_rq, int this_cpu,
</span><span class='line'>        struct rq *busiest, unsigned long max_load_move,
</span><span class='line'>        struct sched_domain *sd, enum cpu_idle_type idle,
</span><span class='line'>        int *all_pinned, int *this_best_prio);
</span><span class='line'>
</span><span class='line'>int (*move_one_task) (struct rq *this_rq, int this_cpu,
</span><span class='line'>              struct rq *busiest, struct sched_domain *sd,
</span><span class='line'>              enum cpu_idle_type idle);
</span><span class='line'>void (*pre_schedule) (struct rq *this_rq, struct task_struct *task);
</span><span class='line'>void (*post_schedule) (struct rq *this_rq);
</span><span class='line'>void (*task_wake_up) (struct rq *this_rq, struct task_struct *task);
</span><span class='line'>
</span><span class='line'>void (*set_cpus_allowed)(struct task_struct *p,
</span><span class='line'>             const struct cpumask *newmask);
</span><span class='line'>
</span><span class='line'>void (*rq_online)(struct rq *rq);
</span><span class='line'>void (*rq_offline)(struct rq *rq);
</span><span class='line'>#endif
</span><span class='line'>/*這個函式用以改變Task目前所屬的Scheduling
</span><span class='line'>Class與改變Task Group.*/
</span><span class='line'>void (*set_curr_task) (struct rq *rq);
</span><span class='line'>/*這是Scheduler的 Timer Tick來源,系統中觸發的
</span><span class='line'>Scheduling Tick會呼叫這個函式 (看HZ設定多少,
</span><span class='line'>100就是每秒呼叫這函式100次,1000就是每秒
</span><span class='line'>呼叫這函式1000次),
</span><span class='line'>用以讓排程機制可以決定哪些Task應該要配
</span><span class='line'>執行與哪些Task應該要被移出RunQueue.*/
</span><span class='line'>void (*task_tick) (struct rq *rq, struct task_struct *p, int queued);
</span><span class='line'>void (*task_new) (struct rq *rq, struct task_struct *p);
</span><span class='line'>
</span><span class='line'>void (*switched_from) (struct rq *this_rq, struct task_struct *task,
</span><span class='line'>               int running);
</span><span class='line'>void (*switched_to) (struct rq *this_rq, struct task_struct *task,
</span><span class='line'>             int running);
</span><span class='line'>void (*prio_changed) (struct rq *this_rq, struct task_struct *task,
</span><span class='line'>             int oldprio, int running);
</span><span class='line'>
</span><span class='line'>unsigned int (*get_rr_interval) (struct task_struct *task);
</span><span class='line'>
</span><span class='line'>#ifdef CONFIG_FAIR_GROUP_SCHED
</span><span class='line'>void (*moved_group) (struct task_struct *p);
</span><span class='line'>#endif
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;```&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;调度实体，调度实体用于调度时间记账，linux中CFS和实时调度使用不同的调度实体。调度运行队列，对于不用的调度算法同样运用不用的运行队列，对于CFS调度，运用的是红黑树，而对于实时调度为组链表。在后面具体的调度算法介绍中我们会看到他们的运用。&lt;/p&gt;
</span><span class='line'>]]&gt;&lt;/content&gt;
</span><span class='line'>  &lt;/entry&gt;
</span><span class='line'>  
</span><span class='line'>  &lt;entry&gt;
</span><span class='line'>&lt;title type="html"&gt;&lt;![CDATA[Idle进程的切换过程]]&gt;&lt;/title&gt;
</span><span class='line'>&lt;link href="http://abcdxyzk.github.io/blog/2015/01/14/kernel-sched-idle/"/&gt;
</span><span class='line'>&lt;updated&gt;2015-01-14T23:39:00+08:00&lt;/updated&gt;
</span><span class='line'>&lt;id&gt;http://abcdxyzk.github.io/blog/2015/01/14/kernel-sched-idle&lt;/id&gt;
</span><span class='line'>&lt;content type="html"&gt;&lt;![CDATA[&lt;p&gt;&lt;a href="http://blog.chinaunix.net/uid-27767798-id-3577069.html"&gt;http://blog.chinaunix.net/uid-27767798-id-3577069.html&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  每个cpu都有自己的运行队列，如果当前cpu上运行的任务都已经dequeue出运行队列，而且idle_balance也没有移动到当前运行队列的任务，那么schedule函数中，按照rt ，cfs，idle这三种调度方式顺序，寻找各自的运行任务，那么如果rt和cfs都未找到运行任务，那么最后会调用idle schedule的idle进程，作为schedule函数调度的下一个任务。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;kernel/sched.c 中的schedule()函数中的片段</span></code></pre></td></tr></table></div></figure>
    if (prev->state &amp;&amp; !(preempt_count() &amp; PREEMPT_ACTIVE)) { <br/>
        //state大于0代表prev也就是当前运行的任务不是running状态，并且没有标记 PREEMPT_ACTIVE，就表示当前的运行的任务没有必要停留在运行队列中了
        if (unlikely(signal_pending_state(prev->state, prev)))  //如果当前进程标记了状态是TASK_INTERRUPTIBLE，并且还有信号未处理，那么没有必要从运行队列中移除这个进程
            prev->state = TASK_RUNNING;
        else
            deactivate_task(rq, prev, DEQUEUE_SLEEP);        //从运行队列中移除这个进程
        switch_count = &amp;prev->nvcsw;
    }</p>

<pre><code>pre_schedule(rq, prev);

if (unlikely(!rq-&gt;nr_running)) //如果当前运行队列没有进程可以运行了，就balance其他运行队列的任务到当前运行队列，这里balance的具体过程暂时不说
    idle_balance(cpu, rq);

put_prev_task(rq, prev);
next = pick_next_task(rq);     //按照rt，cfs，idle优先级的顺序挑选进程，如果在rt和cfs中都没有找到能够运行的任务，那么当前cpu会切换到idle进程。
</code></pre>

<pre><code>  这里 PREEMPT_ACTIVE是个标志位，由于进程由于系统调用或者中断异常返回到用户态之前，都要判断是否可以被抢占，会首先判断preempt_count,等于0的时候表示没有禁止抢占，然后再去判断是否标记了need_resched,如果标记了，在去调用schedule函数，如果在某些时候禁止了抢占，禁止了一次就要preempt_count加1。可以肯定的一点是进程的state和是否在运行队列的因果关系并不是十分同步的，修改了进程的状态后，可能还需要做一些其他的工作才去调用schedule函数。引用一下其他人的例子。
</code></pre>

<pre><code>for (;;) {
   prepare_to_wait(&amp;wq, &amp;__wait,TASK_UNINTERRUPTIBLE);
   if (condition)
     break;
   schedule();
}
</code></pre>

<pre><code>
  可以看出在修改了进程的state之后，并不会立刻调用schedule函数，即使立刻调用了schedule函数，也不能保证在schedule函数之前的禁止抢占开启之前有其他的抢占动作。毕竟修改进程的state和从运行队列中移除任务不是一行代码（机器码）就能搞定的事情。所以如果在修改了进程的状态之后和schedule函数禁止抢占之前有抢占动作（可能是中断异常返回），如果这个时候进程被其他进程抢占，这个时候把当前进程移除运行队列，那么这个进程将永远没有机会运行后面的代码。所以这个时候在抢占的过程之前将preempt_count标记PREEMPT_ACTIVE，这样抢占中调用schedule函数将不会从当前运行队列中移除当前进程，这样才有前面分析schedule函数代码，有判断进程state同时判断preempt_count未标记PREEMPT_ACTIVE的情况。

  在当前进程被移除出运行队列之前还需要判断是否有挂起的信号需要处理，如果当前进程的状态是TASK_INTERRUPTIBLE或者TASK_WAKEKILL的时候，如果还有信号未处理，那么当前进程就不需要被移除运行队列，并且将state置为running。
</code></pre>

<pre><code>static inline int signal_pending_state(long state, struct task_struct *p)
{
    if (!(state &amp; (TASK_INTERRUPTIBLE | TASK_WAKEKILL))) //首先判断状态不是这两个可以处理信号的状态就直接返回0，后面的逻辑不考虑了
        return 0;
    if (!signal_pending(p))             //如果没有信号挂起就不继续了
        return 0;

    return (state &amp; TASK_INTERRUPTIBLE) || __fatal_signal_pending(p); //如果有信号
}
</code></pre>

<pre><code>
    说下 put_prev_task的逻辑，按照道理说应该是rt，cfs，idle的顺序寻找待运行态的任务。
</code></pre>

<pre><code>pick_next_task(struct rq *rq)
{
    const struct sched_class *class;
    struct task_struct *p;

    /*
     * Optimization: we know that if all tasks are in
     * the fair class we can call that function directly:
     */
    //这里注释的意思都能看懂，如果rq中的cfs队列的运行个数和rq中的运行个数相同，直接调用cfs中 的pick函数，因为默认的调度策略是cfs。
    if (likely(rq-&gt;nr_running == rq-&gt;cfs.nr_running)) {
        p = fair_sched_class.pick_next_task(rq);
        if (likely(p))
        return p;
    }

    //这里 sched_class_highest就是rt_sched_class，所以前面没有选择出任务，那么从rt开始挑选任务，直到idle
    class = sched_class_highest;
    for ( ; ; ) {
        p = class-&gt;pick_next_task(rq);
        if (p)
            return p;
        /*
         * Will never be NULL as the idle class always
         * returns a non-NULL p:
         */
        class = class-&gt;next;
    }
}
</code></pre>

<pre><code>
  从每个调度类的代码的最后可以看出这个next关系

sched_rt.c中：
</code></pre>

<pre><code>static const struct sched_class rt_sched_class = {
.next = &amp;fair_sched_class,
</code></pre>

<pre><code>
sched_fair.c中：
</code></pre>

<pre><code>static const struct sched_class fair_sched_class = {
.next = &amp;idle_sched_class,
</code></pre>

<pre><code>
  那么可以试想如果rt和cfs都没有可以运行的任务，那么最后就是调用idle的pick_next_task函数

sched_idletask.c:
</code></pre>

<pre><code>static struct task_struct *pick_next_task_idle(struct rq *rq)
{
    schedstat_inc(rq, sched_goidle);
    calc_load_account_idle(rq);
    return rq-&gt;idle;    //可以看到就是返回rq中idle进程。
}
</code></pre>

<pre><code>  这idle进程在启动start_kernel函数的时候调用init_idle函数的时候，把当前进程（0号进程）置为每个rq的idle上。

kernel/sched.c:5415
</code></pre>

<pre><code>rq-&gt;curr = rq-&gt;idle = idle;
</code></pre>

<pre><code>  这里idle就是调用start_kernel函数的进程，就是0号进程。

  0号进程在fork完init进程等之后，进入cpu_idle函数，大概的逻辑是for循环调用hlt指令，每次hlt返回后，调用schedule函数，具体的流程现在还没太看懂，可以看到的是在具体的逻辑在default_idle函数中，调用了safe_halt函数
</code></pre>

<pre><code>static inline void native_safe_halt(void)
{
        asm volatile("sti; hlt": : :"memory");
}
</code></pre>

<p>```
  关于hlt指令的作用是：引用wiki百科</p>

<blockquote><p>  In the x86 computer architecture, HLT (halt) is an assembly language instruction which halts the CPU until the next external interrupt is fired.[1] Interrupts are signals sent by hardware devices to the CPU alerting it that an event occurred to which it should react. For example, hardware timers send interrupts to the CPU at regular intervals.</p>

<p>  The HLT instruction is executed by the operating system when there is no immediate work to be done, and the system enters its idle state. In Windows NT, for example, this instruction is run in the &ldquo;System Idle Process&rdquo;.</p></blockquote>

<p>  可以看到注释的意思是，hlt指令使得cpu挂起，直到有中断产生这个时候cpu重新开始运行。所以时钟中断会唤醒正在hlt中的cpu，让它调用schedule函数，检测是否有新的任务在rq中，如果有的话切换到新的任务，否则继续执行hlt，cpu继续挂起。</p>

<p>参考文章<br/>
1.<a href="http://blog.csdn.net/dog250/article/details/5303547">http://blog.csdn.net/dog250/article/details/5303547</a></p>

<p>2.<a href="http://en.wikipedia.org/wiki/HLT">http://en.wikipedia.org/wiki/HLT</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[tsc时钟初始化]]></title>
    <link href="http://abcdxyzk.github.io/blog/2014/05/29/kernel-sched-tsc/"/>
    <updated>2014-05-29T14:03:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2014/05/29/kernel-sched-tsc</id>
    <content type="html"><![CDATA[<h5>tsc时钟源初始化</h5>

<pre><code>    //    调用路径：time_init-&gt;tsc_init
    //    函数任务：
    //        1.矫正tsc，获取tsc频率，设置cpu频率等于tsc频率
    //        2.初始化基于tsc的延迟函数
    //        3.检查tsc的特性
    //            3.1 tsc之间是否同步
    //                3.1.1 如果tsc之间不同步，标记tsc不稳定，设置rating=0
    //            3.2 tsc是否稳定
    //        4.注册tsc时钟源设备
</code></pre>

<pre><code>    void __init tsc_init(void)
    {
        u64 lpj;
        int cpu;

        //矫正tsc，获取tsc频率
        tsc_khz = x86_platform.calibrate_tsc();
        //cpu频率等于tsc频率
        cpu_khz = tsc_khz;
        //计算辅助cycle到ns转换的辅助参数scale
        for_each_possible_cpu(cpu)
            set_cyc2ns_scale(cpu_khz, cpu);
        //初始化基于tsc的延迟函数，ndely，udelay，mdelay
        use_tsc_delay();
        //检查cpu之间tsc是否同步
        if (unsynchronized_tsc())
            mark_tsc_unstable("TSCs unsynchronized");
        //检查tsc是否可靠
        check_system_tsc_reliable();
        //注册tsc时钟源设备
        init_tsc_clocksource();
    }
</code></pre>

<h5>延迟函数ndelay，udelay，mdelay</h5>

<p>通过tsc实现短延迟
<code>
    void use_tsc_delay(void)
    {
        //通过tsc进行短延迟
        delay_fn = delay_tsc;
    }
</code></p>

<h5>tsc延迟函数</h5>

<p>通过rep_nop实现轮询时的短延迟，查询tsc时禁止内核抢占，确保不受不同cpu间影响。
```
    static void delay_tsc(unsigned long loops)
    {
        unsigned long bclock, now;
        int cpu;
        //短延迟，禁止内核抢占
        preempt_disable();
        //delay_tsc当前运行的cpu
        cpu = smp_processor_id();
        rdtsc_barrier();
        rdtscl(bclock);
        for (;;) {
            rdtsc_barrier();
            rdtscl(now);
            if ((now - bclock) >= loops)
                break;
            //允许rt策略进程运行
            preempt_enable();
            //空操作
            rep_nop();
            preempt_disable();</p>

<pre><code>        //delay_tsc在运行过程中，可能会迁移到不同的cpu
        //tsc
        if (unlikely(cpu != smp_processor_id())) {
            loops -= (now - bclock);
            cpu = smp_processor_id();
            rdtsc_barrier();
            rdtscl(bclock);
        }
    }
    preempt_enable();
}
</code></pre>

<pre><code>
##### 检查tsc是否同步
</code></pre>

<pre><code>//    调用路径：tsc_init-&gt;unsynchronized_tsc
//    检查办法：
//        1.如果apic在多块板卡，则tsc不同步
//        2.如果cpuid显示具有稳定的tsc，则tsc同步
//        3.intel cpu的tsc都是同步的
//        4.默认其他品牌的多核的tsc不同步
</code></pre>

<pre><code></code></pre>

<pre><code>__cpuinit int unsynchronized_tsc(void)
{
    //如果apic分布在多块板卡上，tsc可能不同步
    if (apic_is_clustered_box())
        return 1;
    //cpu具有稳定的tsc
    if (boot_cpu_has(X86_FEATURE_CONSTANT_TSC))
        return 0;
    //intel cpu的tsc都是同步的
    if (boot_cpu_data.x86_vendor != X86_VENDOR_INTEL) {
        //非intel cpu，如果cpu个数&gt;1,则认为不同步
        if (num_possible_cpus() &gt; 1)
            tsc_unstable = 1;
    }
    return tsc_unstable;
}
</code></pre>

<pre><code>
##### 标记tsc不稳定
</code></pre>

<pre><code>//    调用路径：tsc_init-&gt;mark_tsc_unstable
//    函数任务：
//        1.如果tsc时钟已经注册，异步设置tsc的rating=0，标识其不稳定
//        2.如果tsc时钟还未注册，同步设置tsc的rating=0，标识其不稳定
</code></pre>

<pre><code></code></pre>

<pre><code>void mark_tsc_unstable(char *reason)
{
    if (!tsc_unstable) {
        tsc_unstable = 1;
        sched_clock_stable = 0;
        //tsc已经注册，
        if (clocksource_tsc.mult)
        {
            clocksource_mark_unstable(&amp;clocksource_tsc);
        }
        //如果tsc时钟源未注册，修改rating为最低，从而不会被当做最佳的时钟源
        else {
            clocksource_tsc.flags |= CLOCK_SOURCE_UNSTABLE;
            clocksource_tsc.rating = 0;
        }
    }
}
</code></pre>

<pre><code>
##### 注册tsc时钟源
</code></pre>

<pre><code>//    函数任务：
//        1.计算tsc的mult
//        2.检查tsc是否稳定
//            2.1 如果tsc不稳定，降低其rating，清除时钟源连续标志
//        3.向系统注册tsc clocksource
//    调用路径：tsc_init-&gt;init_tsc_clocksource
</code></pre>

<pre><code></code></pre>

<pre><code>static void __init init_tsc_clocksource(void)
{
    // 计算tsc的mult
    clocksource_tsc.mult = clocksource_khz2mult(tsc_khz,
            clocksource_tsc.shift);
    // 如果tsc的可靠性已经验证，则清除 必须验证 标记
    if (tsc_clocksource_reliable)
        clocksource_tsc.flags &amp;= ~CLOCK_SOURCE_MUST_VERIFY;

    // 检查tsc是否稳定
    // 在tsc_init前通过全局变量标记tsc是否稳定，可靠
    if (check_tsc_unstable()) {
        // 如果tsc不稳定，则降低rating最低，清除连续标记
        clocksource_tsc.rating = 0;
        clocksource_tsc.flags &amp;= ~CLOCK_SOURCE_IS_CONTINUOUS;
    }
    // 向系统注册tsc clocksource
    clocksource_register(&amp;clocksource_tsc);
}
</code></pre>

<p>```</p>
]]></content>
  </entry>
  
</feed>
