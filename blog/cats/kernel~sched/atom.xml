<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: kernel~sched | kk Blog —— 通用基础]]></title>
  <link href="http://abcdxyzk.github.io/blog/cats/kernel~sched/atom.xml" rel="self"/>
  <link href="http://abcdxyzk.github.io/"/>
  <updated>2015-03-03T18:16:23+08:00</updated>
  <id>http://abcdxyzk.github.io/</id>
  <author>
    <name><![CDATA[kk]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[linux内核中异步通知机制--信号处理机制]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/02/11/kernel-sched-signal/"/>
    <updated>2015-02-11T15:08:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/02/11/kernel-sched-signal</id>
    <content type="html"><![CDATA[<p><a href="http://blog.csdn.net/yusiguyuan/article/details/23168363">http://blog.csdn.net/yusiguyuan/article/details/23168363</a></p>

<p>  什么是异步通知：很简单，一旦设备准备好，就主动通知应用程序，这种情况下应用程序就不需要查询设备状态， 特像硬件上常提的“中断的概念”。 比较准确的说法其实应该叫做“信号驱动的异步I/O”,信号是在软件层次上对中断机制的一种模拟。阻塞I/O意味着一直等待设备可访问再访问，非阻塞I/O意味着使用poll()来查询是否可访问，而异步通知则意味着设备通知应用程序自身可访问。（希望用这么一句话能表达我的意思）</p>

<h4>一、系统中存在的异步机制</h4>

<p>  我认为异步机制是一种理念，并不是某一种具体实现，同步/异步的核心理解应该是如何获取消息的问题，你自身（在计算机中当然是进程本身了）亲自去获取消息，那么就是同步机制，但是如果别人使用某种方式通知你某一个消息，那么你采用的就是异步机制。内核中使用到异步机制的大概有：信号，这是一种进程间通信的异步机制；epoll，这是一种高效处理IO的异步通信机制。也就是从通信和IO两个方面通过不同的方式使用了异步机制。（可能还有别的，暂时不知道）</p>

<p>下面进入正题：</p>

<h4>二、信号的基本概念</h4>

<h5>1）信号的本质</h5>

<p>  软中断信号（signal，又简称为信号）用来通知进程发生了异步事件。在软件层次上是对中断机制的一种模拟，在原理上，一个进程收到一个信号与处理器收到一个中断请求可以说是一样的。信号是进程间通信机制中唯一的异步通信机制，一个进程不必通过任何操作来等待信号的到达，事实上，进程也不知道信号到底什么时候到达。进程之间可以互相通过系统调用kill发送软中断信号。内核也可以因为内部事件而给进程发送信号，通知进程发生了某个事件。信号机制除了基本通知功能外，还可以传递附加信息。</p>

<p>收到信号的进程对各种信号有不同的处理方法。处理方法可以分为三类：<br/>
第一种是类似中断的处理程序，对于需要处理的信号，进程可以指定处理函数，由该函数来处理。<br/>
第二种方法是，忽略某个信号，对该信号不做任何处理，就象未发生过一样。<br/>
第三种方法是，对该信号的处理保留系统的默认值，这种缺省操作，对大部分的信号的缺省操作是使得进程终止。进程通过系统调用signal来指定进程对某个信号的处理行为。</p>

<p>  在进程表的表项中有一个软中断信号域，该域中每一位对应一个信号，当有信号发送给进程时，对应位置位。由此可以看出，进程对不同的信号可以同时保留，但对于同一个信号，进程并不知道在处理之前来过多少个。</p>

<h5>2）信号的种类</h5>

<p>可以从两个不同的分类角度对信号进行分类：<br/>
可靠性方面：可靠信号与不可靠信号；<br/>
与时间的关系上：实时信号与非实时信号。</p>

<h5>3）可靠信号与不可靠信号</h5>

<p>  Linux信号机制基本上是从Unix系统中继承过来的。早期Unix系统中的信号机制比较简单和原始，信号值小于SIGRTMIN的信号都是不可靠信号。这就是"不可靠信号"的来源。它的主要问题是信号可能丢失。</p>

<p>  随着时间的发展，实践证明了有必要对信号的原始机制加以改进和扩充。由于原来定义的信号已有许多应用，不好再做改动，最终只好又新增加了一些信号，并在一开始就把它们定义为可靠信号，这些信号支持排队，不会丢失。</p>

<p>  信号值位于SIGRTMIN和SIGRTMAX之间的信号都是可靠信号，可靠信号克服了信号可能丢失的问题。Linux在支持新版本的信号安装函数sigation()以及信号发送函数sigqueue()的同时，仍然支持早期的signal()信号安装函数，支持信号发送函数kill()。</p>

<p>信号的可靠与不可靠只与信号值有关，与信号的发送及安装函数无关。目前linux中的signal()是通过sigation()函数实现的，因此，即使通过signal()安装的信号，在信号处理函数的结尾也不必再调用一次信号安装函数。同时，由signal()安装的实时信号支持排队，同样不会丢失。</p>

<p>  对于目前linux的两个信号安装函数：signal()及sigaction()来说，它们都不能把SIGRTMIN以前的信号变成可靠信号（都不支持排队，仍有可能丢失，仍然是不可靠信号），而且对SIGRTMIN以后的信号都支持排队。这两个函数的最大区别在于，经过sigaction安装的信号都能传递信息给信号处理函数，而经过signal安装的信号不能向信号处理函数传递信息。对于信号发送函数来说也是一样的。</p>

<h5>4）实时信号与非实时信号</h5>

<p>  早期Unix系统只定义了32种信号，前32种信号已经有了预定义值，每个信号有了确定的用途及含义，并且每种信号都有各自的缺省动作。如按键盘的CTRL ^C时，会产生SIGINT信号，对该信号的默认反应就是进程终止。后32个信号表示实时信号，等同于前面阐述的可靠信号。这保证了发送的多个实时信号都被接收。</p>

<p>非实时信号都不支持排队，都是不可靠信号；实时信号都支持排队，都是可靠信号。</p>

<h5>5)linux 下信号的生命周期如下：</h5>

<p>  在目的进程中安装该信号。即是设置捕获该信号时进程进程该执行的操作码。采用signal（）;sigaction（）系统调用来实现。<br/>
  信号被某个进程产生，同时设置该信号的目的进程（使用pid），之后交给操作系统进行管理。采用kill()、arise()、alarm()等系统调用来实现。<br/>
  信号在目的进程被注册。信号被添加进进程的PCB（task_struct）中相关的数据结构里——未决信号的数据成员。信号在进程中注册就是把信号值加入到进程的未决信号集里。并且，信号携带的其他信息被保留到未决信的队列的某个sigqueue结构中。<br/>
  信号在进程中注销。在执行信号处理函数前，要把信号在进程中注销。对于非实时信号（不可靠信号），其在信号未决信号信息链中最多只有一个sigqueue结构，因此该结构被释放后，相应的信号要在未决信号集删除。而实时信号（可靠信号），如果有多个sigqueue，则不会把信号从进程的未决信号集中删除。<br/>
  信号生命的终结。进程终止当前的工作，保护上下文，执行信号处理函数，之后回复。如果内核是可抢占的，那么还需要调度。</p>

<h4>三、信 号 机 制</h4>

<p>  上 一节中介绍了信号的基本概念，在这一节中，我们将介绍内核如何实现信号机制。即内核如何向一个进程发送信号、进程如何接收一个信号、进程怎样控制自己对信 号的反应、内核在什么时机处理和怎样处理进程收到的信号。还要介绍一下setjmp和longjmp在信号中起到的作用。</p>

<h5>1、内核对信号的基本处理方法</h5>

<p>  内核给一个进程发送软中断信号的方法，是在进程所在的进程表项的信号域设置对应于该信号的位。这里要补充的是，如果信号发送给一个正在睡眠的进程，那么要看 该进程进入睡眠的优先级，如果进程睡眠在可被中断的优先级上，则唤醒进程；否则仅设置进程表中信号域相应的位，而不唤醒进程。这一点比较重要，因为进程检 查是否收到信号的时机是：一个进程在即将从内核态返回到用户态时；或者，在一个进程要进入或离开一个适当的低调度优先级睡眠状态时。</p>

<p>进程的task_struct结构中有关于本进程中未决信号的数据成员：struct sigpending pending：
<code>
    struct sigpending{
        struct sigqueue *head, *tail;
        sigset_t signal;
    };
</code>
第三个成员是进程中所有未决信号集，第一、第二个成员分别指向一个sigqueue类型的结构链（称之为"未决信号信息链"）的首尾，信息链中的每个sigqueue结构刻画一个特定信号所携带的信息，并指向下一个sigqueue结构:
<code>
    struct sigqueue{
        struct sigqueue *next;
        siginfo_t info;
    }
</code>
信号在进程中注册指的就是信号值加入到进程的未决信号集sigset_t signal（每个信号占用一位）中，并且信号所携带的信息被保留到未决信号信息链的某个sigqueue结构中。只要信号在进程的未决信号集中，表明进程已经知道这些信号的存在，但还没来得及处理，或者该信号被进程阻塞。</p>

<p>当一个实时信号发送给一个进程时，不管该信号是否已经在进程中注册，都会被再注册一次，因此，信号不会丢失，因此，实时信号又叫做"可靠信号"。这意味着同一个实时信号可以在同一个进程的未决信号信息链中占有多个sigqueue结构（进程每收到一个实时信号，都会为它分配一个结构来登记该信号信息，并把该结构添加在未决信号链尾，即所有诞生的实时信号都会在目标进程中注册）。</p>

<p>当一个非实时信号发送给一个进程时，如果该信号已经在进程中注册（通过sigset_t signal指示），则该信号将被丢弃，造成信号丢失。因此，非实时信号又叫做"不可靠信号"。这意味着同一个非实时信号在进程的未决信号信息链中，至多占有一个sigqueue结构。</p>

<p>总之信号注册与否，与发送信号的函数（如kill()或sigqueue()等）以及信号安装函数（signal()及sigaction()）无关，只与信号值有关（信号值小于SIGRTMIN的信号最多只注册一次，信号值在SIGRTMIN及SIGRTMAX之间的信号，只要被进程接收到就被注册）</p>

<p>内核处理一个进程收到的信号的时机是在一个进程从内核态返回用户态时。所以，当一个进程在内核态下运行时，软中断信号并不立即起作用，要等到将返回用户态时才处理。进程只有处理完信号才会返回用户态，进程在用户态下不会有未处理完的信号。</p>

<p>内核处理一个进程收到的软中断信号是在该进程的上下文中，因此，进程必须处于运行状态。前面介绍概念的时候讲过，处理信号有三种类型：进程接收到信号后退 出；进程忽略该信号；进程收到信号后执行用户设定用系统调用signal的函数。当进程接收到一个它忽略的信号时，进程丢弃该信号，就象没有收到该信号似 的继续运行。如果进程收到一个要捕捉的信号，那么进程从内核态返回用户态时执行用户定义的函数。而且执行用户定义的函数的方法很巧妙，内核是在用户栈上创 建一个新的层，该层中将返回地址的值设置成用户定义的处理函数的地址，这样进程从内核返回弹出栈顶时就返回到用户定义的函数处，从函数返回再弹出栈顶时， 才返回原先进入内核的地方。这样做的原因是用户定义的处理函数不能且不允许在内核态下执行（如果用户定义的函数在内核态下运行的话，用户就可以获得任何权 限）。</p>

<p>对于非实时信号来说，由于在未决信号信息链中最多只占用一个sigqueue结构，因此该结构被释放后，应该把信号在进程未决信号集中删除（信号注销完毕）；而对于实时信号来说，可能在未决信号信息链中占用多个sigqueue结构，因此应该针对占用sigqueue结构的数目区别对待：如果只占用一个sigqueue结构（进程只收到该信号一次），则执行完相应的处理函数后应该把信号在进程的未决信号集中删除（信号注销完毕）。否则待该信号的所有sigqueue处理完毕后再在进程的未决信号集中删除该信号。</p>

<p>当所有未被屏蔽的信号都处理完毕后，即可返回用户空间。对于被屏蔽的信号，当取消屏蔽后，在返回到用户空间时会再次执行上述检查处理的一套流程。</p>

<h6>在信号的处理方法中有几点特别要引起注意。</h6>

<p>第一，在一些系统中，当一个进程处理完中断信号返回用户态之前，内核清除用户区中设 定的对该信号的处理例程的地址，即下一次进程对该信号的处理方法又改为默认值，除非在下一次信号到来之前再次使用signal系统调用。这可能会使得进程 在调用signal之前又得到该信号而导致退出。在BSD中，内核不再清除该地址。但不清除该地址可能使得进程因为过多过快的得到某个信号而导致堆栈溢 出。为了避免出现上述情况。在BSD系统中，内核模拟了对硬件中断的处理方法，即在处理某个中断时，阻止接收新的该类中断。</p>

<p>第二个要 引起注意的是，如果要捕捉的信号发生于进程正在一个系统调用中时，并且该进程睡眠在可中断的优先级上，这时该信号引起进程作一次longjmp，跳出睡眠 状态，返回用户态并执行信号处理例程。当从信号处理例程返回时，进程就象从系统调用返回一样，但返回了一个错误代码，指出该次系统调用曾经被中断。这要注 意的是，BSD系统中内核可以自动地重新开始系统调用。</p>

<p>第三个要注意的地方：若进程睡眠在可中断的优先级上，则当它收到一个要忽略的信号时，该进程被唤醒，但不做longjmp，一般是继续睡眠。但用户感觉不到进程曾经被唤醒，而是象没有发生过该信号一样。</p>

<p>第四个要注意的地方：内核对子进程终止（SIGCLD）信号的处理方法与其他信号有所区别。当进程检查出收到了一个子进程终止的信号时，缺省情况下，该进程 就象没有收到该信号似的，如果父进程执行了系统调用wait，进程将从系统调用wait中醒来并返回wait调用，执行一系列wait调用的后续操作（找 出僵死的子进程，释放子进程的进程表项），然后从wait中返回。SIGCLD信号的作用是唤醒一个睡眠在可被中断优先级上的进程。如果该进程捕捉了这个 信号，就象普通信号处理一样转到处理例程。如果进程忽略该信号，那么系统调用wait的动作就有所不同，因为SIGCLD的作用仅仅是唤醒一个睡眠在可被 中断优先级上的进程，那么执行wait调用的父进程被唤醒继续执行wait调用的后续操作，然后等待其他的子进程。</p>

<p> 如果一个进程调用signal系统调用，并设置了SIGCLD的处理方法，并且该进程有子进程处于僵死状态，则内核将向该进程发一个SIGCLD信号。</p>

<h5>2、setjmp和longjmp的作用</h5>

<p>  前面在介绍信号处理机制时，多次提到了setjmp和longjmp，但没有仔细说明它们的作用和实现方法。这里就此作一个简单的介绍。 <br/>
  在 介绍信号的时候，我们看到多个地方要求进程在检查收到信号后，从原来的系统调用中直接返回，而不是等到该调用完成。这种进程突然改变其上下文的情况，就是 使用setjmp和longjmp的结果。setjmp将保存的上下文存入用户区，并继续在旧的上下文中执行。这就是说，进程执行一个系统调用，当因为资 源或其他原因要去睡眠时，内核为进程作了一次setjmp，如果在睡眠中被信号唤醒，进程不能再进入睡眠时，内核为进程调用longjmp，该操作是内核 为进程将原先setjmp调用保存在进程用户区的上下文恢复成现在的上下文，这样就使得进程可以恢复等待资源前的状态，而且内核为setjmp返回1，使 得进程知道该次系统调用失败。这就是它们的作用。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux内核CPU负载均衡机制]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/02/11/kernel-sched-balance/"/>
    <updated>2015-02-11T14:00:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/02/11/kernel-sched-balance</id>
    <content type="html"><![CDATA[<p><a href="http://www.oenhan.com/cpu-load-balance">http://www.oenhan.com/cpu-load-balance</a></p>

<p> 还是神奇的进程调度问题引发的，参看Linux进程组调度机制分析，组调度机制是看清楚了，发现在重启过程中，很多内核调用栈阻塞在了double_rq_lock函数上，而double_rq_lock则是load_balance触发的，怀疑当时的核间调度出现了问题，在某个负责场景下产生了多核互锁，后面看了一下CPU负载平衡下的代码实现，写一下总结。</p>

<p>内核代码版本：kernel-3.0.13-0.27。</p>

<p>内核代码函数起自load_balance函数,从load_balance函数看引用它的函数可以一直找到schedule函数这里，便从这里开始往下看，在__schedule中有下面一句话。
<code>
    if (unlikely(!rq-&gt;nr_running))
        idle_balance(cpu, rq);
</code>
从上面可以看出什么时候内核会尝试进行CPU负载平衡：即当前CPU运行队列为NULL的时候。</p>

<p>CPU负载平衡有两种方式：pull和push，即空闲CPU从其他忙的CPU队列中拉一个进程到当前CPU队列；或者忙的CPU队列将一个进程推送到空闲的CPU队列中。idle_balance干的则是pull的事情，具体push下面会提到。</p>

<p>在idle_balance里面，有一个proc阀门控制当前CPU是否pull:
<code>
    if (this_rq-&gt;avg_idle &lt; sysctl_sched_migration_cost)
        return;
</code>
sysctl_sched_migration_cost对应proc控制文件是/proc/sys/kernel/sched_migration_cost，开关代表如果CPU队列空闲了500ms（sysctl_sched_migration_cost默认值）以上，则进行pull，否则则返回。</p>

<p>for_each_domain(this_cpu, sd) 则是遍历当前CPU所在的调度域，可以直观的理解成一个CPU组，类似task_group，核间平衡指组内的平衡。负载平衡有一个矛盾就是：负载平衡的频度和CPU cache的命中率是矛盾的，CPU调度域就是将各个CPU分成层次不同的组，低层次搞定的平衡就绝不上升到高层次处理，避免影响cache的命中率。</p>

<p>图例如下;</p>

<p><img src="/images/kernel/2015-02-11-1.jpg" alt="" /></p>

<p>最终通过load_balance进入正题。</p>

<p>首先通过find_busiest_group获取当前调度域中的最忙的调度组，首先update_sd_lb_stats更新sd的状态，也就是遍历对应的sd，将sds里面的结构体数据填满，如下：
```
    struct sd_lb_stats {
        struct sched_group <em>busiest; /</em> Busiest group in this sd <em>/
        struct sched_group </em>this;  /<em> Local group in this sd </em>/
        unsigned long total_load;  /<em> Total load of all groups in sd </em>/
        unsigned long total_pwr;   /<em>   Total power of all groups in sd </em>/
        unsigned long avg_load;    /<em> Average load across all groups in sd </em>/</p>

<pre><code>    /** Statistics of this group */
    unsigned long this_load; //当前调度组的负载
    unsigned long this_load_per_task; //当前调度组的平均负载
    unsigned long this_nr_running; //当前调度组内运行队列中进程的总数
    unsigned long this_has_capacity;
    unsigned int  this_idle_cpus;

    /* Statistics of the busiest group */
    unsigned int  busiest_idle_cpus;
    unsigned long max_load; //最忙的组的负载量
    unsigned long busiest_load_per_task; //最忙的组中平均每个任务的负载量
    unsigned long busiest_nr_running; //最忙的组中所有运行队列中进程的个数
    unsigned long busiest_group_capacity;
    unsigned long busiest_has_capacity;
    unsigned int  busiest_group_weight;
</code></pre>

<pre><code></code></pre>

<pre><code>do
{
    local_group = cpumask_test_cpu(this_cpu, sched_group_cpus(sg));
    if (local_group) {
                  //如果是当前CPU上的group，则进行赋值
        sds-&gt;this_load = sgs.avg_load;
        sds-&gt;this = sg;
        sds-&gt;this_nr_running = sgs.sum_nr_running;
        sds-&gt;this_load_per_task = sgs.sum_weighted_load;
        sds-&gt;this_has_capacity = sgs.group_has_capacity;
        sds-&gt;this_idle_cpus = sgs.idle_cpus;
    } else if (update_sd_pick_busiest(sd, sds, sg, &amp;sgs, this_cpu)) {
                 //在update_sd_pick_busiest判断当前sgs的是否超过了之前的最大值，如果是
                 //则将sgs值赋给sds
        sds-&gt;max_load = sgs.avg_load;
        sds-&gt;busiest = sg;
        sds-&gt;busiest_nr_running = sgs.sum_nr_running;
        sds-&gt;busiest_idle_cpus = sgs.idle_cpus;
        sds-&gt;busiest_group_capacity = sgs.group_capacity;
        sds-&gt;busiest_load_per_task = sgs.sum_weighted_load;
        sds-&gt;busiest_has_capacity = sgs.group_has_capacity;
        sds-&gt;busiest_group_weight = sgs.group_weight;
        sds-&gt;group_imb = sgs.group_imb;
    }
    sg = sg-&gt;next;
} while (sg != sd-&gt;groups);
</code></pre>

<pre><code>
决定选择调度域中最忙的组的参照标准是该组内所有 CPU上负载(load) 的和， 找到组中找到忙的运行队列的参照标准是该CPU运行队列的长度， 即负载，并且 load 值越大就表示越忙。在平衡的过程中，通过比较当前队列与以前记录的busiest 的负载情况，及时更新这些变量，让 busiest 始终指向域内最忙的一组，以便于查找。

调度域的平均负载计算
</code></pre>

<pre><code>sds.avg_load = (SCHED_POWER_SCALE * sds.total_load) / sds.total_pwr;
if (sds.this_load &gt;= sds.avg_load)
    goto out_balanced;
</code></pre>

<pre><code>在比较负载大小的过程中， 当发现当前运行的CPU所在的组中busiest为空时，或者当前正在运行的 CPU队列就是最忙的时， 或者当前 CPU队列的负载不小于本组内的平均负载时，或者不平衡的额度不大时，都会返回 NULL 值，即组组之间不需要进行平衡；当最忙的组的负载小于该调度域的平均负载时，只需要进行小范围的负载平衡；当要转移的任务量小于每个进程的平均负载时，如此便拿到了最忙的调度组。

然后find_busiest_queue中找到最忙的调度队列，遍历该组中的所有 CPU 队列，经过依次比较各个队列的负载，找到最忙的那个队列。
</code></pre>

<pre><code>for_each_cpu(i, sched_group_cpus(group)) {
    /*rq-&gt;cpu_power表示所在处理器的计算能力,在函式sched_init初始化时,会把这值设定为SCHED_LOAD_SCALE (=Nice 0的Load Weight=1024).并可透过函式update_cpu_power (in kernel/sched_fair.c)更新这个值.*/
    unsigned long power = power_of(i);
    unsigned long capacity = DIV_ROUND_CLOSEST(power,SCHED_POWER_SCALE);
    unsigned long wl;
    if (!cpumask_test_cpu(i, cpus))
        continue;

    rq = cpu_rq(i);
</code></pre>

<p>/<em>获取队列负载cpu_rq(cpu)->load.weight;</em>/
        wl = weighted_cpuload(i);</p>

<pre><code>    /*
     * When comparing with imbalance, use weighted_cpuload()
     * which is not scaled with the cpu power.
     */
    if (capacity &amp;&amp; rq-&gt;nr_running == 1 &amp;&amp; wl &gt; imbalance)
        continue;

    /*
     * For the load comparisons with the other cpu's, consider
     * the weighted_cpuload() scaled with the cpu power, so that
     * the load can be moved away from the cpu that is potentially
     * running at a lower capacity.
     */
    wl = (wl * SCHED_POWER_SCALE) / power;

    if (wl &gt; max_load) {
        max_load = wl;
        busiest = rq;
    }
</code></pre>

<pre><code>通过上面的计算，便拿到了最忙队列。  
当busiest-&gt;nr_running运行数大于1的时候，进行pull操作，pull前对move_tasks,先进行double_rq_lock加锁处理。
</code></pre>

<pre><code>double_rq_lock(this_rq, busiest);
ld_moved = move_tasks(this_rq, this_cpu, busiest,
        imbalance, sd, idle, &amp;all_pinned);
double_rq_unlock(this_rq, busiest);
</code></pre>

<pre><code>move_tasks进程pull task是允许失败的，即move_tasks-&gt;balance_tasks，在此处，有sysctl_sched_nr_migrate开关控制进程迁移个数，对应proc的是/proc/sys/kernel/sched_nr_migrate。

下面有can_migrate_task函数检查选定的进程是否可以进行迁移，迁移失败的原因有3个，1.迁移的进程处于运行状态；2.进程被绑核了，不能迁移到目标CPU上；3.进程的cache仍然是hot，此处也是为了保证cache命中率。
</code></pre>

<pre><code>/*关于cache cold的情况下，如果迁移失败的个数太多，仍然进行迁移
 * Aggressive migration if:
 * 1) task is cache cold, or
 * 2) too many balance attempts have failed.
 */

tsk_cache_hot = task_hot(p, rq-&gt;clock_task, sd);
if (!tsk_cache_hot ||
    sd-&gt;nr_balance_failed &gt; sd-&gt;cache_nice_tries) {
</code></pre>

<h1>ifdef CONFIG_SCHEDSTATS</h1>

<pre><code>    if (tsk_cache_hot) {
        schedstat_inc(sd, lb_hot_gained[idle]);
        schedstat_inc(p, se.statistics.nr_forced_migrations);
    }
</code></pre>

<h1>endif</h1>

<pre><code>    return 1;
}
</code></pre>

<pre><code>
判断进程cache是否有效，判断条件，进程的运行的时间大于proc控制开关sysctl_sched_migration_cost，对应目录/proc/sys/kernel/sched_migration_cost_ns
</code></pre>

<pre><code>static int
task_hot(struct task_struct *p, u64 now, struct sched_domain *sd)
{
        s64 delta;
    delta = now - p-&gt;se.exec_start;
    return delta &lt; (s64)sysctl_sched_migration_cost;
}
</code></pre>

<pre><code>在load_balance中，move_tasks返回失败也就是ld_moved==0，其中sd-&gt;nr_balance_failed++对应can_migrate_task中的”too many balance attempts have failed”,然后busiest-&gt;active_balance = 1设置，active_balance = 1。
</code></pre>

<pre><code>if (active_balance)
//如果pull失败了，开始触发push操作
stop_one_cpu_nowait(cpu_of(busiest),
    active_load_balance_cpu_stop, busiest,
    &amp;busiest-&gt;active_balance_work);
</code></pre>

<pre><code>push整个触发操作代码机制比较绕，stop_one_cpu_nowait把active_load_balance_cpu_stop添加到cpu_stopper每CPU变量的任务队列里面，如下：
</code></pre>

<pre><code>void stop_one_cpu_nowait(unsigned int cpu, cpu_stop_fn_t fn, void *arg,
            struct cpu_stop_work *work_buf)
{
    *work_buf = (struct cpu_stop_work){ .fn = fn, .arg = arg, };
    cpu_stop_queue_work(&amp;per_cpu(cpu_stopper, cpu), work_buf);
}
</code></pre>

<pre><code>而cpu_stopper则是cpu_stop_init函数通过cpu_stop_cpu_callback创建的migration内核线程，触发任务队列调度。因为migration内核线程是绑定每个核心上的，进程迁移失败的1和3问题就可以通过push解决。active_load_balance_cpu_stop则调用move_one_task函数迁移指定的进程。

上面描述的则是整个pull和push的过程，需要补充的pull触发除了schedule后触发，还有scheduler_tick通过触发中断，调用run_rebalance_domains再调用rebalance_domains触发，不再细数。
</code></pre>

<pre><code>void __init sched_init(void)
{
      open_softirq(SCHED_SOFTIRQ, run_rebalance_domains);
}
</code></pre>

<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[try_to_wake_up函数]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/02/11/kernel-sched-trywakeup/"/>
    <updated>2015-02-11T11:32:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/02/11/kernel-sched-trywakeup</id>
    <content type="html"><![CDATA[<p>  try_to_wake_up函数通过把进程状态设置为TASK_RUNNING，并把该进程插入本地CPU运行队列rq来达到唤醒睡眠和停止的进程的目的。<br/>
例如：调用该函数唤醒等待队列中的进程，或恢复执行等待信号的进程。该函数接受的参数有：<br/>
- 被唤醒进程的描述符指针（p）<br/>
- 可以被唤醒的进程状态掩码（state）<br/>
- 一个标志（sync），用来禁止被唤醒的进程抢占本地CPU上正在运行的进程<br/>
<code>
    static int try_to_wake_up(struct task_struct *p, unsigned int state, int sync)
    {
        int cpu, this_cpu, success = 0;
        unsigned long flags;
        long old_state;
        struct rq *rq;
    #ifdef CONFIG_SMP
        struct sched_domain *sd, *this_sd = NULL;
        unsigned long load, this_load;
        int new_cpu;
    #endif
        rq = task_rq_lock(p, &amp;flags);
        old_state = p-&gt;state;
        if (!(old_state &amp; state))
            goto out;
        if (p-&gt;array)
            goto out_running;
        cpu = task_cpu(p);
        this_cpu = smp_processor_id();
    #ifdef CONFIG_SMP
    ... // [多处理器负载平衡工作](/blog/2015/02/11/kernel-sched-balance/)
    #endif /* CONFIG_SMP */
        if (old_state == TASK_UNINTERRUPTIBLE) {
            rq-&gt;nr_uninterruptible--;
            /*
             * Tasks on involuntary sleep don't earn
             * sleep_avg beyond just interactive state.
             */
            p-&gt;sleep_type = SLEEP_NONINTERACTIVE; //简单判断出非交互进程
        } else
            if (old_state &amp; TASK_NONINTERACTIVE)
                p-&gt;sleep_type = SLEEP_NONINTERACTIVE;//同上
        activate_task(p, rq, cpu == this_cpu);
        if (!sync || cpu != this_cpu) {
            if (TASK_PREEMPTS_CURR(p, rq))
                resched_task(rq-&gt;curr);
        }
        success = 1;
    out_running:
        trace_sched_wakeup(rq, p, success);
        p-&gt;state = TASK_RUNNING;
    out:
        task_rq_unlock(rq, &amp;flags);
        return success;
    }
</code>
代码解释如下：<br/>
1.首先调用task_rq_lock( )禁止本地中断，并获得最后执行进程的CPU（他可能不同于本地CPU）所拥有的运行队列rq的锁。CPU的逻辑号存储在p->thread_info->cpu字段。</p>

<p>2.检查进程的状态p->state是否属于被当作参数传递给函数的状态掩码state，如果不是，就跳到第9步终止函数。</p>

<p>3.如果p->array字段不等于NULL，那么进程已经属于某个运行队列，因此跳转到第8步。</p>

<p>4.在多处理器系统中，该函数检查要被唤醒的进程是否应该从最近运行的CPU的运行队列迁移到另外一个CPU的运行队列。实际上，函数就是根据一些启发式规则选择一个目标运行队列。</p>

<p>5.如果进程处于TASK_UNINTERRUPTIBLE状态，函数递减目标运行队列的nr_uninterruptible字段，并把进程描述符的p->activated字段设置为-1。</p>

<p>6.调用activate_task( )函数：
<code>
    static void activate_task(struct task_struct *p, struct rq *rq, int local)
    {
        unsigned long long now;
        now = sched_clock();
    #ifdef CONFIG_SMP
    ...
    #endif
        if (!rt_task(p))
            p-&gt;prio = recalc_task_prio(p, now); //计算平均睡眠时间并返回之后的优先级。
        if (p-&gt;sleep_type == SLEEP_NORMAL) {
            if (in_interrupt())
                p-&gt;sleep_type = SLEEP_INTERRUPTED;
            else {
                p-&gt;sleep_type = SLEEP_INTERACTIVE;
            }
        }
        p-&gt;timestamp = now;
        __activate_task(p, rq);
    }
    static void __activate_task(struct task_struct *p, struct rq *rq)
    {
        struct prio_array *target = rq-&gt;active;
        trace_activate_task(p, rq);
        if (batch_task(p))
            target = rq-&gt;expired;
        enqueue_task(p, target);
        inc_nr_running(p, rq);
    }
</code>
它依次执行下面的子步骤：<br/>
  a) 调用sched_clock( )获取以纳秒为单位的当前时间戳。如果目标CPU不是本地CPU，就要补偿本地时钟中断的偏差，这是通过使用本地CPU和目标CPU上最近一次发生时钟中断的相对时间戳来达到的：now = (sched_clock( ) - this_rq( )->timestamp_last_tick)  +  rq->timestamp_last_tick;<br/>
  b) 调用recalc_task_prio()，把进程描述的指针和上一步计算出的时间戳传递给它。recalc_task_prio()主要更新进程的平均睡眠时间和动态优先级，下一篇博文将详细说明这个函数。<br/>
  c) 根据下表设置p->activated字段的值，该字段的意义为：<br/>
        值             说明<br/>
        0   进程处于TASK_RUNNING 状态。<br/>
        1   进程处于TASK_INTERRUPTIBLE 或TASK_STOPPED 状态，而且正在被系统调用服务例程或内核线程唤醒。<br/>
        2   进程处于TASK_INTERRUPTIBLE 或TASK_STOPPED 状态，而且正在被中断处理程序或可延迟函数唤醒。<br/>
        -1  进程处于TASK_UNINTERRUPTIBLE 状态而且正在被唤醒。
  d) 使用在第6a步中计算的时间戳设置p->timestamp字段。<br/>
  e) 把进程描述符插入活动进程集合：
<code>
    enqueue_task(p, rq-&gt;active);
    rq-&gt;nr_running++;
</code></p>

<p>7.如果目标CPU不是本地CPU，或者没有设置sync标志，就检查可运行的新进程的动态优先级是否比rq运行对了中当前进程的动态优先级高（p->prio &lt; rq->curr->prio）；如果是，就调用resched_task()抢占rq->curr。在单处理器系统中，后面的函数只是执行set_tsk_need_resched()来设置rq->curr进程的TIF_NEED_RESCHED标志。在多处理器系统中，resched_task()也检查TIF_NEED_RESCHED的旧值是否为0、目标CPU与本地CPU是否不同、rq->curr进程的TIF_POLLING_NRFLAG标志是否清0（目标CPU没有轮询进程TIF_NEED_RESCHED标志的值）。如果是，resched_task()调用smp_send_reschedule()产生IPI，并强制目标CPU重新调度。</p>

<p>8.把进程的p->state字段设置为TASK_RUNNING状态。</p>

<p>9.调用task_rq_unlock()来打开rq运行队列的锁并打开本地中断。</p>

<p>10.返回1（若成功唤醒进程）或0（如果进程没有被唤醒）</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[内核线程使用]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/02/11/kernel-sched-kthread/"/>
    <updated>2015-02-11T11:06:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/02/11/kernel-sched-kthread</id>
    <content type="html"><![CDATA[<p><a href="http://blog.csdn.net/newnewman80/article/details/7050090">http://blog.csdn.net/newnewman80/article/details/7050090</a></p>

<h5>kthread_create：创建线程。</h5>

<pre><code>struct task_struct *kthread_create(int (*threadfn)(void *data),void *data,const char *namefmt, ...);
</code></pre>

<p>线程创建后，不会马上运行，而是需要将kthread_create() 返回的task_struct指针传给wake_up_process()，然后通过此函数运行线程。</p>

<h5>kthread_run ：创建并启动线程的函数：</h5>

<pre><code>struct task_struct *kthread_run(int (*threadfn)(void *data),void *data,const char *namefmt, ...);
</code></pre>

<h5>kthread_stop：通过发送信号给线程，使之退出。</h5>

<pre><code>int kthread_stop(struct task_struct *thread);
</code></pre>

<p>线程一旦启动起来后，会一直运行，除非该线程主动调用do_exit函数，或者其他的进程调用kthread_stop函数，结束线程的运行。<br/>
但如果线程函数正在处理一个非常重要的任务，它不会被中断的。当然如果线程函数永远不返回并且不检查信号，它将永远都不会停止。</p>

<h4>1. 头文件</h4>

<pre><code>    #include &lt;linux/sched.h&gt;        //wake_up_process()
    #include &lt;linux/kthread.h&gt;      //kthread_create()、kthread_run()   
    #include &lt;err.h&gt;                //IS_ERR()、PTR_ERR()  
</code></pre>

<h4>2. 实现</h4>

<h5>2.1创建线程</h5>

<p>kernel thread可以用kernel_thread创建，但是在执行函数里面必须用daemonize释放资源并挂到init下，还需要用completion等待这一过程的完成。为了简化操作kthread_create闪亮登场。
在模块初始化时，可以进行线程的创建。使用下面的函数和宏定义：
<code>
    struct task_struct *kthread_create(int (*threadfn)(void *data),     
                                void *data,  
                                const char namefmt[], ...);  
</code>
<code>
    #define kthread_run(threadfn, data, namefmt, ...)                      \
    ({                                                                     \
        struct task_struct *__k                                            \
               = kthread_create(threadfn, data, namefmt, ## __VA_ARGS__);  \
        if (!IS_ERR(__k))                                                  \
               wake_up_process(__k);                                       \
        __k;                                                               \
    })  
</code>
例如：
<code>
    static struct task_struct *test_task;  
    static int test_init_module(void)  
    {  
        int err;  
        test_task = kthread_create(test_thread, NULL, "test_task");  
        if (IS_ERR(test_task)) {  
            printk("Unable to start kernel thread./n");  
            err = PTR_ERR(test_task);  
            test_task = NULL;  
            return err;  
        }  
        wake_up_process(test_task);  
        return 0;  
    }  
    module_init(test_init_module);  
</code></p>

<h5>2.2线程函数</h5>

<p>在线程函数里，完成所需的业务逻辑工作。主要框架如下所示：
<code>
    int threadfunc(void *data) {
        ...        
        while(1) {
            set_current_state(TASK_UNINTERRUPTIBLE);
            if (kthread_should_stop()) break;
            if () { //条件为真
                //进行业务处理
            } else { //条件为假
                //让出CPU运行其他线程，并在指定的时间内重新被调度
                schedule_timeout(HZ);
            }
        }
        ...
        return 0;
    }
</code></p>

<h5>2.3结束线程</h5>

<p>在模块卸载时，可以结束线程的运行。使用下面的函数：
<code>
    int kthread_stop(struct task_struct *k);
</code>
例如：
<code>
    static void test_cleanup_module(void)  
    {  
        if (test_task) {  
            kthread_stop(test_task);  
            test_task = NULL;  
        }  
    }  
    module_exit(test_cleanup_module);  
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[linux的调度分析（转）]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/01/22/kernel-sched-n2/"/>
    <updated>2015-01-22T17:42:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/01/22/kernel-sched-n2</id>
    <content type="html"><![CDATA[<p><a href="http://blog.csdn.net/cybertan/article/details/5686451">http://blog.csdn.net/cybertan/article/details/5686451</a></p>

<h3>调度</h3>

<h3>公平调度 (fair-share scheduling) 的进程调度算法：</h3>

<h4>一、公平分享的调度策略</h4>

<p>  Linux 的调度算法是相对独立的一个模块，而且较容易理解。因此很多系统高手都爱对调度算法做改进。但是可以说调度器是一个非常神秘，难以捉摸的精灵。可能通过改变一个关键参数你就可以大大提高系统的效率。<br/>
  对于一般进程， CPU 的使用时间都是系统平均分配给每一个进程的，因此这种公平分享都是从 进程的角度 出发的。 Bach 在 1986 年提出了公平分享调度策略（ Fair_Share scheduling ）来解决这个问题。和 Linux 三种内建策略比，公平分享调度策略是一种更抽象的调度策略。它认为 CPU 应该根据拥有进程的组（对 Linux 来说是用户）来分配时间，它实现了从 用户角度 考虑的公平原则。</p>

<p>由内核的结构来看，实现这个算法有很多种方式。我们可以在与调度相关的程序里做小小的改动来实现，如改动一些数据结构并改写 schedule() 函数。当然也可以做得很复杂，比如重写 schedule() 来实现所需要的结果。但是有一点我们是要必须牢记的，那就是大部分的 Linux 核心都是以短小高效为最高目标。所以，改进的算法必须尽量向这个目标靠拢。</p>

<h4>二、新调度策略的实现：分析</h4>

<p>1 、这里所说的 ‘ 组 ’ 的概念，在 Linux 中是一个用户。我们所关心的是 Linux 的用户，而不是 UNIX 系统下的用户组或是别的什么概念。因此 在公平共享调度策略中，一个进程能够分配到的时间与登录的系统用户数以及拥有该进程用户开辟进程数的多少有关。<br/>
2 、超级用户的进程是 独立于公平分享算法 的，因此它拥有的进程得到的调度时间应该和现在的进程调度算法分配时间相当。<br/>
3 、对于实时进程，调度算法仍旧给予比普通进程更高的优先权。不过也不用担心会花太多的时间去实现，只要在现在调度算法的基础上稍做改进就可以简单实现。<br/>
4 、新的调度算法对系统的吞吐量不能有太多的影响。比如说，如果定义的时间片少于 2 个 “ 滴答 ” ，那么新实现的调度器效率将变得很差。因为过于频繁的进程切换将耗费大部分的系统时间，而真正用于程序计算的时间则排在第二位了。 此条说明时间片的划分不能太小。<br/>
5 、我们所实现的算法并不需要绝对的公平，严格的平均是需要用效率为代价来换取的。如果算法过于精确，那就需要复杂的数据结构和耗时的计算过程，所以我们可以在以速度为第一原则的基础上实现 “ 模糊 ” 的公平分享。<br/>
6 、我们首先需要的是不断地思考和设计，只有将所有的问题都考虑清楚以后才可以开始动手。调度器是操作系统的核心，它将被频繁调用，因此其作用和影响也将是巨大的。我们要花费最小的代价实现算法，并且这种改动对系统核心的影响要降到最小。</p>

<h4>Linux 的进程调度机制：</h4>

<p>概述：<br/>
在多进程的操作系统中，进程调度是一个全局性的、关键性的问题。可以说，关于进程调度的研究是整个操作系统理论的核心，它对系统的总体设计、系统的实现、功能设置以及各方面的性能都有着决定性的影响。</p>

<h5>1、 150ms ：当系统中有大量进程共存时，根据测定，当每个用户可以接受的相应速度延迟超过１５０ ms 时，使用者就会明显地感觉到了。</h5>

<h5>2、 在设计一个进程调度机制时要考虑的具体问题主要有：</h5>

<p>调度的时机：什么情况下、什么时候进行调度；<br/>
调度的政策：根据什么准则挑选下一个进入运行的进程；<br/>
调度的方式：是 “ 可剥夺 ” 还是 “ 不可剥夺 ” 。当正在运行的进程并不自愿暂时放弃对ＣＰＵ的使用权时，是否可以强制性地暂时剥夺其使用权，停止其运行而给其他进程一个机会。如果是可剥夺的，那么是否在任何条件下都可剥夺，有没有例外？</p>

<h5>3、linux 内核的调度机制：</h5>

<h6>１）调度的时机：</h6>

<ul>
<li>首先，自愿的调度 ( 主动调度 ) 随时都可以进行：在内核里面，一个进程可以通过 schedule() 启动一次调度。也就是由当前进程自愿调用 schedule() 暂时放弃运行的情景。</li>
<li>除此之外，调度还可以非自愿的，即强制地发生在每次从系统调用返回的前夕，以及每次从中断或者异常处理 返回到用户空间 的前夕。</li>
</ul>


<p>上述红字说明：只有在用户空间（当ＣＰＵ在用户空间运行时）发生的中断或者异常才会引起调度。
<code>
    ret_from_exception:
        movl SYMBOL_NAME(bh_mask),%eax
        andl SYMBOL_NAME(bh_active),%eax
        jne handle_bottom_half
        ALIGN
    ret_from_intr:
        GET_CURRENT(%ebx)
        movl EFLAGS(%esp),%eax        # mix EFLAGS and CS
        movb CS(%esp),%al
        testl $(VM_MASK | 3),%eax    # return to VM86 mode or non-supervisor?
        jne ret_with_reschedule
        jmp restore_all
</code>
　　 从上述代码中 (arch/i386/kernel/entry.S) ，可以看出，转入 ret_with_reschedule 的条件为中断或异常发生前 CPU 的运行级别为３，即用户态。</p>

<p>这一点 ( 只有在用户空间发生的中断或者异常才会引起调度 ) 对于系统的设计和实现有很重要的意义：因为这意味着当 CPU 在内核中运行时无需考虑强制调度的可能性。发生在系统空间中的中断或异常当然是可能的，但是这种中断或者异常不会引起调度。这使得内核的实现简化了，早期的 Unix 内核正是靠这个前提来简化其设计与实现的。否则的话，内核中所有可能为一个以上进程共享的变量和数据结构就全都要通过互斥机制 ( 如信号量 ) 加以保护，或者说放在临界区里面。即在内核中由于不会发生调度而无需考虑互斥。但是在多处理器 SMP 系统中，这种简化正在失去重要性：因为我们不得不考虑在另一个处理器上运行的进程访问共享资源的可能性。这样，不管在同一个 CPU 上是否可能在内核中发生调度，所有可能为多个进程 ( 可能在不同的 CPU 上运行 ) 共享的变量和数据结构，都得保护起来。这就是为什么读者在阅读代码时看到那么多的 up() 、 down() 等信号量操作或者加锁操作的原因。</p>

<p>注意： “ 从系统空间返回到用户空间 ” 只是发生调度的必要条件，而不是充分条件。也就是说，这个条件满足了，调度并不是一定会发生的，具体是否发生调度还要判断当前进程的 task_struct 结构中的 need_resched 成员是否为非０，非０时才会转到 reschedule 处调用 schedule():
<code>
     ret_with_reschedule:
        cmpl $0, need_resched(%ebx)
        jne reschedule
        cmpl $0,sigpending(%ebx)
        jne signal_return
    ....
     reschedule:
        call SYMBOL_NAME( schedule )    # test
        jmp ret_from_sys_call
</code>
need_resched 成员是内核设置的，因为在用户空间是访问不到进程的 task_struct 结构的。除了当前进程通过系统调用自愿让出运行以及在系统调用中因某种原因受阻以外，主要就是当因某种原因唤醒一个进程的时候，以及在时钟中断服务程序发现当前进程已经连续运行太久的时候，内核会对
need_resched 成员进行设置 ( 非０ ) ，以重新调度。</p>

<h6>２）调度的方式：</h6>

<p>Linux 内核的调度方式可以说是 “ 有条件的可剥夺 ” 方式。
＊当进程在用户空间运行时，无论自愿不自愿，一旦有必要 ( 例如该进程已经运行了足够长的时间 ) ，内核就可以暂时剥夺其运行而调度其他进程进入运行。</p>

<p>＊但是，一旦进程进入了内核空间，或者说进入 “ 系统态 ” 。这时候，尽管内核知道应该要调度了，但是实际上调度并不会发生，直到该进程即将 “ 下台 ” ，也就是 回到用户空间的前夕 才能剥夺其运行权力。所以， linux 的调度方式从原则上来说是可剥夺的，可是实际上由于调度时机的限制而变成了有条件的。</p>

<h6>３）调度策略：</h6>

<p>  基本上是从 UNIX 继承下来的 以优先级为基础 的调度。内核为系统中的每个进程计算出一个反映其运行 “ 资格 ” 的权值，然后挑选权值最高的进程投入运行。在运行的过程中，当前进程的资格 ( 权值 ) 随时间而递减，从而在下一次调度的时候原来资格较低的进程可能就更有资格运行了。到所有的进程的资格都变为０时，就重新计算一次所有进程的资格。<br/>
  但是，为了适应各种不同应用的需要，内核 在此基础上 实现了三种不同的策略： SCHED_FIFO 、 SCHED_RR 、 SCHED_OTHER 。每个进程都有自己适用的调度策略，并且，进程还可以通过系统调用 sched_setscheduler() 设定自己适用的调度策略。下面介绍一下他们的区别：<br/>
   SCHED_FIFO ：适用于时间性要求比较强，但每次运行所需的时间比较短的进程，因此多用于实时进程；<br/>
   SCHED_RR:RR 表示 Round Robin ，是轮流的意思 ( 轮换调度 ) ，这种策略适合比较大、也就是每次运行时间较长的程序。使用 SCHED_RR 策略地进程在 schedule() 调度中有一点特殊的处理。　</p>

<p>  上两者的比较： SCHED_FIFO 、 SCHED_RR 都是基于优先级的调度策略，可是在怎样调度具有相同优先级的进程的问题上两者有区别：<br/>
   调度策略为 SCHED_FIFO 的进程一旦受到调度而开始运行之后，就要一直运行到自愿让出或者被优先级更高的进程剥夺为止。对于每次受到调度时要求运行时间不长的进程，这样并不会有多大的影响。可是， 如果是受到调度后可能执行很长时间的进程 ，这样就不公平了。这种不公正性是对具有相同优先级的进程而言的，同级的进程必须等待该进程自愿让出或者直到其运行结束。因为具有更高优先级的进程可以剥夺他的运行，而优先级则本来就没有机会运行，谈不上不公正。</p>

<p>　所以，对于执行时间可能会很长的进程来说，应该使用 SCHED_RR 调度策略，这种策略 在相同的优先级的进程上实行轮换调度。 也就是说：对调度策略为 SCHED_RR 的进程有个时间配额，用完这个配额就要让具有相同优先级的其他就绪进程先运行。看 schedule() 的５４０行对调度策略为 SCHED_RR 的当前进程的处理。</p>

<p> SCHED_OTHER ：是传统的调度策略，比较适合于交互式的分时应用。</p>

<p> 问题：既然每个进程都有自己的适用的调度策略，内核怎样来调用使用不同调度策略的进程的呢？是根据什么挑选出下一个要运行的进程呢？</p>

<p> 实际上，挑选的原则最后还是归结到每个进程的权值，只不过是在计算资格的时候将适用的策略也考虑进去了，就好像考大学时符合某些特殊条件的考生会获得加分一样。同时，对于适用不同策略地进程的优先级别也加了限制。</p>

<h5>4、调度程序 schedule() ：</h5>

<p>  调度程序 schedule() 是一个非常频繁地执行的函数，因此要将运行效率放在第一位，函数中使用了很多的 goto 语句。<br/>
  前面讲过，对 schedule() 只能由进程在内核中主动 调用，或者在当前进程从系统空间返回用户空间的前夕被动的 发生，而不能在一个中断服务程序的内部发生。即使一个中断服务程序有调度的要求，也只能通过把当前进程的 need_resched 字段设为１来表达这种要求，而不能直接调用 schedule() 。所以，如果在某个中断服务程序内部调用了 schedule() ，那一定是有问题的，所以转向 scheduling_in_interrupt.(kernel/sched.c)
<code>
        asmlinkage void schedule(void)
    509 {
    510 struct schedule_data * sched_data;
    511 struct task_struct *prev, *next, *p;
    512 struct list_head *tmp;
    513 int this_cpu, c;
    514
    515 if (!current&gt;
    active_mm) BUG();
    516 need_resched_back:
    517 prev = current;
    518 this_cpu = prev&gt;
    processor;
    519
    520 if (in_interrupt())
    521 goto scheduling_in_interrupt ;
    522
    523 release_kernel_lock(prev, this_cpu);
    524
    525 /* Do "administrative" work here while we don't hold any locks */
    526 if (softirq_active(this_cpu) &amp; softirq_mask(this_cpu))
    　　 /* 检查是否有内核软中断服务请求在等待，若有，就转入 handle_softirq 为这些请求服务 */
    527 goto handle_softirq;
    528 handle_softirq_back:
</code>
我们来看一下内核对这种问题的响应：
<code>
    [schedule()]
    686 scheduling_in_interrupt:
    687 　　 printk("Scheduling in interrupt/n");
    688 　　 BUG();
    689 　　 return;
</code>
内核对此的响应是显示或者在 /var/log/messages 文件末尾添上一条出错信息，然后执行一个宏操作 BUG 。</p>

<p>接着往下看 schedule() ：<br/>
如果有内核软中断服务请求在等待，那么就转入 handle_softirq ：
<code>
    　 [schedule()]
    675 handle_softirq:
    676 　　　 do_softirq();
    677 　　　 goto handle_softirq_back;
</code>
执行 softirq 队列完毕以后继续往下看：
<code>
    　　 ==================== kernel/sched.c 528 541 ====================
    [schedule()]
    528 handle_softirq_back:
    529
    530 /*
    531 * 'sched_data' is protected by the fact that we can run
    532 * only one process per CPU.
    533 */
    534 sched_data = &amp; aligned_data[this_cpu].schedule_data;
    535
    536 spin_lock_irq(&amp;runqueue_lock);
    537
    538 /* move an exhausted RR process to be last.. */
    539 if (prev&gt;policy == SCHED_RR)
    540 　　　 goto move_rr_last;
    541 move_rr_back:
</code>
指针 sched_data 指向一个 schedule_data 数据结构，用来保存供下一次调度时使用的信息。此数据结构的定义如下：
<code>
    ==================== kernel/sched.c 91 101 ====================
    91 /*
    92 * We align perCPU
    scheduling data on cacheline boundaries,
    93 * to prevent cacheline pingpong.
    94 */
    95 static union {
    96 　　 struct schedule_data {
    97 　　　　 struct task_struct * curr;
    98 　　　　 cycles_t last_schedule;
    99 　　　 } schedule_data;
    100 　　　 char __pad [SMP_CACHE_BYTES];
    101 } aligned_data [ NR_CPUS ] __cacheline_aligned = { };
</code>
这里的 cycles_t 实际上是无符号整数，用来记录调度发生的时间。这个数据结构是为多处理器 SMP 结构而设的，因此我们不必关心。数组中的第一个元素，即 CPU0 的 schedule_data 结构初始化为 {&amp;init_task,0} ，其余的则全为｛０，０｝。代码中的 __cacheline_aligned 表示数据结构的起点应与高速缓存中的缓冲线对齐。</p>

<p>下面就要涉及可执行进程队列了，所以先将这个队列锁住 (536 行 ) ，以防止其他处理器的干扰。从 538 行开始：如果当前进程 prev 的调度策略是 SCHED_RR ，也就是轮换调度，那就要先进行一点特殊的处理 ( 540 : goto move_rr_last; ) 。
（对使用 SCHED_RR 策略的当前进程的处理）
<code>
      ==================== kernel/sched.c 679 685 ====================
     [schedule()]
    679  move_rr_last:
    680   if (!prev&gt;counter) {
    681       prev&gt;counter = NICE_TO_TICKS (prev&gt;nice);
    682       move_last_runqueue(prev);
    683     }
    684 goto move_rr_back;
</code>
  这里的 prev>counter ：代表这当前进程的运行时间配额，其数值在每次时钟中断时都要递减 (update_process_times() 中实现的 ) 。因此，不管一个进程的时间配额有多高，随着运行时间的积累最终总会递减到０。对于调度策略为 SCHED_RR 的进程，一旦其时间配额降到０，就要从 可执行进程队列 runqueue 中当前的位置上移动到队列的末尾，同时恢复其最初的时间配额（ NICE_TO_TICKS ），以等待下一次的调度。对于具有相同优先级的进程，调度的时候排在前面的进程优先，所以这使队列中具有相同优先级的其他进程有了优势。<br/>
  宏操作 NICE_TO_TICKS 根据系统时钟的精度将进程的优先级别换算成可以运行的时间配额。在 kernel/sched.c 中定义。<br/>
　将一个进程的 task_struct 结构从可执行队列中的当前位置移到队列的末尾是由 move_last_runqueue() 完成的 (kernel/sched.c) 。把进程移到可执行进程队列的末尾意味着：如果队列中没有资格更高的进程，但是有一个资格与之相同的进程存在，那么，这个资格虽然相同而排在前面的进程会被选中。</p>

<p>继续看 schedule() ：
<code>
    ==================== kernel/sched.c 541 553 ====================
    [schedule()]
    541 move_rr_back:
    542
    543 switch ( prev&gt;state ) {
    544 case TASK_INTERRUPTIBLE:
    545 　　　 if (signal_pending(prev)) {
    546 　　　　　　 prev&gt;state = TASK_RUNNING;
    547 　　　　　　 break;
    548 　　　　 }
    549 default:
    550 　　　 del_from_runqueue(prev);
    551 case TASK_RUNNING:
    552 }
    553 prev&gt;need_resched = 0;
</code>
  当前进程，就是正在执行的进程，当进入 schedule() 时其状态却不一定是 TASK_RUNNING 。例如：当前进程如已经在 do_exit() 中将其状态改成 TASK_ZOMBIE ，又如当前进程在 sys_wait4() 中调用 schedule() 时的状态为 TASK_INTERRUPTIBLE 。所以，这里的 prev>state 与其说是当前进程的状态不如说是其意愿。当其意愿既不是继续执行也不是可中断的睡眠时，就要通过 del_from_runqueue() 把这个进程从可执行队列中撤下来。另一方面， 也可以看出 TASK_INTERRUPTIBLE 和 TASK_UNINTERRUPTIBLE 两种睡眠状态之间的区别： 前者在进程有信号等待处理时要将其改成 TASK_RUNNING ，让其处理完这些信号再说，而后者则不受信号的影响。</p>

<p>  最后，将 prev>need_resched 恢复为０，因为所需求的调度已经在进行了。 下面的任务就是要 挑选出一个进程来运行了 ( 这一部分是很重要的，通过对就绪进程队列进行扫描 ) 。
<code>
    ==================== kernel/sched.c 555 576 ====================
    [schedule()]
    555 /*
    556 * this is the scheduler proper:
    557 */
    558
    559 repeat_schedule:
    560 /*
    561 * Default process to select..
    562 */
    563 next = idle_task (this_cpu);
    564 c = 1000;
    565 if ( prev&gt;state == TASK_RUNNING )
    566      goto still_running;
    567
    568 still_running_back:
    569      list_for_each (tmp, &amp;runqueue_head) {
    570          p = list_entry(tmp, struct task_struct, run_list);
    571          if (can_schedule(p, this_cpu)) {
    572           int weight = goodness (p, this_cpu, prev&gt;active_mm);
    573           if ( weight &gt; c )
    574            c = weight, next = p;
    575          }
    576 }
</code>
在这段程序中， next 总是指向已知最佳的候选进程， c 则是这个进程的综合权值，或者是运行资格。</p>

<p>  挑选的过程是从 idle 进程即 0 号进程开始，其权值为－ 1000 ，这是可能的最低值，表示仅在没有其他进程可以运行时才会让他运行。<br/>
  然后，遍历可执行队列 runqueue 中的每个进程 ( 在单 CPU 系统中 can_schedule() 的返回值永远是 1) ，也就是一般操作系统书中所称的就绪进程。为每一个就绪进程通过函数 goodness () 计算出他当前所具有的权值，然后与当前的最高值 c 相比。注意这里的条件： weight > c ， 这意味着 “ 先入为大 ” 。也就是说，如果两个进程有相同的权值的话，排在队列前面的进程胜出，优先运行。</p>

<p>这里还有一个小插曲：如果当前进程的意图是继续运行，那么就要先执行一下 still_running(kernel/sched.c) ：
<code>
      ==================== kernel/sched.c 670 674 ====================
    [schedule()]
    670 still_running:
    671    c = goodness(prev, this_cpu, prev&gt;active_mm);
    672    next = prev;
    673    goto still_running_back;
    674
</code>
也就是说，如果当前进程想要继续运行，那么在挑选候选进程时以当前进程此刻的权值开始比较。而且这意味着，对于具有相同权值的其他进程来说，当前进程优先。</p>

<p>  那么，进程的当前权值是怎样计算的呢？也就是 goodness() 是怎样执行的呢？
<code>
    ==================== kernel/sched.c 123 187 ====================
    [schedule()&gt; goodness() ]
    123 /*
    124 * This is the function that decides how desirable a process is..
    125 * You can weigh different processes against each other depending
    126 * on what CPU they've run on lately etc to try to handle cache
    127 * and TLB miss penalties.
    128 *
    129 * Return values:
    130 * 1000:never select this
    131 * 0: out of time, recalculate counters (but it might still be
    132 * selected)
    133 * +ve: "goodness" value (the larger, the better)
    134 * +1000: realtime process, select this.
    135 */
    136
    137 static inline int goodness(struct task_struct * p, int this_cpu, struct mm_struct *this_mm)
    138 {
    139 int weight;
    140
    141 /*
    142 * select the current process after every other
    143 * runnable process, but before the idle thread.
    144 * Also, dont trigger a counter recalculation.
    145 */
    146 weight = -1 ;
    147 if (p&gt;policy &amp; SCHED_YIELD )
    148 goto out;
    149
    150 /*
    151 * Non RT process normal case first.
    152 */
    153 if ( p&gt;policy == SCHED_OTHER ) {
    154 /*
    155 * Give the process a firstapproximation goodness value
    156 * according to the number of clockticks it has left.
    157 *
    158 * Don't do any other calculations if the time slice is
    159 * over..
    160 */
    161    weight = p-&gt;counter;
    162    if (!weight)
    163    goto out;
    164
    165 #ifdef CONFIG_SMP
    166 /* Give a largish advantage to the same processor... */
    167 /* (this is equivalent to penalizing other processors) */
    168 if (p-&gt;processor == this_cpu)
    169    weight += PROC_CHANGE_PENALTY;
    170 #endif
    171
    172 /* .. and a slight advantage to the current MM */
    173   if (p-&gt;mm == this_mm || !p-&gt;mm)
    174       weight += 1;
    175    weight += 20- p&gt;nice;
    176    goto out;
    177 }
    178
    179 /*
    180 * Realtime process, select the first one on the
    181 * runqueue (taking priorities within processes
    182 * into account).
    183 */
    184      weight = 1000 + p-&gt;rt_priority;
    185 out:
    186      return weight;
    187 }
</code>
  ＊首先，如果一个进程通过系统调用 sched_yield() 明确表示了 “ 礼让 ” 后，就将其权值定位 -1 。这是很低的权值，一般就绪进程的权值至少是 0 。<br/>
  ＊对于没有实时要求的进程 ，即调度策略为 SCHED_OTHER 的进程，其权值主要取决于两个因素：一个是剩下的时间配额 p->counter ，如果用完了则权值为 0 。另一个是进程的优先级 nice ，这是从早期 Unix 沿用下来的负向优先级 ( 越负，优先级越高 ) ，其取值范围为 19~-20 ，只有特权用户才能把 nice 值设置为小于 0 。所以，综合的权值 weight 在时间配额尚未用完时基本上是二者之和。 此外，如果是内核线程，或者其用户 空间与当前进程的相同，因而无需切换用户空间，则会得到一点小 “ 奖励 ” ，将权值额外加 1 。<br/>
  ＊对于实时进程，即调度策略为 SCHED_FIFO 或者 SCHED_RR 的进程，则另有一种正向的优先级 ，那就是实时优先级 rt_priority ，而权值为 1000 + p->rt_priority 。可见， SCHED_FIFO 或者 SCHED_RR 两种有时间要求的策略赋予进程很高的权值 ( 相对于 SCHED_OTHER) 。这种进程的权值至少是 1000 。另一方面， rt_priority 的值对于实时进程之间的权值比较也起着重要的作用，其数值也是在 sched_setscheduler() 中与调度策略一起设置的。</p>

<p>从上面可以看出：对于这两种实时调度策略，一个进程已经运行了多久，即时间配额 p->counter 的当前值，对权值的计算不起所用。不过，前面讲到，对于使用 SCHED_RR 策略地进程，当 p->counter 达到 0 时会导致将进程移到队列尾部。<br/>
  实时进程的 nice 数值与优先级无关，但是对 使用 SCHED_RR 策略地进程的时间配额大小有关 ( 宏操作 NICE_TO_TICKS()) 。由于实时进程的权值有个很大的基数 (1000) ，因此当有实时进程就绪时，非实时进程是没有机会运行的。</p>

<p>由此可见， linux 内核中对权值的计算是很简单的，但是 goodness() 函数并不代表 linux 调度算法的全部，而要与前面讲到的 对 SCHED_RR 进程的特殊处理 、 对意欲继续运行的当前进程的特殊处理 ‘ 以及下面要讲到的 recalculate 结合起来分析。</p>

<p>上面 still_running_back 运行结束后，变量 c 的值有几种可能：一种可能是一个大于 0 的正数，此时 next 指向挑选出来的进程；另一种可能是 c 的值为 0 ，发生于就绪队列中所有进程的权值都是 0 的时候。由于除了 init 进程和调用了 sched_yield() 的进程以外，每个进程的权值最低为 0 ，所以只要队列中有其他就绪进程存在就不可能为负数。因此，队列中所有其他进程的权值都已经降到 0 了，说明这些进程的调度策略都是 SCHED_OTHER ，即系统中当前没有就绪的实时进程，因为如果有策略为 SCHED_FIFO 或者 SCHED_RR 的进程存在，其权值至少也有 1000 。</p>

<p>let`s go on ：回到 schedule()
<code>
==================== kernel/sched.c 578 580 ====================
[schedule()]
578 /* Do we need to recalculate
counters? */
579 if (!c)
580 goto recalculate;
</code>
如果当前已经选择的进程（权值最高的进程）的权值为 0 ，那就要重新计算各个进程的时间配额。如上所述，这说明系统中当前没有就绪的实时进程。而且，这种情况已经持续了一段时间，否则 SCHED_OTHER 进程的权值就没有机会消耗到 0 。
<code>
 ==================== kernel/sched.c 658 669 ====================
[schedule()]
658 recalculate:
659 {
660     struct task_struct *p;
661     spin_unlock_irq(&amp;runqueue_lock);
662     read_lock(&amp;tasklist_lock);
663     for_each_task (p)
664         p-&gt;counter = (p-&gt;counter &gt;&gt; 1) + NICE_TO_TICKS(p-&gt;nice);
665     read_unlock(&amp;tasklist_lock);
666     spin_lock_irq(&amp;runqueue_lock);
667 }
668  goto repeat_schedule;
</code>
  这里所作的运算是将每个进程的当前的时间配额 p->counter 除以 2 ，再在上面加上由该进程的 nice 值换算过来的 tick 数量。宏操作 NICE_TO_TICKS 的定义在前面已经见过，显然 nice 值对于非实时进程既表示优先级也决定着时间配额。<br/>
  注意：这里的 for_each_task() 是对所有进程的循环，而并不是仅对就绪进程队列的循环，对于不再就绪进程队列中的非实时进程 ，这里得到了提升其时间配额、从而提升其综合权值的机会。不过，这种对综合权值的提升是很有限的，每次重新计算都将原有的时间配额减半，再与 NICE_TO_TICKS(p->nice) 相加，这样就决定了重新计算以后的综合权值永远也不可能达到 NICE_TO_TICKS(p->nice) 的两倍。因此，即使经过很长时间的韬光养晦，也不可能达到可与实时进程竞争的地步，所以只是对非实时进程之间的竞争有意义。<br/>
  至于实时进程，时间配额的增加并不会提升其综合权值，而且对于 SCHED_FIFO 进程，时间配额就没有什么意义。
重新计算完权值以后，程序转回 repeat_schedule( 跳回前面，再次执行挑选进程 ) 处重新挑选。这样，当再次完成对就绪进程队列的扫描时，变量 c 的值就应该不为 0 了，此时 next 指向挑选出来的进程。<br/>
至此，已经挑选好进程了（权值最高的进程）。</p>

<p>还没有结束阿？哈哈<br/>
进程挑好之后，接下来要做的就是切换的事情了。
<code>
    [schedule()]
    581 /*
    582 * from this point on nothing can prevent us from
    583 * switching to the next task, save this fact in
    584 * sched_data.
    585 */
    586 sched_data&gt;curr = next;
    587 #ifdef CONFIG_SMP
    .....
    590 #endif
    591 spin_unlock_irq(&amp;runqueue_lock);
    592
    593 if ( prev == next )
    594     goto same_process;
    595
    596 #ifdef CONFIG_SMP
    ==================== kernel/sched.c 612 657 ====================
    612 #endif /* CONFIG_SMP */
    613
    614 kstat.context_swtch++;
    615 /*
    616 * there are 3 processes which are affected by a context switch:
    617 *
    618 * prev == .... ==&gt; (last =&gt; next)
    620 * It's the 'much more previous' 'prev' that is on next's stack,
    621 * but prev is set to (the just run) 'last' process by switch_to().
    622 * This might sound slightly confusing but makes tons of sense.
    623 */
    624 prepare_to_switch ();
    625 {
    626   struct mm_struct *mm = next-&gt;mm;
    627   struct mm_struct *oldmm = prev-&gt;active_mm;
    628   if (!mm) {
    629         if (next&gt;active_mm) BUG();
    630         next&gt;active_mm = oldmm;
    631         atomic_inc(&amp;oldmm&gt;mm_count);
    632          enter_lazy_tlb(oldmm, next, this_cpu);
    633 } else {
    634      if (next&gt;active_mm != mm) BUG();
    635     switch_mm(oldmm, mm, next, this_cpu);
    636 }
    637
    638 if (!prev&gt;mm) {
    639       prev&gt;active_mm = NULL;
    640       mmdrop(oldmm);
    641 }
    642 }
    643
    644 /*
    645 * This just switches the register state and the
    646 * stack.
    647 */
    648 switch_to(prev, next, prev);
    649 __schedule_tail(prev);
    650
    651 same_process:
    652     reacquire_kernel_lock(current);
    653     if (current&gt;need_resched)
    654        goto need_resched_back;
    655
    656    return;
</code>
跳过对 SMP 结构的条件编译部分。<br/>
  首先，如果挑选出来的进程 next 就是当前进程 prev ，就不用切换，直接跳转到 same_process 处就返回了。这里的 reacquire_kernel_lock() 对于 i386 单 CPU 结构而言是空语句。前面已经把当前进程的 need_resched 清 0 ，如果现在又成了非 0 ，则一定是发生了中断并且情况有了变化，所以转回 need_resched_back 再调度一次。<br/>
  否则，如果挑选出来的进程 next 与当前进程 prev 不同，那就要切换了。对于 i386 单 CPU 结构而言， prepare_to_switch() 也是空语句。而 649 行的 __schedule_tail() 则只是将当前进程 prev 的 task_struct 结构中的 policy 字段里的 SCHED_YIELD 标志位清成 0 。所以实际上只剩下了两件事：对用户虚存空间的处理；进程的切换 switch_to() 。</p>

<ol>
<li></li>
<li></li>
</ol>


<p>实验：<br/>
第二部分：如何在 sched.c 中实现算法？</p>

<p>首先，确定何时进行算法的计算过程。 是在 schedule() 中选择下一运行进程之前？<br/>
选择下一运行进程时？选择下一运行进程之后？还是直接修改 goodness() 函数以确定下一运行进程呢？<br/>
  在以上提到的各个位置都可以添加代码实现我们的算法，但是考虑到 schedule() 函数是被频繁调用的一个函数 ，它的运行效率直接影响到了系统的吞吐量，因此我们所添加的代码段应该是被调用的频率越小越好。<br/>
  在这种原则的指导之下，我们发现有一段代码只有在 CPU 的时间段（ epoch ）全部耗尽的时候才去调用，而在此时刻可以根据一些信息调度进程，达到给每个用户平均分配 CPU 时间的效果。在 schedule() 函数选择了一个进程之后，它将判断是否需要重新计算进程的 counter 值，这个过程只有在运行队列中所有进程的都用完了时间片时才被调用。在这段代码中加入我们的算法是最合适不过的了。</p>

<p>　原文为：<a href="http://www.cublog.cn/u2/69737/showart_1070708.html">http://www.cublog.cn/u2/69737/showart_1070708.html</a></p>
]]></content>
  </entry>
  
</feed>
