<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: kernel~net | kk Blog —— 通用基础]]></title>
  <link href="http://abcdxyzk.github.io/blog/cats/kernel~net/atom.xml" rel="self"/>
  <link href="http://abcdxyzk.github.io/"/>
  <updated>2015-05-11T18:16:33+08:00</updated>
  <id>http://abcdxyzk.github.io/</id>
  <author>
    <name><![CDATA[kk]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[tcp三个接收队列]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/05/11/kernel-net-tcp_queue/"/>
    <updated>2015-05-11T15:46:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/05/11/kernel-net-tcp_queue</id>
    <content type="html"><![CDATA[<p><a href="http://www.cnblogs.com/alreadyskb/p/4386565.html">http://www.cnblogs.com/alreadyskb/p/4386565.html</a></p>

<h4>三个接收队列</h4>

<ul>
<li>tcp协议栈数据接收实现了三个接收缓存分别是prequeue、sk_write_queue、sk_backlog。</li>
</ul>


<p>之所以需要三个接收缓存的原因如下：<br/>
tcp协议栈接收到数据包时struct sock *sk 可能被进程下上文或者中断上下文占用：</p>

<p>  1、如果处于进程上下文sk_lock.owned=1，软中断因为sk_lock.owned=1，所以数据只能暂存在后备队列中（backlog），当进程上下文逻辑处理完成后会回调tcp_v4_do_rcv处理backlog队列作为补偿，具体看tcp_sendmsg 函数 release_sock的实现。</p>

<p>  2、如果当前处于中断上下文，sk_lock.owned=0，那么数据可能被放置到receive_queue或者prequeue，数据优先放置到prequeue中，如果prequeue满了则会放置到receive_queue中，理论上这里有一个队列就行了，但是TCP协议栈为什么要设计两个呢？其实是为了快点结束软中断数据处理流程，软中断处理函数中禁止了进程抢占和其他软中断发生，效率应该是很低下的，如果数据被放置到prequeue中，那么软中断流程很快就结束了，如果放置到receive_queue那么会有很复杂的逻辑需要处理。receive_queue队列的处理在软中断中，prequeue队列的处理则是在进程上下文中。总的来说就是为了提高TCP协议栈的效率。</p>

<h4>后备队列的处理逻辑</h4>

<h5>1、什么时候使用后备队列</h5>

<p>tcp协议栈对struct sock <em>sk有两把锁，第一把是sk_lock.slock，第二把则是sk_lock.owned。sk_lock.slock用于获取struct sock </em>sk对象的成员的修改权限；sk_lock.owned用于区分当前是进程上下文或是软中断上下文，为进程上下文时sk_lock.owned会被置1，中断上下文为0。</p>

<p>如果是要对sk修改，首先是必须拿锁sk_lock.slock，其后是判断当前是软中断或是进程上下文，如果是进程上下文，那么接收到的skb则只能先放置到后备队列中sk_backlog中。如果是软中断上下文则可以放置到prequeue和sk_write_queue中。</p>

<p>代码片段如下：
<code>
        bh_lock_sock_nested(sk);               // 获取第一把锁。
        ret = 0;
        if (!sock_owned_by_user(sk)) {         // 判断第二把锁，区分是处于进程上下文还是软中断上下文。
    #ifdef CONFIG_NET_DMA
            struct tcp_sock *tp = tcp_sk(sk);
            if (!tp-&gt;ucopy.dma_chan &amp;&amp; tp-&gt;ucopy.pinned_list)
                tp-&gt;ucopy.dma_chan = dma_find_channel(DMA_MEMCPY);
            if (tp-&gt;ucopy.dma_chan)
                ret = tcp_v4_do_rcv(sk, skb);
            else
    #endif
            {
                if (!tcp_prequeue(sk, skb))    // 如果处于中断上下文，则优先放置到prequeue中，如果prequeue满则放置到sk_write_queue中。
                    ret = tcp_v4_do_rcv(sk, skb);
            }
        } else if (unlikely(sk_add_backlog(sk, skb,  // 如果是处于进程上下文则直接放置到后备队列中(sk_backlog中)。
                            sk-&gt;sk_rcvbuf + sk-&gt;sk_sndbuf))) {
            bh_unlock_sock(sk);
            NET_INC_STATS_BH(net, LINUX_MIB_TCPBACKLOGDROP);
            goto discard_and_relse;
        }
        bh_unlock_sock(sk);
</code></p>

<h5>2、skb怎么add到sk_backlog中</h5>

<p>sk_add_backlog函数用于add sbk到sk_backlog中，所以下面我们分析次函数。
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
<span class='line-number'>217</span>
<span class='line-number'>218</span>
<span class='line-number'>219</span>
<span class='line-number'>220</span>
<span class='line-number'>221</span>
<span class='line-number'>222</span>
<span class='line-number'>223</span>
<span class='line-number'>224</span>
<span class='line-number'>225</span>
<span class='line-number'>226</span>
<span class='line-number'>227</span>
<span class='line-number'>228</span>
<span class='line-number'>229</span>
<span class='line-number'>230</span>
<span class='line-number'>231</span>
<span class='line-number'>232</span>
<span class='line-number'>233</span>
<span class='line-number'>234</span>
<span class='line-number'>235</span>
<span class='line-number'>236</span>
<span class='line-number'>237</span>
<span class='line-number'>238</span>
<span class='line-number'>239</span>
<span class='line-number'>240</span>
<span class='line-number'>241</span>
<span class='line-number'>242</span>
<span class='line-number'>243</span>
<span class='line-number'>244</span>
<span class='line-number'>245</span>
<span class='line-number'>246</span>
<span class='line-number'>247</span>
<span class='line-number'>248</span>
<span class='line-number'>249</span>
<span class='line-number'>250</span>
<span class='line-number'>251</span>
<span class='line-number'>252</span>
<span class='line-number'>253</span>
<span class='line-number'>254</span>
<span class='line-number'>255</span>
<span class='line-number'>256</span>
<span class='line-number'>257</span>
<span class='line-number'>258</span>
<span class='line-number'>259</span>
<span class='line-number'>260</span>
<span class='line-number'>261</span>
<span class='line-number'>262</span>
<span class='line-number'>263</span>
<span class='line-number'>264</span>
<span class='line-number'>265</span>
<span class='line-number'>266</span>
<span class='line-number'>267</span>
<span class='line-number'>268</span>
<span class='line-number'>269</span>
<span class='line-number'>270</span>
<span class='line-number'>271</span>
<span class='line-number'>272</span>
<span class='line-number'>273</span>
<span class='line-number'>274</span>
<span class='line-number'>275</span>
<span class='line-number'>276</span>
<span class='line-number'>277</span>
<span class='line-number'>278</span>
<span class='line-number'>279</span>
<span class='line-number'>280</span>
<span class='line-number'>281</span>
<span class='line-number'>282</span>
<span class='line-number'>283</span>
<span class='line-number'>284</span>
<span class='line-number'>285</span>
<span class='line-number'>286</span>
<span class='line-number'>287</span>
<span class='line-number'>288</span>
<span class='line-number'>289</span>
<span class='line-number'>290</span>
<span class='line-number'>291</span>
<span class='line-number'>292</span>
<span class='line-number'>293</span>
<span class='line-number'>294</span>
<span class='line-number'>295</span>
<span class='line-number'>296</span>
<span class='line-number'>297</span>
<span class='line-number'>298</span>
<span class='line-number'>299</span>
<span class='line-number'>300</span>
<span class='line-number'>301</span>
<span class='line-number'>302</span>
<span class='line-number'>303</span>
<span class='line-number'>304</span>
<span class='line-number'>305</span>
<span class='line-number'>306</span>
<span class='line-number'>307</span>
<span class='line-number'>308</span>
<span class='line-number'>309</span>
<span class='line-number'>310</span>
<span class='line-number'>311</span>
<span class='line-number'>312</span>
<span class='line-number'>313</span>
<span class='line-number'>314</span>
<span class='line-number'>315</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>/&lt;em&gt; The per-socket spinlock must be held here. &lt;/em&gt;/
</span><span class='line'>static inline __must_check int sk_add_backlog(struct sock &lt;em&gt;sk, struct sk_buff &lt;/em&gt;skb,
</span><span class='line'>                           unsigned int limit)
</span><span class='line'>{
</span><span class='line'>    if (sk_rcvqueues_full(sk, skb, limit))  // 判断接收缓存是否已经用完了，很明显sk_backlog的缓存大小也算在了总接收缓存中。
</span><span class='line'>        return -ENOBUFS;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    __sk_add_backlog(sk, skb);              // 将skb添加到sk_backlog队列中。
</span><span class='line'>sk_extended(sk)-&gt;sk_backlog.len += skb-&gt;truesize;  // 更新sk_backlog中已经挂载的数据量。
</span><span class='line'>return 0;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;/* OOB backlog add */
</span><span class='line'>static inline void __sk_add_backlog(struct sock *sk, struct sk_buff *skb)
</span><span class='line'>{
</span><span class='line'>if (!sk-&gt;sk_backlog.tail) {   // 如果当前sk_backlog为NULL，此时head和tail都指向skb。
</span><span class='line'>    sk-&gt;sk_backlog.head = sk-&gt;sk_backlog.tail = skb;
</span><span class='line'>} else {                      // 分支表示sk_backlog中已经有数据了，那么skb直接挂在tail的尾部，之后tail指针后移到skb。
</span><span class='line'>    sk-&gt;sk_backlog.tail-&gt;next = skb;
</span><span class='line'>    sk-&gt;sk_backlog.tail = skb;
</span><span class='line'>}
</span><span class='line'>skb-&gt;next = NULL;             // 这种很重要，在sk_backlog处理时会用来判断skb是否处理完毕。
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>##### 3、sk_backlog中skb的处理
</span><span class='line'>
</span><span class='line'>很明显sk_backlog的处理必然中进程上下文进行，对于数据接收，进程上下文的接口是tcp_recvmmsg，所以sk_backlog肯定要在tcp_recvmmsg中处理。
</span><span class='line'>
</span><span class='line'>tcp_recvmmsg sk_backlog的代码处理片段如下：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;tcp_cleanup_rbuf(sk, copied);
</span><span class='line'>TCP_CHECK_TIMER(sk);
</span><span class='line'>release_sock(sk);
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>release_sock(sk)涉及到sk_backlog处理。
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;void release_sock(struct sock *sk)
</span><span class='line'>{
</span><span class='line'>/*
</span><span class='line'>* The sk_lock has mutex_unlock() semantics:
</span><span class='line'>*/
</span><span class='line'>mutex_release(&amp;sk-&gt;sk_lock.dep_map, 1, _RET_IP_);
</span><span class='line'>
</span><span class='line'>spin_lock_bh(&amp;sk-&gt;sk_lock.slock);   // 获取第一把锁。
</span><span class='line'>if (sk-&gt;sk_backlog.tail)            // 如果后备队列不为NULL，则开始处理。
</span><span class='line'>    __release_sock(sk);
</span><span class='line'>
</span><span class='line'>if (proto_has_rhel_ext(sk-&gt;sk_prot, RHEL_PROTO_HAS_RELEASE_CB) &amp;&amp;
</span><span class='line'>        sk-&gt;sk_prot-&gt;release_cb)
</span><span class='line'>    sk-&gt;sk_prot-&gt;release_cb(sk);
</span><span class='line'>
</span><span class='line'>sk-&gt;sk_lock.owned = 0;              // 进成上下文skb处理完了，释放第二把锁。
</span><span class='line'>if (waitqueue_active(&amp;sk-&gt;sk_lock.wq))
</span><span class='line'>    wake_up(&amp;sk-&gt;sk_lock.wq);
</span><span class='line'>spin_unlock_bh(&amp;sk-&gt;sk_lock.slock); // 释放第一把锁。
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>`__release_sock(sk)`是后备队列的真正处理函数。
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;static void __release_sock(struct sock *sk)
</span><span class='line'>{
</span><span class='line'>struct sk_buff *skb = sk-&gt;sk_backlog.head;
</span><span class='line'>
</span><span class='line'>do {
</span><span class='line'>    sk-&gt;sk_backlog.head = sk-&gt;sk_backlog.tail = NULL;
</span><span class='line'>    bh_unlock_sock(sk);
</span><span class='line'>
</span><span class='line'>    do {
</span><span class='line'>        struct sk_buff *next = skb-&gt;next;
</span><span class='line'>
</span><span class='line'>        skb-&gt;next = NULL;
</span><span class='line'>        sk_backlog_rcv(sk, skb);    // skb的处理函数，其实调用的是tcp_v4_do_rcv函数。
</span><span class='line'>
</span><span class='line'>        /*
</span><span class='line'>         * We are in process context here with softirqs
</span><span class='line'>         * disabled, use cond_resched_softirq() to preempt.
</span><span class='line'>         * This is safe to do because we've taken the backlog
</span><span class='line'>         * queue private:
</span><span class='line'>         */
</span><span class='line'>        cond_resched_softirq();
</span><span class='line'>
</span><span class='line'>        skb = next;
</span><span class='line'>    } while (skb != NULL);          // 如果skb=NULL，那么说明之前的sk_backlog已经处理完了。
</span><span class='line'>
</span><span class='line'>    bh_lock_sock(sk);
</span><span class='line'>} while ((skb = sk-&gt;sk_backlog.head) != NULL); // 在处理上一个sk_backlog时，可能被软中断中断了，建立了新的sk_backlog，新建立的sk_backlog也将一并被处理。
</span><span class='line'>
</span><span class='line'>/*
</span><span class='line'>* Doing the zeroing here guarantee we can not loop forever
</span><span class='line'>* while a wild producer attempts to flood us.
</span><span class='line'>*/
</span><span class='line'>sk_extended(sk)-&gt;sk_backlog.len = 0;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;code&gt;``
</span><span class='line'>  一开始重置sk-&gt;sk_backlog.head ，sk-&gt;sk_backlog.tail为NULL。sk_backlog是一个双链表，head指向了链表头部的skb，而tail则指向了链表尾部的skb。这里之所以置NULL head 和tail，是因为struct sk_buff *skb = sk-&gt;sk_backlog.head 提前取到了head指向的skb，之后就可以通过skb-&gt;next来获取下一个skb处理，结束的条件是skb-&gt;next=NULL，这个是在&lt;/code&gt;__sk_add_backlog`函数中置位的，也就说对于sk_backlog的处理head和tail指针已经没有用了。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  为什么要置NULLsk-&gt;sk_backlog.head ，sk-&gt;sk_backlog.tail呢？第一想法是它可能要被重新使用了。那么在什么情况下会被重新使用呢？试想一下当前是在进程上下文，并且sk-&gt;sk_lock.slock没有被锁住，那是不是可能被软中断打断呢？如果被软中断打断了是不是要接收数据呢，tcp协议栈为了效率考虑肯定是要接收数据的，前面分析道这种情况的数据必须放置到后备队列中(sk_backlog)，所以可以肯定置NULL sk-&gt;sk_backlog.head ，sk-&gt;sk_backlog.tail是为了在处理上一个sk_backlog时，能重用sk_backlog，建立一条新的sk_backlog，或许有人会问为什么不直接添加到原先的sk_backlog tail末尾呢？这个问题我也没有想太清楚，或许是同步不好做吧。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h5&gt;4、skb被处理到哪去了&lt;/h5&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  很明显接收的数据最终都将被传递到应用层，在传递到应用层前必须要保证三个接收队列中的数据有序，那么这三个队列是怎么保证数据字节流有序的被递交给应用层呢？三个队列都会调用tcp_v4_do_rcv函数，prequeue和sk_backlog是在tcp_recvmsg中调用tcp_v4_do_rcv函数，也就是进程上下文中调用tcp_v4_do_rcv函数。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  如果仔细分析tcp_v4_do_rcv函数能发现，这个函数能保证数据有序的排列在一起，所以无论是在处理sk_backlog还是prequeue，最终都会调用tcp_v4_do_rcv函数将数据有效地插入到sk_write_queue中，最后被应用层取走。&lt;/p&gt;
</span><span class='line'>]]&gt;&lt;/content&gt;
</span><span class='line'>  &lt;/entry&gt;
</span><span class='line'>  
</span><span class='line'>  &lt;entry&gt;
</span><span class='line'>&lt;title type="html"&gt;&lt;![CDATA[文件socket]]&gt;&lt;/title&gt;
</span><span class='line'>&lt;link href="http://abcdxyzk.github.io/blog/2015/04/29/kernel-net-socket-file/"/&gt;
</span><span class='line'>&lt;updated&gt;2015-04-29T17:32:00+08:00&lt;/updated&gt;
</span><span class='line'>&lt;id&gt;http://abcdxyzk.github.io/blog/2015/04/29/kernel-net-socket-file&lt;/id&gt;
</span><span class='line'>&lt;content type="html"&gt;&lt;![CDATA[&lt;p&gt;&lt;a href="http://blog.csdn.net/y_23k_bug/article/details/9993555"&gt;http://blog.csdn.net/y_23k_bug/article/details/9993555&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h4&gt;1. 建立socket&lt;/h4&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    #include&lt;sys/socket.h&gt;
</span><span class='line'>
</span><span class='line'>int socket(
</span><span class='line'>    int domain,    //地址族的类型AF_UNIX (绑定在本地) AF_INET（绑定在网卡）
</span><span class='line'>    int type,      //支持的数据格式：流SOCK_STREAM/报文SOCK_DGRAM
</span><span class='line'>    int protocol); //支持的协议,建议为0
</span><span class='line'>
</span><span class='line'>返回值：
</span><span class='line'>    成功返回文件描述符号。
</span><span class='line'>    失败返回-1;
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;h4&gt;2.绑定在地址上(文件目录地址)URL(Universe ResourceLocation)&lt;/h4&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    协议://路径/文件名
</span><span class='line'>file:///usr/bin/ls      普通文件
</span><span class='line'>http://192.168.0.72/index.php
</span><span class='line'>struct sockaddr;  地址结构体
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    #include&lt;linux/un.h&gt;
</span><span class='line'>
</span><span class='line'>struct sockaddr_un;   un=unix（绑定unix本地）
</span><span class='line'>
</span><span class='line'>struct sockaddr_un {
</span><span class='line'>    sa_family_t   sun_family; /*AF_UNIX*/
</span><span class='line'>    char sun_path[UNIX_PATH_MAX];
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    struct sockaddr_in;   in=internet（绑定网卡）
</span><span class='line'>int bind(int fd,           //socket描述符号
</span><span class='line'>    struct sockaddr *addr, //绑定地址
</span><span class='line'>    socklen_tsize);        //地址长度
</span><span class='line'>
</span><span class='line'>返回值：
</span><span class='line'>    0成功
</span><span class='line'>    -1失败
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;h4&gt;样例&lt;/h4&gt;
</span><span class='line'>
</span><span class='line'>&lt;h5&gt;server.c&lt;/h5&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    #include&lt;sys/socket.h&gt;
</span><span class='line'>#include&lt;stdio.h&gt;
</span><span class='line'>#include&lt;stdlib.h&gt;
</span><span class='line'>#include&lt;string.h&gt;
</span><span class='line'>#include&lt;unistd.h&gt;
</span><span class='line'>#include&lt;linux/un.h&gt;
</span><span class='line'>
</span><span class='line'>int main()
</span><span class='line'>{
</span><span class='line'>    int fd; 
</span><span class='line'>    int r;
</span><span class='line'>    char buf[100];
</span><span class='line'>    //1.建立socket
</span><span class='line'>    fd = socket(AF_UNIX, SOCK_DGRAM, 0);  //AF_FILE 等同//AF_UNIX
</span><span class='line'>    if (fd == -1) {
</span><span class='line'>        printf("socket error:%m\n");
</span><span class='line'>        exit(-1);
</span><span class='line'>    }   
</span><span class='line'>
</span><span class='line'>    //2.构造本地文件地址
</span><span class='line'>    struct sockaddr_un addr = {0};
</span><span class='line'>    addr.sun_family = AF_UNIX; //必须跟socket的地址族一致
</span><span class='line'>    memcpy(addr.sun_path, "my.sock", strlen("my.sock"));
</span><span class='line'>
</span><span class='line'>    //3.把socket绑定在地址上
</span><span class='line'>    r = bind(fd, (struct sockaddr *)&amp;addr, sizeof(addr));
</span><span class='line'>    if (r == -1) {
</span><span class='line'>        printf("bind error:%m\n");
</span><span class='line'>        exit(-1);
</span><span class='line'>    }   
</span><span class='line'>
</span><span class='line'>    //4.接收数据
</span><span class='line'>    bzero(buf , sizeof(buf));
</span><span class='line'>    r = read(fd, buf, sizeof(buf));
</span><span class='line'>    buf[r] = 0;
</span><span class='line'>    printf("%s\n", buf);
</span><span class='line'>
</span><span class='line'>    //5.关闭
</span><span class='line'>    close(fd);
</span><span class='line'>
</span><span class='line'>    //6.删除socket文件
</span><span class='line'>    unlink("my.sock");
</span><span class='line'>
</span><span class='line'>    //socket文件不会自动删除，需要在程序结尾去删除该文件，否则，再次运行//A程序出错
</span><span class='line'>    return 0;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;h5&gt;client.c&lt;/h5&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    #include&lt;stdio.h&gt;
</span><span class='line'>#include&lt;stdlib.h&gt;
</span><span class='line'>#include&lt;sys/socket.h&gt;
</span><span class='line'>#include&lt;linux/un.h&gt;
</span><span class='line'>#include&lt;string.h&gt;
</span><span class='line'>#include&lt;unistd.h&gt;
</span><span class='line'>
</span><span class='line'>int main()
</span><span class='line'>{
</span><span class='line'>    int fd; 
</span><span class='line'>    int r;
</span><span class='line'>    struct sockaddr_un addr = {0};
</span><span class='line'>    //1.建立socket
</span><span class='line'>    fd = socket(AF_UNIX, SOCK_DGRAM, 0); 
</span><span class='line'>
</span><span class='line'>    //2.连接到指定的地址
</span><span class='line'>    addr.sun_family = AF_UNIX;
</span><span class='line'>    memcpy(addr.sun_path, "my.sock", strlen("my.sock"));
</span><span class='line'>    r = connect(fd, (struct sockaddr*)&amp;addr, sizeof(addr));
</span><span class='line'>
</span><span class='line'>    //3.发送数据
</span><span class='line'>    write(fd, "hello!", strlen("hello!"));
</span><span class='line'>
</span><span class='line'>    //4.关闭
</span><span class='line'>    close(fd);
</span><span class='line'>    return 0;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>]]&gt;&lt;/content&gt;
</span><span class='line'>  &lt;/entry&gt;
</span><span class='line'>  
</span><span class='line'>  &lt;entry&gt;
</span><span class='line'>&lt;title type="html"&gt;&lt;![CDATA[TCP状态转换]]&gt;&lt;/title&gt;
</span><span class='line'>&lt;link href="http://abcdxyzk.github.io/blog/2015/04/18/kernel-net-tcp-state/"/&gt;
</span><span class='line'>&lt;updated&gt;2015-04-18T16:13:00+08:00&lt;/updated&gt;
</span><span class='line'>&lt;id&gt;http://abcdxyzk.github.io/blog/2015/04/18/kernel-net-tcp-state&lt;/id&gt;
</span><span class='line'>&lt;content type="html"&gt;&lt;![CDATA[&lt;p&gt;&lt;img src="/images/kernel/2015-04-18-1.png" alt="" /&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h5&gt;1、建立连接协议（三次握手）&lt;/h5&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;(1) 客户端发送一个带SYN标志的TCP报文到服务器。这是三次握手过程中的报文1。&lt;br/&gt;
</span><span class='line'>(2) 服务器端回应客户端的，这是三次握手中的第2个报文，这个报文同时带ACK标志和SYN标志。因此它表示对刚才客户端SYN报文的回应；同时又标志SYN给客户端，询问客户端是否准备好进行数据通讯。&lt;br/&gt;
</span><span class='line'>(3) 客户必须再次回应服务段一个ACK报文，这是报文段3。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h5&gt;2、连接终止协议（四次握手）&lt;/h5&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。&lt;br/&gt;
</span><span class='line'>(1) TCP客户端发送一个FIN，用来关闭客户到服务器的数据传送（报文段4）。&lt;br/&gt;
</span><span class='line'>(2) 服务器收到这个FIN，它发回一个ACK，确认序号为收到的序号加1（报文段5）。和SYN一样，一个FIN将占用一个序号。&lt;br/&gt;
</span><span class='line'>(3) 服务器关闭客户端的连接，发送一个FIN给客户端（报文段6）。&lt;br/&gt;
</span><span class='line'>(4) 客户段发回ACK报文确认，并将确认序号设置为收到序号加1（报文段7）。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h4&gt;tcp状态解释&lt;/h4&gt;
</span><span class='line'>
</span><span class='line'>&lt;ol&gt;
</span><span class='line'>&lt;li&gt;CLOSED: 表示初始状态。&lt;/li&gt;
</span><span class='line'>&lt;li&gt;LISTEN: 表示服务器端的某个SOCKET处于监听状态，可以接受连接了.&lt;/li&gt;
</span><span class='line'>&lt;li&gt;SYN_SENT: 客户端通过应用程序调用connect进行active open.于是客户端tcp发送一个SYN以请求建立一个连接.之后状态置为SYN_SENT.&lt;/li&gt;
</span><span class='line'>&lt;li&gt;SYN_RECV: 服务端应发出ACK确认客户端的SYN,同时自己向客户端发送一个SYN.之后状态置为SYN_RECV.&lt;/li&gt;
</span><span class='line'>&lt;li&gt;ESTABLISHED：代表一个打开的连接，双方可以进行或已经在数据交互了.&lt;/li&gt;
</span><span class='line'>&lt;li&gt;FIN_WAIT_1: 主动关闭(active close)端应用程序调用close，于是其TCP发出FIN请求主动关闭连接，之后进入FIN_WAIT1状态.&lt;/li&gt;
</span><span class='line'>&lt;li&gt;FIN_WAIT2: 主动关闭端接到ACK后，就进入了FIN-WAIT-2 . 其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。而这两种状态的区别 是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即 进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态.&lt;/li&gt;
</span><span class='line'>&lt;li&gt;CLOSE_WAIT: CLOSE_WAIT:被动关闭(passive close)端TCP接到FIN后，就发出ACK以回应FIN请求(它的接收也作为文件结束符传递给上层应用程序),并进入CLOSE_WAIT。接下来还有数据发送给对方，如果没有的话，那么你也就可以 close这个SOCKET，发送FIN报文给对方，也即关闭连接。所以你在CLOSE_WAIT状态下，需要完成的事情是等待你去关闭连接.&lt;/li&gt;
</span><span class='line'>&lt;li&gt;LAST_ACK: 被动关闭端一段时间后，接收到文件结束符的应用程序将调用CLOSE关闭连接。这导致它的TCP也发送一个 FIN,等待对方的ACK.就进入了LAST-ACK.&lt;/li&gt;
</span><span class='line'>&lt;li&gt;TIME_WAIT: 在主动关闭端接收到FIN后，TCP就发送ACK包，并进入TIME-WAIT状态.&lt;/li&gt;
</span><span class='line'>&lt;li&gt;CLOSING: 正常情况下，当你发送FIN报文后，按理来说是应该先收到（或同时收到）对方的 ACK报文，再收到对方的FIN报文。但是CLOSING状态表示你发送FIN报文后，没有收到对方的ACK报文，反而收到了对方的FIN报文。表示双方都正在关闭SOCKET连接.&lt;/li&gt;
</span><span class='line'>&lt;li&gt;CLOSED: 被动关闭端在接受到ACK包后，就进入了closed的状态。连接结束.&lt;/li&gt;
</span><span class='line'>&lt;/ol&gt;
</span><span class='line'>
</span><span class='line'>]]&gt;&lt;/content&gt;
</span><span class='line'>  &lt;/entry&gt;
</span><span class='line'>  
</span><span class='line'>  &lt;entry&gt;
</span><span class='line'>&lt;title type="html"&gt;&lt;![CDATA[linux kernel 网络协议栈之GRO(Generic receive offload)]]&gt;&lt;/title&gt;
</span><span class='line'>&lt;link href="http://abcdxyzk.github.io/blog/2015/04/18/kernel-net-gro/"/&gt;
</span><span class='line'>&lt;updated&gt;2015-04-18T15:48:00+08:00&lt;/updated&gt;
</span><span class='line'>&lt;id&gt;http://abcdxyzk.github.io/blog/2015/04/18/kernel-net-gro&lt;/id&gt;
</span><span class='line'>&lt;content type="html"&gt;&lt;![CDATA[&lt;hr /&gt;
</span><span class='line'>
</span><span class='line'>&lt;h2&gt;Attention: gro会合并多个gso_size不同的包, 会将gso_size设置成第一个包的gso_size.&lt;/h2&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a href="http://www.pagefault.info/?p=159"&gt;http://www.pagefault.info/?p=159&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;GRO(Generic receive offload)在内核2.6.29之后合并进去的，作者是一个华裔Herbert Xu ,GRO的简介可以看这里：&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a href="http://lwn.net/Articles/358910/"&gt;http://lwn.net/Articles/358910/&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;先来描述一下GRO的作用，GRO是针对网络接受包的处理的，并且只是针对NAPI类型的驱动，因此如果要支持GRO，不仅要内核支持，而且驱动也必须调用相应的借口，用ethtool -K gro on来设置，如果报错就说明网卡驱动本身就不支持GRO。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;GRO类似tso，可是tso只支持发送数据包，这样你tcp层大的段会在网卡被切包，然后再传递给对端，而如果没有gro，则小的段会被一个个送到协议栈，有了gro之后，就会在接收端做一个反向的操作(想对于tso).也就是将tso切好的数据包组合成大包再传递给协议栈。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;如果实现了GRO支持的驱动是这样子处理数据的，在NAPI的回调poll方法中读取数据包，然后调用GRO的接口napi_gro_receive或者napi_gro_frags来将数据包feed进协议栈。而具体GRO的工作就是在这两个函数中进行的，他们最终都会调用&lt;code&gt;__napi_gro_receive&lt;/code&gt;。下面就是napi_gro_receive，它最终会调用napi_skb_finish以及&lt;code&gt;__napi_gro_receive&lt;/code&gt;。</span></code></pre></td></tr></table></div></figure>
    gro_result_t napi_gro_receive(struct napi_struct <em>napi, struct sk_buff </em>skb)
    {
        skb_gro_reset_offset(skb);</p>

<pre><code>    return napi_skb_finish(__napi_gro_receive(napi, skb), skb);
}
</code></pre>

<pre><code>然后GRO什么时候会将数据feed进协议栈呢，这里会有两个退出点，一个是在napi_skb_finish里，他会通过判断`__napi_gro_receive`的返回值，来决定是需要将数据包立即feed进协议栈还是保存起来，还有一个点是当napi的循环执行完毕时，也就是执行napi_complete的时候，先来看napi_skb_finish,napi_complete我们后面会详细介绍。

在NAPI驱动中，直接调用netif_receive_skb会将数据feed 进协议栈，因此这里如果返回值是NORMAL，则直接调用netif_receive_skb来将数据送进协议栈。
</code></pre>

<pre><code>gro_result_t napi_skb_finish(gro_result_t ret, struct sk_buff *skb)
{
    switch (ret) {
    case GRO_NORMAL:
        //将数据包送进协议栈
        if (netif_receive_skb(skb))
            ret = GRO_DROP;
        break;
    //表示skb可以被free，因为gro已经将skb合并并保存起来。
    case GRO_DROP:
    case GRO_MERGED_FREE:
        //free skb
        kfree_skb(skb);
        break;
    //这个表示当前数据已经被gro保存起来，但是并没有进行合并，因此skb还需要保存。
    case GRO_HELD:
    case GRO_MERGED:
        break;
    }

    return ret;
}
</code></pre>

<pre><code>GRO的主要思想就是，组合一些类似的数据包(基于一些数据域，后面会介绍到)为一个大的数据包(一个skb)，然后feed给协议栈，这里主要是利用Scatter-gather IO，也就是skb的struct skb_shared_info域(我前面的blog讲述ip分片的时候有详细介绍这个域)来合并数据包。

在每个NAPI的实例都会包括一个域叫gro_list,保存了我们积攒的数据包(将要被merge的).然后每次进来的skb都会在这个链表里面进行查找，看是否需要merge。而gro_count表示当前的gro_list中的skb的个数。
</code></pre>

<pre><code>struct napi_struct {
................................................
    //个数
    unsigned int        gro_count;
......................................
    //积攒的数据包
    struct sk_buff      *gro_list;
    struct sk_buff      *skb;
};
</code></pre>

<pre><code>紧接着是gro最核心的一个数据结构napi_gro_cb,它是保存在skb的cb域中，它保存了gro要使用到的一些上下文，这里每个域kernel的注释都比较清楚。到后面我们会看到这些域的具体用途。
</code></pre>

<pre><code>struct napi_gro_cb {
    /* Virtual address of skb_shinfo(skb)-&gt;frags[0].page + offset. */
    void *frag0;

    /* Length of frag0. */
    unsigned int frag0_len;

    /* This indicates where we are processing relative to skb-&gt;data. */
    int data_offset;

    /* This is non-zero if the packet may be of the same flow. */
    int same_flow;

    /* This is non-zero if the packet cannot be merged with the new skb. */
    int flush;

    /* Number of segments aggregated. */
    int count;

    /* Free the skb? */
    int free;
};
</code></pre>

<pre><code>每一层协议都实现了自己的gro回调函数，gro_receive和gro_complete，gro系统会根据协议来调用对应回调函数，其中gro_receive是将输入skb尽量合并到我们gro_list中。而gro_complete则是当我们需要提交gro合并的数据包到协议栈时被调用的。

下面就是ip层和tcp层对应的回调方法：
</code></pre>

<pre><code>static const struct net_protocol tcp_protocol = {
    .handler =  tcp_v4_rcv,
    .err_handler =  tcp_v4_err,
    .gso_send_check = tcp_v4_gso_send_check,
    .gso_segment =  tcp_tso_segment,
    //gso回调
    .gro_receive =  tcp4_gro_receive,
    .gro_complete = tcp4_gro_complete,
    .no_policy =    1,
    .netns_ok = 1,
};

static struct packet_type ip_packet_type __read_mostly = {
    .type = cpu_to_be16(ETH_P_IP),
    .func = ip_rcv,
    .gso_send_check = inet_gso_send_check,
    .gso_segment = inet_gso_segment,
    //gso回调
    .gro_receive = inet_gro_receive,
    .gro_complete = inet_gro_complete,
};
</code></pre>

<pre><code>gro的入口函数是napi_gro_receive，它的实现很简单，就是将skb包含的gro上下文reset，然后调用`__napi_gro_receive`,最终通过napi_skb_finis来判断是否需要讲数据包feed进协议栈。
</code></pre>

<pre><code>gro_result_t napi_gro_receive(struct napi_struct *napi, struct sk_buff *skb)
{
    //reset gro对应的域
    skb_gro_reset_offset(skb);

    return napi_skb_finish(__napi_gro_receive(napi, skb), skb);
}
</code></pre>

<pre><code>napi_skb_finish一开始已经介绍过了，这个函数主要是通过判断传递进来的ret(`__napi_gro_receive`的返回值),来决定是否需要feed数据进协议栈。它的第二个参数是前面处理过的skb。

这里再来看下skb_gro_reset_offset，首先要知道一种情况，那就是skb本身不包含数据(包括头也没有),而所有的数据都保存在skb_shared_info中(支持S/G的网卡有可能会这么做).此时我们如果想要合并的话，就需要将包头这些信息取出来，也就是从skb_shared_info的frags[0]中去的，在 skb_gro_reset_offset中就有做这个事情,而这里就会把头的信息保存到napi_gro_cb 的frags0中。并且此时frags必然不会在high mem,要么是线性区，要么是dma(S/G io)。 来看skb_gro_reset_offset。
</code></pre>

<pre><code>void skb_gro_reset_offset(struct sk_buff *skb)
{
    NAPI_GRO_CB(skb)-&gt;data_offset = 0;
    NAPI_GRO_CB(skb)-&gt;frag0 = NULL;
    NAPI_GRO_CB(skb)-&gt;frag0_len = 0;
    //如果mac_header和skb-&gt;tail相等并且地址不在高端内存，则说明包头保存在skb_shinfo中，所以我们需要从frags中取得对应的数据包
    if (skb-&gt;mac_header == skb-&gt;tail &amp;&amp;
        !PageHighMem(skb_shinfo(skb)-&gt;frags[0].page)) {
        // 可以看到frag0保存的就是对应的skb的frags的第一个元素的地址
        // frag0的作用是: 有些包的包头会存在skb-&gt;frag[0]里面，gro合并时会调用skb_gro_header_slow将包头拉到线性空间中，那么在非线性skb-&gt;frag[0]中的包头部分就应该删掉。
            NAPI_GRO_CB(skb)-&gt;frag0 =
                page_address(skb_shinfo(skb)-&gt;frags[0].page) +
                skb_shinfo(skb)-&gt;frags[0].page_offset;
        //然后保存对应的大小。
        NAPI_GRO_CB(skb)-&gt;frag0_len = skb_shinfo(skb)-&gt;frags[0].size;
    }
}
</code></pre>

<pre><code>接下来就是`__napi_gro_receive`，它主要是遍历gro_list,然后给same_flow赋值，这里要注意，same_flow是一个标记，表示某个skb是否有可能会和当前要处理的skb是相同的流,而这里的相同会在每层都进行判断，也就是在设备层，ip层，tcp层都会判断，这里就是设备层的判断了。这里的判断很简单，有2个条件：  
1 设备是否相同  
2 mac的头必须相等  

如果上面两个条件都满足，则说明两个skb有可能是相同的flow，所以设置same_flow,以便与我们后面合并。
</code></pre>

<pre><code>static gro_result_t
__napi_gro_receive(struct napi_struct *napi, struct sk_buff *skb)
{
    struct sk_buff *p;

    if (netpoll_rx_on(skb))
        return GRO_NORMAL;
    //遍历gro_list,然后判断是否有可能两个skb 相似。
    for (p = napi-&gt;gro_list; p; p = p-&gt;next) {
        //给same_flow赋值
        NAPI_GRO_CB(p)-&gt;same_flow =
            (p-&gt;dev == skb-&gt;dev) &amp;&amp;
            !compare_ether_header(skb_mac_header(p),
                skb_gro_mac_header(skb));
        NAPI_GRO_CB(p)-&gt;flush = 0;
    }
    //调用dev_gro_receiv
    return dev_gro_receive(napi, skb);
}
</code></pre>

<pre><code>接下来来看dev_gro_receive，这个函数我们分做两部分来看，第一部分是正常处理部分，第二部份是处理frag0的部分。

来看如何判断是否支持GRO，这里每个设备的features会在驱动初始化的时候被初始化，然后如果支持GRO，则会包括NETIF_F_GRO。 还有要注意的就是，gro不支持切片的ip包，因为ip切片的组包在内核的ip会做一遍，因此这里gro如果合并的话，没有多大意义，而且还增加复杂度。

在dev_gro_receive中会遍历对应的ptype(也就是协议的类链表，以前的blog有详细介绍),然后调用对应的回调函数，一般来说这里会调用文章开始说的ip_packet_type，也就是 inet_gro_receive。

而 inet_gro_receive的返回值表示我们需要立刻feed 进协议栈的数据包，如果为空，则说明不需要feed数据包进协议栈。后面会分析到这里他的详细算法。

而如果当inet_gro_receive正确返回后，如果same_flow没有被设置，则说明gro list中不存在能和当前的skb合并的项，因此此时需要将skb插入到gro list中。这个时候的返回值就是HELD。
</code></pre>

<pre><code>enum gro_result dev_gro_receive(struct napi_struct *napi, struct sk_buff *skb)
{
    struct sk_buff **pp = NULL;
    struct packet_type *ptype;
    __be16 type = skb-&gt;protocol;
    struct list_head *head = &amp;ptype_base[ntohs(type) &amp; PTYPE_HASH_MASK];
    int same_flow;
    int mac_len;
    enum gro_result ret;
    //判断是否支持gro
    if (!(skb-&gt;dev-&gt;features &amp; NETIF_F_GRO))
        goto normal;
    //判断是否为切片的ip包
    if (skb_is_gso(skb) || skb_has_frags(skb))
        goto normal;

    rcu_read_lock();
    //开始遍历对应的协议表
    list_for_each_entry_rcu(ptype, head, list) {
        if (ptype-&gt;type != type || ptype-&gt;dev || !ptype-&gt;gro_receive)
            continue;

        skb_set_network_header(skb, skb_gro_offset(skb));
        mac_len = skb-&gt;network_header - skb-&gt;mac_header;
        skb-&gt;mac_len = mac_len;
        NAPI_GRO_CB(skb)-&gt;same_flow = 0;
        NAPI_GRO_CB(skb)-&gt;flush = 0;
        NAPI_GRO_CB(skb)-&gt;free = 0;
        //调用对应的gro接收函数
        pp = ptype-&gt;gro_receive(&amp;napi-&gt;gro_list, skb);
        break;
    }
    rcu_read_unlock();
    //如果是没有实现gro的协议则也直接调到normal处理
    if (&amp;ptype-&gt;list == head)
        goto normal;

    //到达这里，则说明gro_receive已经调用过了，因此进行后续的处理

    //得到same_flow
    same_flow = NAPI_GRO_CB(skb)-&gt;same_flow;
    //看是否有需要free对应的skb
    ret = NAPI_GRO_CB(skb)-&gt;free ? GRO_MERGED_FREE : GRO_MERGED;
    //如果返回值pp部位空，则说明pp需要马上被feed进协议栈
    if (pp) {
        struct sk_buff *nskb = *pp;

        *pp = nskb-&gt;next;
        nskb-&gt;next = NULL;
        //调用napi_gro_complete 将pp刷进协议栈
        napi_gro_complete(nskb);
        napi-&gt;gro_count--;
    }
    //如果same_flow有设置，则说明skb已经被正确的合并，因此直接返回。
    if (same_flow)
        goto ok;
    //查看是否有设置flush和gro list的个数是否已经超过限制
    // BUG: 这里是有点不对的，因为这时的skb是比gro_list中的skb更晚到的，但是却被先feed进了协议栈
    if (NAPI_GRO_CB(skb)-&gt;flush || napi-&gt;gro_count &gt;= MAX_GRO_SKBS)
        goto normal;

    //到达这里说明skb对应gro list来说是一个新的skb，也就是说当前的gro list并不存在可以和skb合并的数据包，因此此时将这个skb插入到gro_list的头。
    napi-&gt;gro_count++;
    NAPI_GRO_CB(skb)-&gt;count = 1;
    skb_shinfo(skb)-&gt;gso_size = skb_gro_len(skb);
    //将skb插入到gro list的头
    skb-&gt;next = napi-&gt;gro_list;
    napi-&gt;gro_list = skb;
    //设置返回值
    ret = GRO_HELD;
</code></pre>

<pre><code>然后就是处理frag0的部分，以及不支持gro的处理。
frag0的作用是: 有些包的包头会存在skb-&gt;frag[0]里面，gro合并时会调用skb_gro_header_slow将包头拉到线性空间中，那么在非线性skb-&gt;frag[0]中的包头部分就应该删掉。

这里要需要对skb_shinfo的结构比较了解，我在以前的blog对这个有很详细的介绍，可以去查阅。
</code></pre>

<pre><code>pull:
    //是否需要拷贝头
    if (skb_headlen(skb) &lt; skb_gro_offset(skb)) {
        //得到对应的头的大小
        int grow = skb_gro_offset(skb) - skb_headlen(skb);

        BUG_ON(skb-&gt;end - skb-&gt;tail &lt; grow);
        //开始拷贝
        memcpy(skb_tail_pointer(skb), NAPI_GRO_CB(skb)-&gt;frag0, grow);

        skb-&gt;tail += grow;
        skb-&gt;data_len -= grow;
        //更新对应的frags[0]
        skb_shinfo(skb)-&gt;frags[0].page_offset += grow;
        skb_shinfo(skb)-&gt;frags[0].size -= grow;
        //如果size为0了，则说明第一个页全部包含头，因此需要将后面的页全部移动到前面。
        if (unlikely(!skb_shinfo(skb)-&gt;frags[0].size)) {
            put_page(skb_shinfo(skb)-&gt;frags[0].page);
            //开始移动。
            memmove(skb_shinfo(skb)-&gt;frags,
                skb_shinfo(skb)-&gt;frags + 1,
                --skb_shinfo(skb)-&gt;nr_frags * sizeof(skb_frag_t));
        }
    }

ok:
    return ret;

normal:
    ret = GRO_NORMAL;
    goto pull;
}
</code></pre>

<pre><code>接下来就是inet_gro_receive，这个函数是ip层的gro receive回调函数，函数很简单，首先取得ip头，然后判断是否需要从frag复制数据，如果需要则复制数据
</code></pre>

<pre><code>//得到偏移
off = skb_gro_offset(skb);
//得到头的整个长度(mac+ip)
hlen = off + sizeof(*iph);
//得到ip头
iph = skb_gro_header_fast(skb, off);
//是否需要复制
if (skb_gro_header_hard(skb, hlen)) {
    iph = skb_gro_header_slow(skb, hlen, off);
    if (unlikely(!iph))
        goto out;
}
</code></pre>

<pre><code>然后就是一些校验工作，比如协议是否支持gro_reveive,ip头是否合法等等
</code></pre>

<pre><code>proto = iph-&gt;protocol &amp; (MAX_INET_PROTOS - 1);

rcu_read_lock();
ops = rcu_dereference(inet_protos[proto]);
//是否支持gro
if (!ops || !ops-&gt;gro_receive)
    goto out_unlock;
//ip头是否合法, iph-&gt;version = 4, iph-&gt;ipl = 5
if (*(u8 *)iph != 0x45)
    goto out_unlock;
//ip头教研
if (unlikely(ip_fast_csum((u8 *)iph, iph-&gt;ihl)))
    goto out_unlock;
</code></pre>

<pre><code>然后就是核心的处理部分，它会遍历整个gro_list,然后进行same_flow和是否需要flush的判断。

这里ip层设置same_flow是根据下面的规则的:  
1 4层的协议必须相同  
2 tos域必须相同  
3 源，目的地址必须相同  

如果3个条件一个不满足，则会设置same_flow为0。
这里还有一个就是判断是否需要flush 对应的skb到协议栈，这里的判断条件是这样子的。  
1 ip包的ttl不一样  
2 ip包的id顺序不对  
3 如果是切片包  

如果上面两个条件某一个满足，则说明skb需要被flush出gro。

不过这里要注意只有两个数据包是same flow的情况下，才会进行flush判断。原因很简单，都不是有可能进行merge的包，自然没必要进行flush了。
</code></pre>

<pre><code>    //取出id
    id = ntohl(*(__be32 *)&amp;iph-&gt;id);
    //判断是否需要切片
    flush = (u16)((ntohl(*(__be32 *)iph) ^ skb_gro_len(skb)) | (id ^ IP_DF));
    id &gt;&gt;= 16;
    //开始遍历gro list
    for (p = *head; p; p = p-&gt;next) {
        struct iphdr *iph2;
        //如果上一层已经不可能same flow则直接继续下一个
        if (!NAPI_GRO_CB(p)-&gt;same_flow)
            continue;
        //取出ip头
        iph2 = ip_hdr(p);
        //开始same flow的判断
        if ((iph-&gt;protocol ^ iph2-&gt;protocol) |
            (iph-&gt;tos ^ iph2-&gt;tos) |
            ((__force u32)iph-&gt;saddr ^ (__force u32)iph2-&gt;saddr) |
            ((__force u32)iph-&gt;daddr ^ (__force u32)iph2-&gt;daddr)) {
            NAPI_GRO_CB(p)-&gt;same_flow = 0;
            continue;
        }
        //开始flush的判断。这里注意如果不是same_flow的话，就没必要进行flush的判断。
        /* All fields must match except length and checksum. */
        NAPI_GRO_CB(p)-&gt;flush |=
            (iph-&gt;ttl ^ iph2-&gt;ttl) |
            ((u16)(ntohs(iph2-&gt;id) + NAPI_GRO_CB(p)-&gt;count) ^ id);

        NAPI_GRO_CB(p)-&gt;flush |= flush;
    }

    NAPI_GRO_CB(skb)-&gt;flush |= flush;
    //pull ip头进gro，这里更新data_offset
    skb_gro_pull(skb, sizeof(*iph));
    //设置传输层的头的位置
    skb_set_transport_header(skb, skb_gro_offset(skb));
    //调用传输层的reveive方法。
    pp = ops-&gt;gro_receive(head, skb);

out_unlock:
    rcu_read_unlock();

out:
    NAPI_GRO_CB(skb)-&gt;flush |= flush;

}
</code></pre>

<pre><code>
然后就是tcp层的gro方法，它的主要实现函数是tcp_gro_receive，他的流程和inet_gro_receiv类似，就是取得tcp的头，然后对gro list进行遍历，最终会调用合并方法。

首先来看gro list遍历的部分,它对same flow的要求就是source必须相同，如果不同则设置same flow为0.如果相同则跳到found部分，进行合并处理。
</code></pre>

<pre><code>//遍历gro list
for (; (p = *head); head = &amp;p-&gt;next) {
    //如果ip层已经不可能same flow则直接进行下一次匹配
    if (!NAPI_GRO_CB(p)-&gt;same_flow)
        continue;

    th2 = tcp_hdr(p);
    //判断源地址
    if (*(u32 *)&amp;th-&gt;source ^ *(u32 *)&amp;th2-&gt;source) {
        NAPI_GRO_CB(p)-&gt;same_flow = 0;
        continue;
    }

    goto found;
}
</code></pre>

<pre><code>
接下来就是当找到能够合并的skb的时候的处理，这里首先来看flush的设置,这里会有4个条件：  
1 拥塞状态被设置(TCP_FLAG_CWR).  
2 tcp的ack的序列号不匹配 (这是肯定的，因为它只是对tso或者说gso进行反向操作)  
3 skb的flag和从gro list中查找到要合并skb的flag 如果他们中的不同位 不包括TCP_FLAG_CWR | TCP_FLAG_FIN | TCP_FLAG_PSH，这三个任意一个域。  
4 tcp的option域不同  

如果上面4个条件有一个满足，则会设置flush为1，也就是找到的这个skb(gro list中)必须被刷出到协议栈。

这里谈一下flags域的设置问题首先如果当前的skb设置了cwr，也就是发生了拥塞，那么自然前面被缓存的数据包需要马上被刷到协议栈，以便与tcp的拥塞控制马上进行。

而FIN和PSH这两个flag自然不需要一致，因为这两个和其他的不是互斥的。
</code></pre>

<pre><code>found:
    flush = NAPI_GRO_CB(p)-&gt;flush;
    //如果设置拥塞，则肯定需要刷出skb到协议栈
    flush |= (__force int)(flags &amp; TCP_FLAG_CWR);
    //如果相差的域是除了这3个中的，就需要flush出skb
    flush |= (__force int)((flags ^ tcp_flag_word(th2)) &amp;
          ~(TCP_FLAG_CWR | TCP_FLAG_FIN | TCP_FLAG_PSH));
    //ack的序列号必须一致
    flush |= (__force int)(th-&gt;ack_seq ^ th2-&gt;ack_seq);
    //tcp的option头必须一致
    for (i = sizeof(*th); i &lt; thlen; i += 4)
        flush |= *(u32 *)((u8 *)th + i) ^
             *(u32 *)((u8 *)th2 + i);

    mss = skb_shinfo(p)-&gt;gso_size;
    // 0-1 = 0xFFFFFFFF, 所以skb的数据部分长度为0的包是不会被合并的
    flush |= (len - 1) &gt;= mss;
    flush |= (ntohl(th2-&gt;seq) + skb_gro_len(p)) ^ ntohl(th-&gt;seq);
    //如果flush有设置则不会调用 skb_gro_receive，也就是不需要进行合并，否则调用skb_gro_receive进行数据包合并
    if (flush || skb_gro_receive(head, skb)) {
        mss = 1;
        goto out_check_final;
    }

    p = *head;
    th2 = tcp_hdr(p);
    //更新p的头。到达这里说明合并完毕，因此需要更新合并完的新包的头。
    tcp_flag_word(th2) |= flags &amp; (TCP_FLAG_FIN | TCP_FLAG_PSH);
</code></pre>

<pre><code>从上面我们可以看到如果tcp的包被设置了一些特殊的flag比如PSH，SYN这类的就必须马上把数据包刷出到协议栈。

下面就是最终的一些flags判断,比如第一个数据包进来都会到这里来判断。
</code></pre>

<pre><code>out_check_final:
    flush = len &lt; mss;
    //根据flag得到flush
    flush |= (__force int)(flags &amp; (TCP_FLAG_URG | TCP_FLAG_PSH |
                    TCP_FLAG_RST | TCP_FLAG_SYN |
                    TCP_FLAG_FIN));

    if (p &amp;&amp; (!NAPI_GRO_CB(skb)-&gt;same_flow || flush))
        pp = head;

out:
    NAPI_GRO_CB(skb)-&gt;flush |= flush;
</code></pre>

<pre><code>这里要知道每次我们只会刷出gro list中的一个skb节点，这是因为每次进来的数据包我们也只会匹配一个。因此如果遇到需要刷出的数据包，会在dev_gro_receive中先刷出gro list中的，然后再将当前的skb feed进协议栈。

最后就是gro最核心的一个函数skb_gro_receive，它的主要工作就是合并，它有2个参数，第一个是gro list中和当前处理的skb是same flow的skb，第二个就是我们需要合并的skb。

这里要注意就是farg_list,其实gro对待skb_shared_info和ip层切片，组包很类似，就是frags放Scatter-Gather I/O的数据包，frag_list放线性数据。这里gro 也是这样的，如果过来的skb支持Scatter-Gather I/O并且数据是只放在frags中，则会合并frags，如果过来的skb不支持Scatter-Gather I/O(数据头还是保存在skb中)，则合并很简单，就是新建一个skb然后拷贝当前的skb，并将gro list中的skb直接挂载到farg_list。

先来看支持Scatter-Gather I/O的处理部分。
</code></pre>

<pre><code>//一些需要用到的变量
struct sk_buff *p = *head;
struct sk_buff *nskb;
//当前的skb的 share_ino
struct skb_shared_info *skbinfo = skb_shinfo(skb);
//当前的gro list中的要合并的skb的share_info
struct skb_shared_info *pinfo = skb_shinfo(p);
unsigned int headroom;
unsigned int len = skb_gro_len(skb);
unsigned int offset = skb_gro_offset(skb);
unsigned int headlen = skb_headlen(skb);
//如果有frag_list的话，则直接去非Scatter-Gather I/O部分处理，也就是合并到frag_list.
if (pinfo-&gt;frag_list)
    goto merge;
else if (headlen &lt;= offset) {
    //支持Scatter-Gather I/O的处理
    skb_frag_t *frag;
    skb_frag_t *frag2;
    int i = skbinfo-&gt;nr_frags;
    //这里遍历是从后向前。
    int nr_frags = pinfo-&gt;nr_frags + i;

    offset -= headlen;

    if (nr_frags &gt; MAX_SKB_FRAGS)
        return -E2BIG;
    //设置pinfo的frags的大小，可以看到就是加上skb的frags的大小
    pinfo-&gt;nr_frags = nr_frags;
    skbinfo-&gt;nr_frags = 0;

    frag = pinfo-&gt;frags + nr_frags;
    frag2 = skbinfo-&gt;frags + i;
    //遍历赋值，其实就是地址赋值，这里就是将skb的frag加到pinfo的frgas后面。
    do {
        *--frag = *--frag2;
    } while (--i);
    //更改page_offet的值
    frag-&gt;page_offset += offset;
    //修改size大小
    frag-&gt;size -= offset;
    //更新skb的相关值
    skb-&gt;truesize -= skb-&gt;data_len;
    skb-&gt;len -= skb-&gt;data_len;
    skb-&gt;data_len = 0;

    NAPI_GRO_CB(skb)-&gt;free = 1;
    //最终完成
    goto done;
} else if (skb_gro_len(p) != pinfo-&gt;gso_size)
    return -E2BIG;
</code></pre>

<pre><code>这里gro list中的要被合并的skb我们叫做skb_s.

接下来就是不支持支持Scatter-Gather I/O(skb的头放在skb中)的处理。这里处理也比较简单，就是复制一个新的nskb，然后它的头和skb_s一样，然后将skb_s挂载到nskb的frag_list上，并且把新建的nskb挂在到gro list中，代替skb_s的位置，而当前的skb
</code></pre>

<pre><code>    headroom = skb_headroom(p);
    nskb = alloc_skb(headroom + skb_gro_offset(p), GFP_ATOMIC);
    if (unlikely(!nskb))
        return -ENOMEM;
    //复制头
    __copy_skb_header(nskb, p);
    nskb-&gt;mac_len = p-&gt;mac_len;

    skb_reserve(nskb, headroom);
    __skb_put(nskb, skb_gro_offset(p));
    //设置各层的头
    skb_set_mac_header(nskb, skb_mac_header(p) - p-&gt;data);
    skb_set_network_header(nskb, skb_network_offset(p));
    skb_set_transport_header(nskb, skb_transport_offset(p));

    __skb_pull(p, skb_gro_offset(p));
    //复制数据
    memcpy(skb_mac_header(nskb), skb_mac_header(p),
           p-&gt;data - skb_mac_header(p));
    //对应的gro 域的赋值
    *NAPI_GRO_CB(nskb) = *NAPI_GRO_CB(p);
    //可以看到frag_list被赋值
    skb_shinfo(nskb)-&gt;frag_list = p;
    skb_shinfo(nskb)-&gt;gso_size = pinfo-&gt;gso_size;
    pinfo-&gt;gso_size = 0;
    skb_header_release(p);
    nskb-&gt;prev = p;
    //更新新的skb的数据段
    nskb-&gt;data_len += p-&gt;len;
    nskb-&gt;truesize += p-&gt;len;  // 应该改成 nskb-&gt;truesize += p-&gt;truesize; 更准确
    nskb-&gt;len += p-&gt;len;
    //将新的skb插入到gro list中
    *head = nskb;
    nskb-&gt;next = p-&gt;next;
    p-&gt;next = NULL;

    p = nskb;

merge:
    if (offset &gt; headlen) {
        skbinfo-&gt;frags[0].page_offset += offset - headlen;
        skbinfo-&gt;frags[0].size -= offset - headlen;
        offset = headlen;
    }

    __skb_pull(skb, offset);
    //将skb插入新的skb的(或者老的skb，当frag list本身存在)fraglist
    // 这里是用p-&gt;prev来记录了p-&gt;fraglist的最后一个包，所以在gro向协议栈提交时最好加一句skb-&gt;prev = NULL;
    p-&gt;prev-&gt;next = skb;
    p-&gt;prev = skb;
    skb_header_release(skb);
</code></pre>

<p>```</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[TCP校验和的原理和实现]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/04/15/kernel-net-sum/"/>
    <updated>2015-04-15T14:07:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/04/15/kernel-net-sum</id>
    <content type="html"><![CDATA[<p><a href="http://blog.csdn.net/zhangskd/article/details/11770647">http://blog.csdn.net/zhangskd/article/details/11770647</a></p>

<h4>概述</h4>

<p>TCP校验和是一个端到端的校验和，由发送端计算，然后由接收端验证。其目的是为了发现TCP首部和数据在发送端到接收端之间发生的任何改动。如果接收方检测到校验和有差错，则TCP段会被直接丢弃。</p>

<p>TCP校验和覆盖TCP首部和TCP数据，而IP首部中的校验和只覆盖IP的首部，不覆盖IP数据报中的任何数据。</p>

<p>TCP的校验和是必需的，而UDP的校验和是可选的。</p>

<p>TCP和UDP计算校验和时，都要加上一个12字节的伪首部。</p>

<h4>伪首部</h4>

<p><img src="/images/kernel/2015-04-15-1.jpeg" alt="" /></p>

<p>伪首部共有12字节，包含如下信息：源IP地址、目的IP地址、保留字节(置0)、传输层协议号(TCP是6)、TCP报文长度(报头+数据)。</p>

<p>伪首部是为了增加TCP校验和的检错能力：如检查TCP报文是否收错了(目的IP地址)、传输层协议是否选对了(传输层协议号)等。</p>

<h4>定义</h4>

<h5>(1) RFC 793的TCP校验和定义</h5>

<p>The checksum field is the 16 bit one&rsquo;s complement of the one&rsquo;s complement sum of all 16-bit words in the header and text. If a segment contains an odd number of header and text octets to be checksummed, the last octet is padded on the right with zeros to form a 16-bit word for checksum purposes. The pad is not transmitted as part of the segment. While computing the checksum, the checksum field itself is replaced with zeros.</p>

<p>上述的定义说得很明确：<br/>
首先，把伪首部、TCP报头、TCP数据分为16位的字，如果总长度为奇数个字节，则在最后增添一个位都为0的字节。把TCP报头中的校验和字段置为0（否则就陷入鸡生蛋还是蛋生鸡的问题）。</p>

<p>其次，用反码相加法累加所有的16位字（进位也要累加）。</p>

<p>最后，对计算结果取反，作为TCP的校验和。</p>

<h5>(2) RFC 1071的IP校验和定义</h5>

<p>1.Adjacent octets to be checksummed are paired to form 16-bit integers, and the 1&rsquo;s complement sum of these 16-bit integers is formed.</p>

<p>2.To generate a checksum, the checksum field itself is cleared, the 16-bit 1&rsquo;s complement sum is computed over the octets concerned, and the 1&rsquo;s complement of this sum is placed in the checksum field.</p>

<p>3.To check a checksum, the 1&rsquo;s complement sum is computed over the same set of octets, including the checksum field. If the result is all 1 bits (-0 in 1&rsquo;s complement arithmetic), the check succeeds.</p>

<p>可以看到，TCP校验和、IP校验和的计算方法是基本一致的，除了计算的范围不同。</p>

<h4>实现</h4>

<p>基于2.6.18、x86_64。</p>

<p>csum_tcpudp_nofold()按4字节累加伪首部到sum中。
<code>
    static inline unsigned long csum_tcpudp_nofold (unsigned long saddr, unsigned long daddr,  
                                                    unsigned short len, unsigned short proto,  
                                                    unsigned int sum)  
    {  
        asm("addl %1, %0\n"    /* 累加daddr */  
            "adcl %2, %0\n"    /* 累加saddr */  
            "adcl %3, %0\n"    /* 累加len(2字节), proto, 0*/  
            "adcl $0, %0\n"    /*加上进位 */  
            : "=r" (sum)  
            : "g" (daddr), "g" (saddr), "g" ((ntohs(len) &lt;&lt; 16) + proto*256), "0" (sum));  
        return sum;  
    }   
</code></p>

<p>csum_tcpudp_magic()产生最终的校验和。</p>

<p>首先，按4字节累加伪首部到sum中。</p>

<p>其次，累加sum的低16位、sum的高16位，并且对累加的结果取反。</p>

<p>最后，截取sum的高16位，作为校验和。
```
    static inline unsigned short int csum_tcpudp_magic(unsigned long saddr, unsigned long daddr,<br/>
                                                       unsigned short len, unsigned short proto,<br/>
                                                       unsigned int sum)<br/>
    {<br/>
        return csum_fold(csum_tcpudp_nofold(saddr, daddr, len, proto, sum));<br/>
    }</p>

<pre><code>static inline unsigned int csum_fold(unsigned int sum)  
{  
    __asm__(  
        "addl %1, %0\n"  
        "adcl 0xffff, %0"  
        : "=r" (sum)  
        : "r" (sum &lt;&lt; 16), "0" (sum &amp; 0xffff0000)   

        /* 将sum的低16位，作为寄存器1的高16位，寄存器1的低16位补0。 
          * 将sum的高16位，作为寄存器0的高16位，寄存器0的低16位补0。 
          * 这样，addl %1, %0就累加了sum的高16位和低16位。 
          * 
         * 还要考虑进位。如果有进位，adcl 0xfff, %0为：0x1 + 0xffff + %0，寄存器0的高16位加1。 
          * 如果没有进位，adcl 0xffff, %0为：0xffff + %0，对寄存器0的高16位无影响。 
          */  

    );  

    return (~sum) &gt;&gt; 16; /* 对sum取反，返回它的高16位，作为最终的校验和 */  
}  
</code></pre>

<pre><code>
#### 发送校验
</code></pre>

<pre><code>#define CHECKSUM_NONE 0 /* 不使用校验和，UDP可选 */  
#define CHECKSUM_HW 1 /* 由硬件计算报头和首部的校验和 */  
#define CHECKSUM_UNNECESSARY 2 /* 表示不需要校验，或者已经成功校验了 */  
#define CHECKSUM_PARTIAL CHECKSUM_HW  
#define CHECKSUM_COMPLETE CHECKSUM_HW  
</code></pre>

<pre><code>
##### @tcp_transmit_skb()
    icsk-&gt;icsk_af_ops-&gt;send_check(sk, skb-&gt;len, skb); /* 计算校验和 */
</code></pre>

<pre><code>void tcp_v4_send_check(struct sock *sk, int len, struct sk_buff *skb)  
{  
    struct inet_sock *inet = inet_sk(sk);  
    struct tcphdr *th = skb-&gt;h.th;  

    if (skb-&gt;ip_summed == CHECKSUM_HW) {  
        /* 只计算伪首部，TCP报头和TCP数据的累加由硬件完成 */  
        th-&gt;check = ~tcp_v4_check(th, len, inet-&gt;saddr, inet-&gt;daddr, 0);  
        skb-&gt;csum = offsetof(struct tcphdr, check); /* 校验和值在TCP首部的偏移 */  

    } else {  
        /* tcp_v4_check累加伪首部，获取最终的校验和。 
         * csum_partial累加TCP报头。 
         * 那么skb-&gt;csum应该是TCP数据部分的累加，这是在从用户空间复制时顺便累加的。 
         */  
        th-&gt;check = tcp_v4_check(th, len, inet-&gt;saddr, inet-&gt;daddr,  
                                 csum_partial((char *)th, th-&gt;doff &lt;&lt; 2, skb-&gt;csum));  
    }  
}  
</code></pre>

<p><code>
</code>
    unsigned csum_partial(const unsigned char *buff, unsigned len, unsigned sum)<br/>
    {<br/>
        return add32_with_carry(do_csum(buff, len), sum);<br/>
    }</p>

<pre><code>static inline unsigned add32_with_carry(unsigned a, unsigned b)  
{  
    asm("addl %2, %0\n\t"  
             "adcl $0, %0"  
             : "=r" (a)  
             : "0" (a), "r" (b));  
    return a;  
}   
</code></pre>

<pre><code>
do_csum()用于计算一段内存的校验和，这里用于累加TCP报头。

具体计算时用到一些技巧：  
1.反码累加时，按16位、32位、64位来累加的效果是一样的。  
2.使用内存对齐，减少内存操作的次数。
</code></pre>

<pre><code>static __force_inline unsigned do_csum(const unsigned char *buff, unsigned len)  
{  
    unsigned odd, count;  
    unsigned long result = 0;  

    if (unlikely(len == 0))  
        return result;  

    /* 使起始地址为XXX0，接下来可按2字节对齐 */  
    odd = 1 &amp; (unsigned long) buff;  
    if (unlikely(odd)) {  
        result = *buff &lt;&lt; 8; /* 因为机器是小端的 */  
        len--;  
        buff++;  
    }  
    count = len &gt;&gt; 1; /* nr of 16-bit words，这里可能余下1字节未算，最后会处理*/  

    if (count) {  
        /* 使起始地址为XX00，接下来可按4字节对齐 */  
        if (2 &amp; (unsigned long) buff) {  
            result += *(unsigned short *)buff;  
            count--;  
            len -= 2;  
            buff += 2;  
        }  
        count &gt;&gt;= 1; /* nr of 32-bit words，这里可能余下2字节未算，最后会处理 */  

        if (count) {  
            unsigned long zero;  
            unsigned count64;  
            /* 使起始地址为X000，接下来可按8字节对齐 */  
            if (4 &amp; (unsigned long)buff) {  
                result += *(unsigned int *)buff;  
                count--;  
                len -= 4;  
                buff += 4;  
            }  
            count &gt;&gt;= 1; /* nr of 64-bit words，这里可能余下4字节未算，最后会处理*/  

            /* main loop using 64byte blocks */  
            zero = 0;  
            count64 = count &gt;&gt; 3; /* 64字节的块数，这里可能余下56字节未算，最后会处理 */  
            while (count64) { /* 反码累加所有的64字节块 */  
                asm ("addq 0*8(%[src]), %[res]\n\t"    /* b、w、l、q分别对应8、16、32、64位操作 */  
                          "addq 1*8(%[src]), %[res]\n\t"    /* [src]为指定寄存器的别名，效果应该等同于0、1等 */  
                          "adcq 2*8(%[src]), %[res]\n\t"  
                          "adcq 3*8(%[src]), %[res]\n\t"  
                          "adcq 4*8(%[src]), %[res]\n\t"  
                          "adcq 5*8(%[src]), %[res]\n\t"  
                          "adcq 6*8(%[src]), %[res]\n\t"  
                          "adcq 7*8(%[src]), %[res]\n\t"  
                          "adcq %[zero], %[res]"  
                          : [res] "=r" (result)  
                          : [src] "r" (buff), [zero] "r" (zero), "[res]" (result));  
                buff += 64;  
                count64--;  
            }  

            /* 从这里开始，反序处理之前可能漏算的字节 */  

            /* last upto 7 8byte blocks，前面按8个8字节做计算单位，所以最多可能剩下7个8字节 */  
            count %= 8;  
            while (count) {  
                asm ("addq %1, %0\n\t"  
                     "adcq %2, %0\n"  
                     : "=r" (result)  
                     : "m" (*(unsigned long *)buff), "r" (zero), "0" (result));  
                --count;  
                buff += 8;  
            }  

            /* 带进位累加result的高32位和低32位 */  
            result = add32_with_carry(result&gt;&gt;32, result&amp;0xffffffff);  

            /* 之前始按8字节对齐，可能有4字节剩下 */  
            if (len &amp; 4) {  
                result += *(unsigned int *) buff;  
                buff += 4;  
            }  
        }  

       /* 更早前按4字节对齐，可能有2字节剩下 */  
        if (len &amp; 2) {  
            result += *(unsigned short *) buff;  
            buff += 2;  
        }  
    }  

    /* 最早之前按2字节对齐，可能有1字节剩下 */  
    if (len &amp; 1)  
        result += *buff;  

    /* 再次带进位累加result的高32位和低32位 */  
    result = add32_with_carry(result&gt;&gt;32, result &amp; 0xffffffff);   

    /* 这里涉及到一个技巧，用于处理初始地址为奇数的情况 */  
    if (unlikely(odd)) {  
        result = from32to16(result); /* 累加到result的低16位 */  
        /* result为：0 0 a b 
         * 然后交换a和b，result变为：0 0 b a 
         */  
        result = ((result &gt;&gt; 8) &amp; 0xff) | ((result &amp; oxff) &lt;&lt; 8);  
    }  

    return result; /* 返回result的低32位 */  
}  
</code></pre>

<pre><code></code></pre>

<pre><code>static inline unsigned short from32to16(unsigned a)  
{  
    unsigned short b = a &gt;&gt; 16;  
    asm ("addw %w2, %w0\n\t"  
              "adcw $0, %w0\n"  
              : "=r" (b)  
              : "0" (b), "r" (a));  
    return b;  
}  
</code></pre>

<pre><code>
csum_partial_copy_from_user()用于拷贝用户空间数据到内核空间，同时计算用户数据的校验和，结果保存到skb-&gt;csum中（X86_64）。
</code></pre>

<pre><code>/** 
 * csum_partial_copy_from_user - Copy and checksum from user space. 
 * @src: source address (user space) 
 * @dst: destination address 
 * @len: number of bytes to be copied. 
 * @isum: initial sum that is added into the result (32bit unfolded) 
 * @errp: set to -EFAULT for an bad source address. 
 * 
 * Returns an 32bit unfolded checksum of the buffer. 
 * src and dst are best aligned to 64bits. 
 */  

unsigned int csum_partial_copy_from_user(const unsigned char __user *src,  
                                  unsigned char *dst, int len, unsigned int isum, int *errp)  
{  
    might_sleep();  
    *errp = 0;  

    if (likely(access_ok(VERIFY_READ, src, len))) {  

        /* Why 6, not 7? To handle odd addresses aligned we would need to do considerable 
         * complications to fix the checksum which is defined as an 16bit accumulator. The fix 
         * alignment code is primarily for performance compatibility with 32bit and that will handle 
         * odd addresses slowly too. 
         * 处理X010、X100、X110的起始地址。不处理X001，因为这会使复杂度大增加。 
         */  
        if (unlikely((unsigned long)src &amp; 6)) {  
            while (((unsigned long)src &amp; 6) &amp;&amp; len &gt;= 2) {  
                __u16 val16;  
                *errp = __get_user(val16, (__u16 __user *)src);  
                if (*errp)  
                    return isum;  
                *(__u16 *)dst = val16;  
                isum = add32_with_carry(isum, val16);  
                src += 2;  
                dst += 2;  
                len -= 2;  
            }  
        }  

        /* 计算函数是用纯汇编实现的，应该是因为效率吧 */  
        isum = csum_parial_copy_generic((__force void *)src, dst, len, isum, errp, NULL);  

        if (likely(*errp == 0))  
            return isum; /* 成功 */  
    }  

    *errp = -EFAULT;  
    memset(dst, 0, len);  
    return isum;  
}  
</code></pre>

<pre><code>
上述的实现比较复杂，来看下最简单的csum_partial_copy_from_user()实现（um）。
</code></pre>

<pre><code>unsigned int csum_partial_copy_from_user(const unsigned char *src,  
                                         unsigned char *dst, int len, int sum,  
                                         int *err_ptr)  
{  
    if (copy_from_user(dst, src, len)) { /* 拷贝用户空间数据到内核空间 */  
        *err_ptr = -EFAULT; /* bad address */  
        return (-1);  
    }  

    return csum_partial(dst, len, sum); /* 计算用户数据的校验和，会存到skb-&gt;csum中 */  
}  
</code></pre>

<pre><code>
#### 接收校验

##### @tcp_v4_rcv
    /* 检查校验和 */
    if (skb-&gt;ip_summed != CHECKSUM_UNNECESSARY &amp;&amp; tcp_v4_checksum_init(skb))  
        goto bad_packet;   


接收校验的第一部分，主要是计算伪首部。
</code></pre>

<pre><code>static int tcp_v4_checksum_init(struct sk_buff *skb)  
{  
    /* 如果TCP报头、TCP数据的反码累加已经由硬件完成 */  
    if (skb-&gt;ip_summed == CHECKSUM_HW) {  

        /* 现在只需要再累加上伪首部，取反获取最终的校验和。 
         * 校验和为0时，表示TCP数据报正确。 
         */  
        if (! tcp_v4_check(skb-&gt;h.th, skb-&gt;len, skb-&gt;nh.iph-&gt;saddr, skb-&gt;nh.iph-&gt;daddr, skb-&gt;csum)) {  
            skb-&gt;ip_summed = CHECKSUM_UNNECESSARY;  
            return 0; /* 校验成功 */  

        } /* 没有else失败退出吗？*/  
    }  

    /* 对伪首部进行反码累加，主要用于软件方法 */  
    skb-&gt;csum = csum_tcpudp_nofold(skb-&gt;nh.iph-&gt;saddr, skb-&gt;nh.iph-&gt;daddr, skb-&gt;len, IPPROTO_TCP, 0);  


    /* 对于长度小于76字节的小包，接着累加TCP报头和报文，完成校验；否则，以后再完成检验。*/  
    if (skb-&gt;len &lt;= 76) {  
        return __skb_checksum_complete(skb);  
    }  
}  
</code></pre>

<pre><code>
接收校验的第二部分，计算报头和报文。
</code></pre>

<p>tcp_v4_rcv、tcp_v4_do_rcv()</p>

<pre><code>| --&gt; tcp_checksum_complete()

            | --&gt; __tcp_checksum_complete()

                        | --&gt; __skb_checksum_complete()
</code></pre>

<p>tcp_rcv_established()</p>

<pre><code>| --&gt; tcp_checksum_complete_user()

            | --&gt; __tcp_checksum_complete_user()

                        | --&gt; __tcp_checksum_complete()

                                    | --&gt; __skb_checksum_complete()
</code></pre>

<pre><code></code></pre>

<pre><code>unsigned int __skb_checksum_complete(struct sk_buff *skb)  
{  
    unsigned int sum;  

    sum = (u16) csum_fold(skb_checksum(skb, 0, skb-&gt;len, skb-&gt;csum));  

    if (likely(!sum)) { /* sum为0表示成功了 */  
        /* 硬件检测失败，软件检测成功了，说明硬件检测有误 */  
        if (unlikely(skb-&gt;ip_summed == CHECKSUM_HW))  
            netdev_rx_csum_fault(skb-&gt;dev);  
        skb-&gt;ip_summed = CHECKSUM_UNNECESSARY;  
    }  
    return sum;  
}  
</code></pre>

<pre><code>
计算skb包的校验和时，可以指定相对于skb-&gt;data的偏移量offset。由于skb包可能由分页和分段，所以需要考虑skb-&gt;data + offset是位于此skb段的线性区中、还是此skb的分页中，或者位于其它分段中。这个函数逻辑比较复杂。
</code></pre>

<pre><code>/* Checksum skb data. */  
unsigned int skb_checksum(const struct sk_buff *skb, int offset, int len, unsigned int csum)  
{  
    int start = skb_headlen(skb); /* 线性区域长度 */  
    /* copy &gt; 0，说明offset在线性区域中。 
     * copy &lt; 0，说明offset在此skb的分页数据中，或者在其它分段skb中。 
     */  
    int i, copy = start - offset;  
    int pos = 0; /* 表示校验了多少数据 */  

    /* Checksum header. */  
    if (copy &gt; 0) { /* 说明offset在本skb的线性区域中 */  
        if (copy &gt; len)  
            copy = len; /* 不能超过指定的校验长度 */  

        /* 累加copy长度的线性区校验 */  
        csum = csum_partial(skb-&gt;data + offset, copy, csum);  

        if ((len -= copy) == 0)  
            return csum;  

        offset += copy; /* 接下来从这里继续处理 */  
        pos = copy; /* 已处理数据长 */  
    }  

    /* 累加本skb分页数据的校验和 */  
    for (i = 0; i &lt; skb_shinfo(skb)-&gt;nr_frags; i++) {  
        int end;  
        BUG_TRAP(start &lt;= offset + len);  

        end = start + skb_shinfo(skb)-&gt;frags[i].size;  

        if ((copy = end - offset) &gt; 0) { /* 如果offset位于本页中，或者线性区中 */  
            unsigned int csum2;  
            u8 *vaddr; /* 8位够吗？*/  
            skb_frag_t *frag = &amp;skb_shinfo(skb)-&gt;frags[i];  

            if (copy &gt; len)  
                copy = len;  

            vaddr = kmap_skb_frag(frag); /* 把物理页映射到内核空间 */  
            csum2 = csum_partial(vaddr + frag-&gt;page_offset + offset - start, copy, 0);  
            kunmap_skb_frag(vaddr); /* 解除映射 */  

            /* 如果pos为奇数，需要对csum2进行处理。 
             * csum2：a, b, c, d =&gt; b, a, d, c 
             */  
            csum = csum_block_add(csum, csum2, pos);  

            if (! (len -= copy))  
                return csum;  

            offset += copy;  
            pos += copy;  
        }  
        start = end; /* 接下来从这里处理 */  
    }  

    /* 如果此skb是个大包，还有其它分段 */  
    if (skb_shinfo(skb)-&gt;frag_list) {  
        struct sk_buff *list = skb_shinfo(skb)-&gt;frag_list;  

        for (; list; list = list-&gt;next) {  
            int end;  
            BUG_TRAP(start &lt;= offset + len);  

            end = start + list-&gt;len;  

            if ((copy = end - offset) &gt; 0) { /* 如果offset位于此skb分段中，或者分页，或者线性区 */  
                unsigned int csum2;  
                if (copy &gt; len)  
                    copy = len;  

                csum2 = skb_checksum(list, offset - start, copy, 0); /* 递归调用 */  
                csum = csum_block_add(csum, csum2, pos);  
                if ((len -= copy) == 0)  
                    return csum;  

                offset += copy;  
                pos += copy;  
            }  
            start = end;  
        }  
    }  

    BUG_ON(len);  
    return csum;  
}
</code></pre>

<p>```</p>
]]></content>
  </entry>
  
</feed>
