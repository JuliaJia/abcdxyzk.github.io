<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 2015~06 | kk Blog —— 通用基础]]></title>
  <link href="http://abcdxyzk.github.io/blog/cats/2015~06/atom.xml" rel="self"/>
  <link href="http://abcdxyzk.github.io/"/>
  <updated>2015-06-09T18:20:54+08:00</updated>
  <id>http://abcdxyzk.github.io/</id>
  <author>
    <name><![CDATA[kk]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[socket创建过程 sys_socket]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/06/09/kernel-net-socket/"/>
    <updated>2015-06-09T17:45:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/06/09/kernel-net-socket</id>
    <content type="html"><![CDATA[<p><a href="http://m.blog.chinaunix.net/uid-26905027-id-4031796.html">http://m.blog.chinaunix.net/uid-26905027-id-4031796.html</a></p>

<p>对于网络编程程序员来说sockfd = socket(AF_INET, SOCKET_DGRM, 0);这行代码是最熟悉不过，但这行代码的背后是&hellip;&hellip;</p>

<ol>
<li><p>socket这个api是库函数，我们直接调用就可以了，调用之后，产生0x80号软中断，linux系统由用户态切换到内核态，接着执行系统调用函数，在内核态执行相应的服务例程，针对socket这个函数，服务例程是sys_socket函数。至于这个过程是怎么实现的，在这里不阐述。下面我们分析sys_socket函数，看socket是怎么创建的。</p></li>
<li><p>在分析sys_socket函数之前，我们先看一下sock_init初始化过程</p></li>
</ol>


<pre><code>    static int __init sock_init(void)
    {
        /*
         * Initialize sock SLAB cache.
         */

        sk_init(); 

        /*
         * Initialize skbuff SLAB cache
         */
        skb_init();

        /*
         * Initialize the protocols module.
         */

        init_inodecache();   //在这里创建了名为sock_inode_cache的cache
        register_filesystem(&amp;sock_fs_type);
        sock_mnt = kern_mount(&amp;sock_fs_type);

        /* The real protocol initialization is performed in later initcalls.
         */

    #ifdef CONFIG_NETFILTER
        netfilter_init();
    #endif

        return 0;
    }

    struct socket_alloc {
        struct socket socket;
        struct inode vfs_inode;
    };

    static int init_inodecache(void)
    {
        sock_inode_cachep = kmem_cache_create("sock_inode_cache",
                        sizeof(struct socket_alloc),         //在这里创建了名为sock_inode_cache，大小为sizeof(struct socket_alloc)的slab高速缓存  
                                                              //猜测创建slab高速缓存，而不是普通内存，那么操作socket结构就快了
                        0,
                        (SLAB_HWCACHE_ALIGN |
                        SLAB_RECLAIM_ACCOUNT |
                        SLAB_MEM_SPREAD),
                        init_once,
                        NULL);
        if (sock_inode_cachep == NULL)
            return -ENOMEM;
        return 0;
    }

    static struct vfsmount *sock_mnt __read_mostly;

    static struct file_system_type sock_fs_type = {    
        .name =        "sockfs",
        .get_sb =    sockfs_get_sb,
        .kill_sb =    kill_anon_super,
    };

    register_filesystem(&amp;sock_fs_type);   //在这里注册了名为sockfs的VFS
    sock_mnt = kern_mount(&amp;sock_fs_type);  //并在这里得到struct vfsmount 结构的sock_mnt变量，这个变量是全局变量，在创建socket的时候会用到

    static struct super_operations sockfs_ops = {
        .alloc_inode =    sock_alloc_inode,      //这里就是最终创建struct socket_alloc结构的函数
        .destroy_inode =sock_destroy_inode,
        .statfs =    simple_statfs,
    };

    static int sockfs_get_sb(struct file_system_type *fs_type,
            int flags, const char *dev_name, void *data,
            struct vfsmount *mnt)
    {
        return get_sb_pseudo(fs_type, "socket:", &amp;sockfs_ops, SOCKFS_MAGIC,
                                mnt);
    }

    static struct inode *sock_alloc_inode(struct super_block *sb)
    {
        struct socket_alloc *ei;

        ei = kmem_cache_alloc(sock_inode_cachep, GFP_KERNEL);  //在这里我们看到了memory allocate 操作
        if (!ei)
            return NULL;
        init_waitqueue_head(&amp;ei-&gt;socket.wait);

        ei-&gt;socket.fasync_list = NULL;          //在这里对socket结构一些字段进行了初始化
        ei-&gt;socket.state = SS_UNCONNECTED;
        ei-&gt;socket.flags = 0;
        ei-&gt;socket.ops = NULL;
        ei-&gt;socket.sk = NULL;
        ei-&gt;socket.file = NULL;

        return &amp;ei-&gt;vfs_inode;
    }
</code></pre>

<ol>
<li>前面进行的这些初始化，为后面做好了准备，接着往下看吧：</li>
</ol>


<pre><code>    asmlinkage long sys_socket(int family, int type, int protocol)
    {
        int retval;
        struct socket *sock;

        retval = sock_create(family, type, protocol, &amp;sock);  //在这个函数完成了socket的创建过程
        if (retval &lt; 0)
            goto out;

        retval = sock_map_fd(sock);  //把创建的socket和文件相关联，
        if (retval &lt; 0)
            goto out_release;

    out:
        /* It may be already another descriptor 8) Not kernel problem. */
        return retval;

    out_release:
        sock_release(sock);
        return retval;
    }
</code></pre>

<p>sock_create函数是封装函数，实际调用的是__sock_create函数</p>

<pre><code>    static int __sock_create(int family, int type, int protocol,
                struct socket **res, int kern)
    {
        int err;
        struct socket *sock;
        const struct net_proto_family *pf;

        /*
         * Check protocol is in range
         */
        if (family &lt; 0 || family &gt;= NPROTO)
            return -EAFNOSUPPORT;
        if (type &lt; 0 || type &gt;= SOCK_MAX)
            return -EINVAL;

        /* Compatibility.
         * This uglymoron is moved from INET layer to here to avoid
         * deadlock in module load.
         */
        if (family == PF_INET &amp;&amp; type == SOCK_PACKET) {
            static int warned;
            if (!warned) {
                warned = 1;
                printk(KERN_INFO "%s uses obsolete (PF_INET,SOCK_PACKET)\n",
                        current-&gt;comm);
            }
            family = PF_PACKET;
        }

        err = security_socket_create(family, type, protocol, kern);
        if (err)
            return err;

        /*
         *    Allocate the socket and allow the family to set things up. if
         *    the protocol is 0, the family is instructed to select an appropriate
         *    default.
         */
        sock = sock_alloc(); //这个函数调用了初始化时注册的创建socket和inode节点的回调函数，完成了socket和inode节点的创建。在unix和类unix系统中把socket当做文件节点来处理，所以有inode节点
                             //后面我们分析这个函数
        if (!sock) {
            if (net_ratelimit())
                printk(KERN_WARNING "socket: no more sockets\n");
            return -ENFILE;    /* Not exactly a match, but its the
                                closest posix thing */
        }

        sock-&gt;type = type;

    #if defined(CONFIG_KMOD)
        /* Attempt to load a protocol module if the find failed.
         *
         * 12/09/1996 Marcin: this makes REALLY only sense, if the user
         * requested real, full-featured networking support upon configuration.
         * Otherwise module support will
         */
        if (net_families[family] == NULL)
            request_module("net-pf-%d", family);
    #endif

        rcu_read_lock();
        pf = rcu_dereference(net_families[family]);  //根据协议族family得到struct net_proto_family结构，这个net_families数组在inet_init函数中初始化，稍后我们看看这个初始化过程
        err = -EAFNOSUPPORT;
        if (!pf)
            goto out_release;

        /*
         * We will call the -&gt;create function, that possibly is in a loadable
         * module, so we have to bump that loadable module refcnt first.
         */
        if (!try_module_get(pf-&gt;owner))
            goto out_release;

        /* Now protected by module ref count */
        rcu_read_unlock();

        err = pf-&gt;create(sock, protocol); //在这里创建了庞大的struct sock 结构，并进行了初始化。这个挂入的inet_create函数
        if (err &lt; 0)
            goto out_module_put;

        /*
         * Now to bump the refcnt of the [loadable] module that owns this
         * socket at sock_release time we decrement its refcnt.
         */
        if (!try_module_get(sock-&gt;ops-&gt;owner))
            goto out_module_busy;

        /*
         * Now that we're done with the -&gt;create function, the [loadable]
         * module can have its refcnt decremented
         */
        module_put(pf-&gt;owner);
        err = security_socket_post_create(sock, family, type, protocol, kern);
        if (err)
            goto out_release;
        *res = sock;

        return 0;

    out_module_busy:
        err = -EAFNOSUPPORT;
    out_module_put:
        sock-&gt;ops = NULL;
        module_put(pf-&gt;owner);
    out_sock_release:
        sock_release(sock);
        return err;

    out_release:
        rcu_read_unlock();
        goto out_sock_release;
    }
</code></pre>

<p>从上面的代码中看到_sock_create函数调用了回调函数完成了socket创建和初始化过程，下面我们看创建socket结构的过程：sock = sock_alloc();</p>

<pre><code>    static struct socket *sock_alloc(void)
    {
        struct inode *inode;
        struct socket *sock;

        inode = new_inode(sock_mnt-&gt;mnt_sb); //在这里我们看到了sock_init函数中得到的全局变量sock_mnt，稍后看下new_inode函数
        if (!inode)
            return NULL;

        sock = SOCKET_I(inode); //得到了socket结构

        inode-&gt;i_mode = S_IFSOCK | S_IRWXUGO;
        inode-&gt;i_uid = current-&gt;fsuid;
        inode-&gt;i_gid = current-&gt;fsgid;

        get_cpu_var(sockets_in_use)++;
        put_cpu_var(sockets_in_use);
        return sock;
    }
    struct inode *new_inode(struct super_block *sb)
    {
        static unsigned long last_ino;
        struct inode * inode;

        spin_lock_prefetch(&amp;inode_lock);

        inode = alloc_inode(sb);  //接着看这个函数
        if (inode) {
            spin_lock(&amp;inode_lock);
            inodes_stat.nr_inodes++;
            list_add(&amp;inode-&gt;i_list, &amp;inode_in_use);
            list_add(&amp;inode-&gt;i_sb_list, &amp;sb-&gt;s_inodes);
            inode-&gt;i_ino = ++last_ino;
            inode-&gt;i_state = 0;
            spin_unlock(&amp;inode_lock);
        }
        return inode;
    }
    static struct inode *alloc_inode(struct super_block *sb)
    {
        static const struct address_space_operations empty_aops;
        static struct inode_operations empty_iops;
        static const struct file_operations empty_fops;
        struct inode *inode;

        if (sb-&gt;s_op-&gt;alloc_inode) //在这里我们看到 if调节满足，因为在sock_init函数中我们挂入了sock_alloc_inode函数，之前我们也看到了sock_alloc_inode函数创建了sizeof(struct socket_alloc
                                   //大小的slab高速缓存
            inode = sb-&gt;s_op-&gt;alloc_inode(sb); 
        else
            inode = (struct inode *) kmem_cache_alloc(inode_cachep, GFP_KERNEL);

        if (inode) {
            struct address_space * const mapping = &amp;inode-&gt;i_data;

            inode-&gt;i_sb = sb;
            inode-&gt;i_blkbits = sb-&gt;s_blocksize_bits;
            inode-&gt;i_flags = 0;
            atomic_set(&amp;inode-&gt;i_count, 1);
            inode-&gt;i_op = &amp;empty_iops;
            inode-&gt;i_fop = &amp;empty_fops;
            inode-&gt;i_nlink = 1;
            atomic_set(&amp;inode-&gt;i_writecount, 0);
            inode-&gt;i_size = 0;
            inode-&gt;i_blocks = 0;
            inode-&gt;i_bytes = 0;
            inode-&gt;i_generation = 0;
    #ifdef CONFIG_QUOTA
            memset(&amp;inode-&gt;i_dquot, 0, sizeof(inode-&gt;i_dquot));
    #endif
            inode-&gt;i_pipe = NULL;
            inode-&gt;i_bdev = NULL;
            inode-&gt;i_cdev = NULL;
            inode-&gt;i_rdev = 0;
            inode-&gt;dirtied_when = 0;
            if (security_inode_alloc(inode)) {
                if (inode-&gt;i_sb-&gt;s_op-&gt;destroy_inode)
                    inode-&gt;i_sb-&gt;s_op-&gt;destroy_inode(inode);
                else
                    kmem_cache_free(inode_cachep, (inode));
                return NULL;
            }

            mapping-&gt;a_ops = &amp;empty_aops;
            mapping-&gt;host = inode;
            mapping-&gt;flags = 0;
            mapping_set_gfp_mask(mapping, GFP_HIGHUSER);
            mapping-&gt;assoc_mapping = NULL;
            mapping-&gt;backing_dev_info = &amp;default_backing_dev_info;

            /*
             * If the block_device provides a backing_dev_info for client
             * inodes then use that.  Otherwise the inode share the bdev's
             * backing_dev_info.
             */
            if (sb-&gt;s_bdev) {
                struct backing_dev_info *bdi;

                bdi = sb-&gt;s_bdev-&gt;bd_inode_backing_dev_info;
                if (!bdi)
                    bdi = sb-&gt;s_bdev-&gt;bd_inode-&gt;i_mapping-&gt;backing_dev_info;
                mapping-&gt;backing_dev_info = bdi;
            }
            inode-&gt;i_private = NULL;
            inode-&gt;i_mapping = mapping;
        }
        return inode;
    }
</code></pre>

<p>从上面的分析中我们就可以很好的理解得到socket结构的过程：根据inode 得到socket</p>

<pre><code>    sock = SOCKET_I(inode);  
    static inline struct socket *SOCKET_I(struct inode *inode)
    {
        return &amp;container_of(inode, struct socket_alloc, vfs_inode)-&gt;socket;
    }
</code></pre>

<ol>
<li>现在创建socket结构的过程也就完成了，下面我们看看创建struct sock结构的过程</li>
</ol>


<p> 在inet_init函数中，
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
<span class='line-number'>59</span>
<span class='line-number'>60</span>
<span class='line-number'>61</span>
<span class='line-number'>62</span>
<span class='line-number'>63</span>
<span class='line-number'>64</span>
<span class='line-number'>65</span>
<span class='line-number'>66</span>
<span class='line-number'>67</span>
<span class='line-number'>68</span>
<span class='line-number'>69</span>
<span class='line-number'>70</span>
<span class='line-number'>71</span>
<span class='line-number'>72</span>
<span class='line-number'>73</span>
<span class='line-number'>74</span>
<span class='line-number'>75</span>
<span class='line-number'>76</span>
<span class='line-number'>77</span>
<span class='line-number'>78</span>
<span class='line-number'>79</span>
<span class='line-number'>80</span>
<span class='line-number'>81</span>
<span class='line-number'>82</span>
<span class='line-number'>83</span>
<span class='line-number'>84</span>
<span class='line-number'>85</span>
<span class='line-number'>86</span>
<span class='line-number'>87</span>
<span class='line-number'>88</span>
<span class='line-number'>89</span>
<span class='line-number'>90</span>
<span class='line-number'>91</span>
<span class='line-number'>92</span>
<span class='line-number'>93</span>
<span class='line-number'>94</span>
<span class='line-number'>95</span>
<span class='line-number'>96</span>
<span class='line-number'>97</span>
<span class='line-number'>98</span>
<span class='line-number'>99</span>
<span class='line-number'>100</span>
<span class='line-number'>101</span>
<span class='line-number'>102</span>
<span class='line-number'>103</span>
<span class='line-number'>104</span>
<span class='line-number'>105</span>
<span class='line-number'>106</span>
<span class='line-number'>107</span>
<span class='line-number'>108</span>
<span class='line-number'>109</span>
<span class='line-number'>110</span>
<span class='line-number'>111</span>
<span class='line-number'>112</span>
<span class='line-number'>113</span>
<span class='line-number'>114</span>
<span class='line-number'>115</span>
<span class='line-number'>116</span>
<span class='line-number'>117</span>
<span class='line-number'>118</span>
<span class='line-number'>119</span>
<span class='line-number'>120</span>
<span class='line-number'>121</span>
<span class='line-number'>122</span>
<span class='line-number'>123</span>
<span class='line-number'>124</span>
<span class='line-number'>125</span>
<span class='line-number'>126</span>
<span class='line-number'>127</span>
<span class='line-number'>128</span>
<span class='line-number'>129</span>
<span class='line-number'>130</span>
<span class='line-number'>131</span>
<span class='line-number'>132</span>
<span class='line-number'>133</span>
<span class='line-number'>134</span>
<span class='line-number'>135</span>
<span class='line-number'>136</span>
<span class='line-number'>137</span>
<span class='line-number'>138</span>
<span class='line-number'>139</span>
<span class='line-number'>140</span>
<span class='line-number'>141</span>
<span class='line-number'>142</span>
<span class='line-number'>143</span>
<span class='line-number'>144</span>
<span class='line-number'>145</span>
<span class='line-number'>146</span>
<span class='line-number'>147</span>
<span class='line-number'>148</span>
<span class='line-number'>149</span>
<span class='line-number'>150</span>
<span class='line-number'>151</span>
<span class='line-number'>152</span>
<span class='line-number'>153</span>
<span class='line-number'>154</span>
<span class='line-number'>155</span>
<span class='line-number'>156</span>
<span class='line-number'>157</span>
<span class='line-number'>158</span>
<span class='line-number'>159</span>
<span class='line-number'>160</span>
<span class='line-number'>161</span>
<span class='line-number'>162</span>
<span class='line-number'>163</span>
<span class='line-number'>164</span>
<span class='line-number'>165</span>
<span class='line-number'>166</span>
<span class='line-number'>167</span>
<span class='line-number'>168</span>
<span class='line-number'>169</span>
<span class='line-number'>170</span>
<span class='line-number'>171</span>
<span class='line-number'>172</span>
<span class='line-number'>173</span>
<span class='line-number'>174</span>
<span class='line-number'>175</span>
<span class='line-number'>176</span>
<span class='line-number'>177</span>
<span class='line-number'>178</span>
<span class='line-number'>179</span>
<span class='line-number'>180</span>
<span class='line-number'>181</span>
<span class='line-number'>182</span>
<span class='line-number'>183</span>
<span class='line-number'>184</span>
<span class='line-number'>185</span>
<span class='line-number'>186</span>
<span class='line-number'>187</span>
<span class='line-number'>188</span>
<span class='line-number'>189</span>
<span class='line-number'>190</span>
<span class='line-number'>191</span>
<span class='line-number'>192</span>
<span class='line-number'>193</span>
<span class='line-number'>194</span>
<span class='line-number'>195</span>
<span class='line-number'>196</span>
<span class='line-number'>197</span>
<span class='line-number'>198</span>
<span class='line-number'>199</span>
<span class='line-number'>200</span>
<span class='line-number'>201</span>
<span class='line-number'>202</span>
<span class='line-number'>203</span>
<span class='line-number'>204</span>
<span class='line-number'>205</span>
<span class='line-number'>206</span>
<span class='line-number'>207</span>
<span class='line-number'>208</span>
<span class='line-number'>209</span>
<span class='line-number'>210</span>
<span class='line-number'>211</span>
<span class='line-number'>212</span>
<span class='line-number'>213</span>
<span class='line-number'>214</span>
<span class='line-number'>215</span>
<span class='line-number'>216</span>
<span class='line-number'>217</span>
<span class='line-number'>218</span>
<span class='line-number'>219</span>
<span class='line-number'>220</span>
<span class='line-number'>221</span>
<span class='line-number'>222</span>
<span class='line-number'>223</span>
<span class='line-number'>224</span>
<span class='line-number'>225</span>
<span class='line-number'>226</span>
<span class='line-number'>227</span>
<span class='line-number'>228</span>
<span class='line-number'>229</span>
<span class='line-number'>230</span>
<span class='line-number'>231</span>
<span class='line-number'>232</span>
<span class='line-number'>233</span>
<span class='line-number'>234</span>
<span class='line-number'>235</span>
<span class='line-number'>236</span>
<span class='line-number'>237</span>
<span class='line-number'>238</span>
<span class='line-number'>239</span>
<span class='line-number'>240</span>
<span class='line-number'>241</span>
<span class='line-number'>242</span>
<span class='line-number'>243</span>
<span class='line-number'>244</span>
<span class='line-number'>245</span>
<span class='line-number'>246</span>
<span class='line-number'>247</span>
<span class='line-number'>248</span>
<span class='line-number'>249</span>
<span class='line-number'>250</span>
<span class='line-number'>251</span>
<span class='line-number'>252</span>
<span class='line-number'>253</span>
<span class='line-number'>254</span>
<span class='line-number'>255</span>
<span class='line-number'>256</span>
<span class='line-number'>257</span>
<span class='line-number'>258</span>
<span class='line-number'>259</span>
<span class='line-number'>260</span>
<span class='line-number'>261</span>
<span class='line-number'>262</span>
<span class='line-number'>263</span>
<span class='line-number'>264</span>
<span class='line-number'>265</span>
<span class='line-number'>266</span>
<span class='line-number'>267</span>
<span class='line-number'>268</span>
<span class='line-number'>269</span>
<span class='line-number'>270</span>
<span class='line-number'>271</span>
<span class='line-number'>272</span>
<span class='line-number'>273</span>
<span class='line-number'>274</span>
<span class='line-number'>275</span>
<span class='line-number'>276</span>
<span class='line-number'>277</span>
<span class='line-number'>278</span>
<span class='line-number'>279</span>
<span class='line-number'>280</span>
<span class='line-number'>281</span>
<span class='line-number'>282</span>
<span class='line-number'>283</span>
<span class='line-number'>284</span>
<span class='line-number'>285</span>
<span class='line-number'>286</span>
<span class='line-number'>287</span>
<span class='line-number'>288</span>
<span class='line-number'>289</span>
<span class='line-number'>290</span>
<span class='line-number'>291</span>
<span class='line-number'>292</span>
<span class='line-number'>293</span>
<span class='line-number'>294</span>
<span class='line-number'>295</span>
<span class='line-number'>296</span>
<span class='line-number'>297</span>
<span class='line-number'>298</span>
<span class='line-number'>299</span>
<span class='line-number'>300</span>
<span class='line-number'>301</span>
<span class='line-number'>302</span>
<span class='line-number'>303</span>
<span class='line-number'>304</span>
<span class='line-number'>305</span>
<span class='line-number'>306</span>
<span class='line-number'>307</span>
<span class='line-number'>308</span>
<span class='line-number'>309</span>
<span class='line-number'>310</span>
<span class='line-number'>311</span>
<span class='line-number'>312</span>
<span class='line-number'>313</span>
<span class='line-number'>314</span>
<span class='line-number'>315</span>
<span class='line-number'>316</span>
<span class='line-number'>317</span>
<span class='line-number'>318</span>
<span class='line-number'>319</span>
<span class='line-number'>320</span>
<span class='line-number'>321</span>
<span class='line-number'>322</span>
<span class='line-number'>323</span>
<span class='line-number'>324</span>
<span class='line-number'>325</span>
<span class='line-number'>326</span>
<span class='line-number'>327</span>
<span class='line-number'>328</span>
<span class='line-number'>329</span>
<span class='line-number'>330</span>
<span class='line-number'>331</span>
<span class='line-number'>332</span>
<span class='line-number'>333</span>
<span class='line-number'>334</span>
<span class='line-number'>335</span>
<span class='line-number'>336</span>
<span class='line-number'>337</span>
<span class='line-number'>338</span>
<span class='line-number'>339</span>
<span class='line-number'>340</span>
<span class='line-number'>341</span>
<span class='line-number'>342</span>
<span class='line-number'>343</span>
<span class='line-number'>344</span>
<span class='line-number'>345</span>
<span class='line-number'>346</span>
<span class='line-number'>347</span>
<span class='line-number'>348</span>
<span class='line-number'>349</span>
<span class='line-number'>350</span>
<span class='line-number'>351</span>
<span class='line-number'>352</span>
<span class='line-number'>353</span>
<span class='line-number'>354</span>
<span class='line-number'>355</span>
<span class='line-number'>356</span>
<span class='line-number'>357</span>
<span class='line-number'>358</span>
<span class='line-number'>359</span>
<span class='line-number'>360</span>
<span class='line-number'>361</span>
<span class='line-number'>362</span>
<span class='line-number'>363</span>
<span class='line-number'>364</span>
<span class='line-number'>365</span>
<span class='line-number'>366</span>
<span class='line-number'>367</span>
<span class='line-number'>368</span>
<span class='line-number'>369</span>
<span class='line-number'>370</span>
<span class='line-number'>371</span>
<span class='line-number'>372</span>
<span class='line-number'>373</span>
<span class='line-number'>374</span>
<span class='line-number'>375</span>
<span class='line-number'>376</span>
<span class='line-number'>377</span>
<span class='line-number'>378</span>
<span class='line-number'>379</span>
<span class='line-number'>380</span>
<span class='line-number'>381</span>
<span class='line-number'>382</span>
<span class='line-number'>383</span>
<span class='line-number'>384</span>
<span class='line-number'>385</span>
<span class='line-number'>386</span>
<span class='line-number'>387</span>
<span class='line-number'>388</span>
<span class='line-number'>389</span>
<span class='line-number'>390</span>
<span class='line-number'>391</span>
<span class='line-number'>392</span>
<span class='line-number'>393</span>
<span class='line-number'>394</span>
<span class='line-number'>395</span>
<span class='line-number'>396</span>
<span class='line-number'>397</span>
<span class='line-number'>398</span>
<span class='line-number'>399</span>
<span class='line-number'>400</span>
<span class='line-number'>401</span>
<span class='line-number'>402</span>
<span class='line-number'>403</span>
<span class='line-number'>404</span>
<span class='line-number'>405</span>
<span class='line-number'>406</span>
<span class='line-number'>407</span>
<span class='line-number'>408</span>
<span class='line-number'>409</span>
<span class='line-number'>410</span>
<span class='line-number'>411</span>
<span class='line-number'>412</span>
<span class='line-number'>413</span>
<span class='line-number'>414</span>
<span class='line-number'>415</span>
<span class='line-number'>416</span>
<span class='line-number'>417</span>
<span class='line-number'>418</span>
<span class='line-number'>419</span>
<span class='line-number'>420</span>
<span class='line-number'>421</span>
<span class='line-number'>422</span>
<span class='line-number'>423</span>
<span class='line-number'>424</span>
<span class='line-number'>425</span>
<span class='line-number'>426</span>
<span class='line-number'>427</span>
<span class='line-number'>428</span>
<span class='line-number'>429</span>
<span class='line-number'>430</span>
<span class='line-number'>431</span>
<span class='line-number'>432</span>
<span class='line-number'>433</span>
<span class='line-number'>434</span>
<span class='line-number'>435</span>
<span class='line-number'>436</span>
<span class='line-number'>437</span>
<span class='line-number'>438</span>
<span class='line-number'>439</span>
<span class='line-number'>440</span>
<span class='line-number'>441</span>
<span class='line-number'>442</span>
<span class='line-number'>443</span>
<span class='line-number'>444</span>
<span class='line-number'>445</span>
<span class='line-number'>446</span>
<span class='line-number'>447</span>
<span class='line-number'>448</span>
<span class='line-number'>449</span>
<span class='line-number'>450</span>
<span class='line-number'>451</span>
<span class='line-number'>452</span>
<span class='line-number'>453</span>
<span class='line-number'>454</span>
<span class='line-number'>455</span>
<span class='line-number'>456</span>
<span class='line-number'>457</span>
<span class='line-number'>458</span>
<span class='line-number'>459</span>
<span class='line-number'>460</span>
<span class='line-number'>461</span>
<span class='line-number'>462</span>
<span class='line-number'>463</span>
<span class='line-number'>464</span>
<span class='line-number'>465</span>
<span class='line-number'>466</span>
<span class='line-number'>467</span>
<span class='line-number'>468</span>
<span class='line-number'>469</span>
<span class='line-number'>470</span>
<span class='line-number'>471</span>
<span class='line-number'>472</span>
<span class='line-number'>473</span>
<span class='line-number'>474</span>
<span class='line-number'>475</span>
<span class='line-number'>476</span>
<span class='line-number'>477</span>
<span class='line-number'>478</span>
<span class='line-number'>479</span>
<span class='line-number'>480</span>
<span class='line-number'>481</span>
<span class='line-number'>482</span>
<span class='line-number'>483</span>
<span class='line-number'>484</span>
<span class='line-number'>485</span>
<span class='line-number'>486</span>
<span class='line-number'>487</span>
<span class='line-number'>488</span>
<span class='line-number'>489</span>
<span class='line-number'>490</span>
<span class='line-number'>491</span>
<span class='line-number'>492</span>
<span class='line-number'>493</span>
<span class='line-number'>494</span>
<span class='line-number'>495</span>
<span class='line-number'>496</span>
<span class='line-number'>497</span>
<span class='line-number'>498</span>
<span class='line-number'>499</span>
<span class='line-number'>500</span>
<span class='line-number'>501</span>
<span class='line-number'>502</span>
<span class='line-number'>503</span>
<span class='line-number'>504</span>
<span class='line-number'>505</span>
<span class='line-number'>506</span>
<span class='line-number'>507</span>
<span class='line-number'>508</span>
<span class='line-number'>509</span>
<span class='line-number'>510</span>
<span class='line-number'>511</span>
<span class='line-number'>512</span>
<span class='line-number'>513</span>
<span class='line-number'>514</span>
<span class='line-number'>515</span>
<span class='line-number'>516</span>
<span class='line-number'>517</span>
<span class='line-number'>518</span>
<span class='line-number'>519</span>
<span class='line-number'>520</span>
<span class='line-number'>521</span>
<span class='line-number'>522</span>
<span class='line-number'>523</span>
<span class='line-number'>524</span>
<span class='line-number'>525</span>
<span class='line-number'>526</span>
<span class='line-number'>527</span>
<span class='line-number'>528</span>
<span class='line-number'>529</span>
<span class='line-number'>530</span>
<span class='line-number'>531</span>
<span class='line-number'>532</span>
<span class='line-number'>533</span>
<span class='line-number'>534</span>
<span class='line-number'>535</span>
<span class='line-number'>536</span>
<span class='line-number'>537</span>
<span class='line-number'>538</span>
<span class='line-number'>539</span>
<span class='line-number'>540</span>
<span class='line-number'>541</span>
<span class='line-number'>542</span>
<span class='line-number'>543</span>
<span class='line-number'>544</span>
<span class='line-number'>545</span>
<span class='line-number'>546</span>
<span class='line-number'>547</span>
<span class='line-number'>548</span>
<span class='line-number'>549</span>
<span class='line-number'>550</span>
<span class='line-number'>551</span>
<span class='line-number'>552</span>
<span class='line-number'>553</span>
<span class='line-number'>554</span>
<span class='line-number'>555</span>
<span class='line-number'>556</span>
<span class='line-number'>557</span>
<span class='line-number'>558</span>
<span class='line-number'>559</span>
<span class='line-number'>560</span>
<span class='line-number'>561</span>
<span class='line-number'>562</span>
<span class='line-number'>563</span>
<span class='line-number'>564</span>
<span class='line-number'>565</span>
<span class='line-number'>566</span>
<span class='line-number'>567</span>
<span class='line-number'>568</span>
<span class='line-number'>569</span>
<span class='line-number'>570</span>
<span class='line-number'>571</span>
<span class='line-number'>572</span>
<span class='line-number'>573</span>
<span class='line-number'>574</span>
<span class='line-number'>575</span>
<span class='line-number'>576</span>
<span class='line-number'>577</span>
<span class='line-number'>578</span>
<span class='line-number'>579</span>
<span class='line-number'>580</span>
<span class='line-number'>581</span>
<span class='line-number'>582</span>
<span class='line-number'>583</span>
<span class='line-number'>584</span>
<span class='line-number'>585</span>
<span class='line-number'>586</span>
<span class='line-number'>587</span>
<span class='line-number'>588</span>
<span class='line-number'>589</span>
<span class='line-number'>590</span>
<span class='line-number'>591</span>
<span class='line-number'>592</span>
<span class='line-number'>593</span>
<span class='line-number'>594</span>
<span class='line-number'>595</span>
<span class='line-number'>596</span>
<span class='line-number'>597</span>
<span class='line-number'>598</span>
<span class='line-number'>599</span>
<span class='line-number'>600</span>
<span class='line-number'>601</span>
<span class='line-number'>602</span>
<span class='line-number'>603</span>
<span class='line-number'>604</span>
<span class='line-number'>605</span>
<span class='line-number'>606</span>
<span class='line-number'>607</span>
<span class='line-number'>608</span>
<span class='line-number'>609</span>
<span class='line-number'>610</span>
<span class='line-number'>611</span>
<span class='line-number'>612</span>
<span class='line-number'>613</span>
<span class='line-number'>614</span>
<span class='line-number'>615</span>
<span class='line-number'>616</span>
<span class='line-number'>617</span>
<span class='line-number'>618</span>
<span class='line-number'>619</span>
<span class='line-number'>620</span>
<span class='line-number'>621</span>
<span class='line-number'>622</span>
<span class='line-number'>623</span>
<span class='line-number'>624</span>
<span class='line-number'>625</span>
<span class='line-number'>626</span>
<span class='line-number'>627</span>
<span class='line-number'>628</span>
<span class='line-number'>629</span>
<span class='line-number'>630</span>
<span class='line-number'>631</span>
<span class='line-number'>632</span>
<span class='line-number'>633</span>
<span class='line-number'>634</span>
<span class='line-number'>635</span>
<span class='line-number'>636</span>
<span class='line-number'>637</span>
<span class='line-number'>638</span>
<span class='line-number'>639</span>
<span class='line-number'>640</span>
<span class='line-number'>641</span>
<span class='line-number'>642</span>
<span class='line-number'>643</span>
<span class='line-number'>644</span>
<span class='line-number'>645</span>
<span class='line-number'>646</span>
<span class='line-number'>647</span>
<span class='line-number'>648</span>
<span class='line-number'>649</span>
<span class='line-number'>650</span>
<span class='line-number'>651</span>
<span class='line-number'>652</span>
<span class='line-number'>653</span>
<span class='line-number'>654</span>
<span class='line-number'>655</span>
<span class='line-number'>656</span>
<span class='line-number'>657</span>
<span class='line-number'>658</span>
<span class='line-number'>659</span>
<span class='line-number'>660</span>
<span class='line-number'>661</span>
<span class='line-number'>662</span>
<span class='line-number'>663</span>
<span class='line-number'>664</span>
<span class='line-number'>665</span>
<span class='line-number'>666</span>
<span class='line-number'>667</span>
<span class='line-number'>668</span>
<span class='line-number'>669</span>
<span class='line-number'>670</span>
<span class='line-number'>671</span>
<span class='line-number'>672</span>
<span class='line-number'>673</span>
<span class='line-number'>674</span>
<span class='line-number'>675</span>
<span class='line-number'>676</span>
<span class='line-number'>677</span>
<span class='line-number'>678</span>
<span class='line-number'>679</span>
<span class='line-number'>680</span>
<span class='line-number'>681</span>
<span class='line-number'>682</span>
<span class='line-number'>683</span>
<span class='line-number'>684</span>
<span class='line-number'>685</span>
<span class='line-number'>686</span>
<span class='line-number'>687</span>
<span class='line-number'>688</span>
<span class='line-number'>689</span>
<span class='line-number'>690</span>
<span class='line-number'>691</span>
<span class='line-number'>692</span>
<span class='line-number'>693</span>
<span class='line-number'>694</span>
<span class='line-number'>695</span>
<span class='line-number'>696</span>
<span class='line-number'>697</span>
<span class='line-number'>698</span>
<span class='line-number'>699</span>
<span class='line-number'>700</span>
<span class='line-number'>701</span>
<span class='line-number'>702</span>
<span class='line-number'>703</span>
<span class='line-number'>704</span>
<span class='line-number'>705</span>
<span class='line-number'>706</span>
<span class='line-number'>707</span>
<span class='line-number'>708</span>
<span class='line-number'>709</span>
<span class='line-number'>710</span>
<span class='line-number'>711</span>
<span class='line-number'>712</span>
<span class='line-number'>713</span>
<span class='line-number'>714</span>
<span class='line-number'>715</span>
<span class='line-number'>716</span>
<span class='line-number'>717</span>
<span class='line-number'>718</span>
<span class='line-number'>719</span>
<span class='line-number'>720</span>
<span class='line-number'>721</span>
<span class='line-number'>722</span>
<span class='line-number'>723</span>
<span class='line-number'>724</span>
<span class='line-number'>725</span>
<span class='line-number'>726</span>
<span class='line-number'>727</span>
<span class='line-number'>728</span>
<span class='line-number'>729</span>
<span class='line-number'>730</span>
<span class='line-number'>731</span>
<span class='line-number'>732</span>
<span class='line-number'>733</span>
<span class='line-number'>734</span>
<span class='line-number'>735</span>
<span class='line-number'>736</span>
<span class='line-number'>737</span>
<span class='line-number'>738</span>
<span class='line-number'>739</span>
<span class='line-number'>740</span>
<span class='line-number'>741</span>
<span class='line-number'>742</span>
<span class='line-number'>743</span>
<span class='line-number'>744</span>
<span class='line-number'>745</span>
<span class='line-number'>746</span>
<span class='line-number'>747</span>
<span class='line-number'>748</span>
<span class='line-number'>749</span>
<span class='line-number'>750</span>
<span class='line-number'>751</span>
<span class='line-number'>752</span>
<span class='line-number'>753</span>
<span class='line-number'>754</span>
<span class='line-number'>755</span>
<span class='line-number'>756</span>
<span class='line-number'>757</span>
<span class='line-number'>758</span>
<span class='line-number'>759</span>
<span class='line-number'>760</span>
<span class='line-number'>761</span>
<span class='line-number'>762</span>
<span class='line-number'>763</span>
<span class='line-number'>764</span>
<span class='line-number'>765</span>
<span class='line-number'>766</span>
<span class='line-number'>767</span>
<span class='line-number'>768</span>
<span class='line-number'>769</span>
<span class='line-number'>770</span>
<span class='line-number'>771</span>
<span class='line-number'>772</span>
<span class='line-number'>773</span>
<span class='line-number'>774</span>
<span class='line-number'>775</span>
<span class='line-number'>776</span>
<span class='line-number'>777</span>
<span class='line-number'>778</span>
<span class='line-number'>779</span>
<span class='line-number'>780</span>
<span class='line-number'>781</span>
<span class='line-number'>782</span>
<span class='line-number'>783</span>
<span class='line-number'>784</span>
<span class='line-number'>785</span>
<span class='line-number'>786</span>
<span class='line-number'>787</span>
<span class='line-number'>788</span>
<span class='line-number'>789</span>
<span class='line-number'>790</span>
<span class='line-number'>791</span>
<span class='line-number'>792</span>
<span class='line-number'>793</span>
<span class='line-number'>794</span>
<span class='line-number'>795</span>
<span class='line-number'>796</span>
<span class='line-number'>797</span>
<span class='line-number'>798</span>
<span class='line-number'>799</span>
<span class='line-number'>800</span>
<span class='line-number'>801</span>
<span class='line-number'>802</span>
<span class='line-number'>803</span>
<span class='line-number'>804</span>
<span class='line-number'>805</span>
<span class='line-number'>806</span>
<span class='line-number'>807</span>
<span class='line-number'>808</span>
<span class='line-number'>809</span>
<span class='line-number'>810</span>
<span class='line-number'>811</span>
<span class='line-number'>812</span>
<span class='line-number'>813</span>
<span class='line-number'>814</span>
<span class='line-number'>815</span>
<span class='line-number'>816</span>
<span class='line-number'>817</span>
<span class='line-number'>818</span>
<span class='line-number'>819</span>
<span class='line-number'>820</span>
<span class='line-number'>821</span>
<span class='line-number'>822</span>
<span class='line-number'>823</span>
<span class='line-number'>824</span>
<span class='line-number'>825</span>
<span class='line-number'>826</span>
<span class='line-number'>827</span>
<span class='line-number'>828</span>
<span class='line-number'>829</span>
<span class='line-number'>830</span>
<span class='line-number'>831</span>
<span class='line-number'>832</span>
<span class='line-number'>833</span>
<span class='line-number'>834</span>
<span class='line-number'>835</span>
<span class='line-number'>836</span>
<span class='line-number'>837</span>
<span class='line-number'>838</span>
<span class='line-number'>839</span>
<span class='line-number'>840</span>
<span class='line-number'>841</span>
<span class='line-number'>842</span>
<span class='line-number'>843</span>
<span class='line-number'>844</span>
<span class='line-number'>845</span>
<span class='line-number'>846</span>
<span class='line-number'>847</span>
<span class='line-number'>848</span>
<span class='line-number'>849</span>
<span class='line-number'>850</span>
<span class='line-number'>851</span>
<span class='line-number'>852</span>
<span class='line-number'>853</span>
<span class='line-number'>854</span>
<span class='line-number'>855</span>
<span class='line-number'>856</span>
<span class='line-number'>857</span>
<span class='line-number'>858</span>
<span class='line-number'>859</span>
<span class='line-number'>860</span>
<span class='line-number'>861</span>
<span class='line-number'>862</span>
<span class='line-number'>863</span>
<span class='line-number'>864</span>
<span class='line-number'>865</span>
<span class='line-number'>866</span>
<span class='line-number'>867</span>
<span class='line-number'>868</span>
<span class='line-number'>869</span>
<span class='line-number'>870</span>
<span class='line-number'>871</span>
<span class='line-number'>872</span>
<span class='line-number'>873</span>
<span class='line-number'>874</span>
<span class='line-number'>875</span>
<span class='line-number'>876</span>
<span class='line-number'>877</span>
<span class='line-number'>878</span>
<span class='line-number'>879</span>
<span class='line-number'>880</span>
<span class='line-number'>881</span>
<span class='line-number'>882</span>
<span class='line-number'>883</span>
<span class='line-number'>884</span>
<span class='line-number'>885</span>
<span class='line-number'>886</span>
<span class='line-number'>887</span>
<span class='line-number'>888</span>
<span class='line-number'>889</span>
<span class='line-number'>890</span>
<span class='line-number'>891</span>
<span class='line-number'>892</span>
<span class='line-number'>893</span>
<span class='line-number'>894</span>
<span class='line-number'>895</span>
<span class='line-number'>896</span>
<span class='line-number'>897</span>
<span class='line-number'>898</span>
<span class='line-number'>899</span>
<span class='line-number'>900</span>
<span class='line-number'>901</span>
<span class='line-number'>902</span>
<span class='line-number'>903</span>
<span class='line-number'>904</span>
<span class='line-number'>905</span>
<span class='line-number'>906</span>
<span class='line-number'>907</span>
<span class='line-number'>908</span>
<span class='line-number'>909</span>
<span class='line-number'>910</span>
<span class='line-number'>911</span>
<span class='line-number'>912</span>
<span class='line-number'>913</span>
<span class='line-number'>914</span>
<span class='line-number'>915</span>
<span class='line-number'>916</span>
<span class='line-number'>917</span>
<span class='line-number'>918</span>
<span class='line-number'>919</span>
<span class='line-number'>920</span>
<span class='line-number'>921</span>
<span class='line-number'>922</span>
<span class='line-number'>923</span>
<span class='line-number'>924</span>
<span class='line-number'>925</span>
<span class='line-number'>926</span>
<span class='line-number'>927</span>
<span class='line-number'>928</span>
<span class='line-number'>929</span>
<span class='line-number'>930</span>
<span class='line-number'>931</span>
<span class='line-number'>932</span>
<span class='line-number'>933</span>
<span class='line-number'>934</span>
<span class='line-number'>935</span>
<span class='line-number'>936</span>
<span class='line-number'>937</span>
<span class='line-number'>938</span>
<span class='line-number'>939</span>
<span class='line-number'>940</span>
<span class='line-number'>941</span>
<span class='line-number'>942</span>
<span class='line-number'>943</span>
<span class='line-number'>944</span>
<span class='line-number'>945</span>
<span class='line-number'>946</span>
<span class='line-number'>947</span>
<span class='line-number'>948</span>
<span class='line-number'>949</span>
<span class='line-number'>950</span>
<span class='line-number'>951</span>
<span class='line-number'>952</span>
<span class='line-number'>953</span>
<span class='line-number'>954</span>
<span class='line-number'>955</span>
<span class='line-number'>956</span>
<span class='line-number'>957</span>
<span class='line-number'>958</span>
<span class='line-number'>959</span>
<span class='line-number'>960</span>
<span class='line-number'>961</span>
<span class='line-number'>962</span>
<span class='line-number'>963</span>
<span class='line-number'>964</span>
<span class='line-number'>965</span>
<span class='line-number'>966</span>
<span class='line-number'>967</span>
<span class='line-number'>968</span>
<span class='line-number'>969</span>
<span class='line-number'>970</span>
<span class='line-number'>971</span>
<span class='line-number'>972</span>
<span class='line-number'>973</span>
<span class='line-number'>974</span>
<span class='line-number'>975</span>
<span class='line-number'>976</span>
<span class='line-number'>977</span>
<span class='line-number'>978</span>
<span class='line-number'>979</span>
<span class='line-number'>980</span>
<span class='line-number'>981</span>
<span class='line-number'>982</span>
<span class='line-number'>983</span>
<span class='line-number'>984</span>
<span class='line-number'>985</span>
<span class='line-number'>986</span>
<span class='line-number'>987</span>
<span class='line-number'>988</span>
<span class='line-number'>989</span>
<span class='line-number'>990</span>
<span class='line-number'>991</span>
<span class='line-number'>992</span>
<span class='line-number'>993</span>
<span class='line-number'>994</span>
<span class='line-number'>995</span>
<span class='line-number'>996</span>
<span class='line-number'>997</span>
<span class='line-number'>998</span>
<span class='line-number'>999</span>
<span class='line-number'>1000</span>
<span class='line-number'>1001</span>
<span class='line-number'>1002</span>
<span class='line-number'>1003</span>
<span class='line-number'>1004</span>
<span class='line-number'>1005</span>
<span class='line-number'>1006</span>
<span class='line-number'>1007</span>
<span class='line-number'>1008</span>
<span class='line-number'>1009</span>
<span class='line-number'>1010</span>
<span class='line-number'>1011</span>
<span class='line-number'>1012</span>
<span class='line-number'>1013</span>
<span class='line-number'>1014</span>
<span class='line-number'>1015</span>
<span class='line-number'>1016</span>
<span class='line-number'>1017</span>
<span class='line-number'>1018</span>
<span class='line-number'>1019</span>
<span class='line-number'>1020</span>
<span class='line-number'>1021</span>
<span class='line-number'>1022</span>
<span class='line-number'>1023</span>
<span class='line-number'>1024</span>
<span class='line-number'>1025</span>
<span class='line-number'>1026</span>
<span class='line-number'>1027</span>
<span class='line-number'>1028</span>
<span class='line-number'>1029</span>
<span class='line-number'>1030</span>
<span class='line-number'>1031</span>
<span class='line-number'>1032</span>
<span class='line-number'>1033</span>
<span class='line-number'>1034</span>
<span class='line-number'>1035</span>
<span class='line-number'>1036</span>
<span class='line-number'>1037</span>
<span class='line-number'>1038</span>
<span class='line-number'>1039</span>
<span class='line-number'>1040</span>
<span class='line-number'>1041</span>
<span class='line-number'>1042</span>
<span class='line-number'>1043</span>
<span class='line-number'>1044</span>
<span class='line-number'>1045</span>
<span class='line-number'>1046</span>
<span class='line-number'>1047</span>
<span class='line-number'>1048</span>
<span class='line-number'>1049</span>
<span class='line-number'>1050</span>
<span class='line-number'>1051</span>
<span class='line-number'>1052</span>
<span class='line-number'>1053</span>
<span class='line-number'>1054</span>
<span class='line-number'>1055</span>
<span class='line-number'>1056</span>
<span class='line-number'>1057</span>
<span class='line-number'>1058</span>
<span class='line-number'>1059</span>
<span class='line-number'>1060</span>
<span class='line-number'>1061</span>
<span class='line-number'>1062</span>
<span class='line-number'>1063</span>
<span class='line-number'>1064</span>
<span class='line-number'>1065</span>
<span class='line-number'>1066</span>
<span class='line-number'>1067</span>
<span class='line-number'>1068</span>
<span class='line-number'>1069</span>
<span class='line-number'>1070</span>
<span class='line-number'>1071</span>
<span class='line-number'>1072</span>
<span class='line-number'>1073</span>
<span class='line-number'>1074</span>
<span class='line-number'>1075</span>
<span class='line-number'>1076</span>
<span class='line-number'>1077</span>
<span class='line-number'>1078</span>
<span class='line-number'>1079</span>
<span class='line-number'>1080</span>
<span class='line-number'>1081</span>
<span class='line-number'>1082</span>
<span class='line-number'>1083</span>
<span class='line-number'>1084</span>
<span class='line-number'>1085</span>
<span class='line-number'>1086</span>
<span class='line-number'>1087</span>
<span class='line-number'>1088</span>
<span class='line-number'>1089</span>
<span class='line-number'>1090</span>
<span class='line-number'>1091</span>
<span class='line-number'>1092</span>
<span class='line-number'>1093</span>
<span class='line-number'>1094</span>
<span class='line-number'>1095</span>
<span class='line-number'>1096</span>
<span class='line-number'>1097</span>
<span class='line-number'>1098</span>
<span class='line-number'>1099</span>
<span class='line-number'>1100</span>
<span class='line-number'>1101</span>
<span class='line-number'>1102</span>
<span class='line-number'>1103</span>
<span class='line-number'>1104</span>
<span class='line-number'>1105</span>
<span class='line-number'>1106</span>
<span class='line-number'>1107</span>
<span class='line-number'>1108</span>
<span class='line-number'>1109</span>
<span class='line-number'>1110</span>
<span class='line-number'>1111</span>
<span class='line-number'>1112</span>
<span class='line-number'>1113</span>
<span class='line-number'>1114</span>
<span class='line-number'>1115</span>
<span class='line-number'>1116</span>
<span class='line-number'>1117</span>
<span class='line-number'>1118</span>
<span class='line-number'>1119</span>
<span class='line-number'>1120</span>
<span class='line-number'>1121</span>
<span class='line-number'>1122</span>
<span class='line-number'>1123</span>
<span class='line-number'>1124</span>
<span class='line-number'>1125</span>
<span class='line-number'>1126</span>
<span class='line-number'>1127</span>
<span class='line-number'>1128</span>
<span class='line-number'>1129</span>
<span class='line-number'>1130</span>
<span class='line-number'>1131</span>
<span class='line-number'>1132</span>
<span class='line-number'>1133</span>
<span class='line-number'>1134</span>
<span class='line-number'>1135</span>
<span class='line-number'>1136</span>
<span class='line-number'>1137</span>
<span class='line-number'>1138</span>
<span class='line-number'>1139</span>
<span class='line-number'>1140</span>
<span class='line-number'>1141</span>
<span class='line-number'>1142</span>
<span class='line-number'>1143</span>
<span class='line-number'>1144</span>
<span class='line-number'>1145</span>
<span class='line-number'>1146</span>
<span class='line-number'>1147</span>
<span class='line-number'>1148</span>
<span class='line-number'>1149</span>
<span class='line-number'>1150</span>
<span class='line-number'>1151</span>
<span class='line-number'>1152</span>
<span class='line-number'>1153</span>
<span class='line-number'>1154</span>
<span class='line-number'>1155</span>
<span class='line-number'>1156</span>
<span class='line-number'>1157</span>
<span class='line-number'>1158</span>
<span class='line-number'>1159</span>
<span class='line-number'>1160</span>
<span class='line-number'>1161</span>
<span class='line-number'>1162</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>(void)sock_register(&amp;inet_family_ops);&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;static struct net_proto_family inet_family_ops = {
</span><span class='line'>.family = PF_INET,
</span><span class='line'>.create = inet_create,
</span><span class='line'>.owner    = THIS_MODULE,
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;在这里我们看到了挂入的过程，net_families数组以family为下标，组成了各个协议创建函数，还记得执行create函数的地方吧？但在看这个函数以前先看看这里：
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;/* Upon startup we insert all the elements in inetsw_array[] into
</span><span class='line'> * the linked list inetsw.
</span><span class='line'> */
</span><span class='line'>static struct inet_protosw inetsw_array[] =
</span><span class='line'>{
</span><span class='line'>{
</span><span class='line'>    .type = SOCK_STREAM,
</span><span class='line'>    .protocol = IPPROTO_TCP,
</span><span class='line'>    .prot = &amp;tcp_prot,
</span><span class='line'>    .ops = &amp;inet_stream_ops,
</span><span class='line'>    .capability = -1,
</span><span class='line'>    .no_check = 0,
</span><span class='line'>    .flags = INET_PROTOSW_PERMANENT |
</span><span class='line'>        INET_PROTOSW_ICSK,
</span><span class='line'>},
</span><span class='line'>
</span><span class='line'>{
</span><span class='line'>    .type = SOCK_DGRAM,
</span><span class='line'>    .protocol = IPPROTO_UDP,
</span><span class='line'>    .prot = &amp;udp_prot,
</span><span class='line'>    .ops = &amp;inet_dgram_ops,
</span><span class='line'>    .capability = -1,
</span><span class='line'>    .no_check = UDP_CSUM_DEFAULT,
</span><span class='line'>    .flags = INET_PROTOSW_PERMANENT,
</span><span class='line'>},
</span><span class='line'>
</span><span class='line'>
</span><span class='line'>{
</span><span class='line'>    .type = SOCK_RAW,
</span><span class='line'>    .protocol = IPPROTO_IP,    /* wild card */
</span><span class='line'>    .prot = &amp;raw_prot,
</span><span class='line'>    .ops = &amp;inet_sockraw_ops,
</span><span class='line'>    .capability = CAP_NET_RAW,
</span><span class='line'>    .no_check = UDP_CSUM_DEFAULT,
</span><span class='line'>    .flags = INET_PROTOSW_REUSE,
</span><span class='line'>}
</span><span class='line'>};
</span><span class='line'>
</span><span class='line'>//下面的代码是在inet_init函数中执行的
</span><span class='line'>/* Register the socket-side information for inet_create. */
</span><span class='line'>for (r = &amp;inetsw[0]; r &lt; &amp;inetsw[SOCK_MAX]; ++r)
</span><span class='line'>    INIT_LIST_HEAD(r);
</span><span class='line'>
</span><span class='line'>for (q = inetsw_array; q &lt; &amp;inetsw_array[INETSW_ARRAY_LEN]; ++q)
</span><span class='line'>    inet_register_protosw(q);
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;
</span><span class='line'>我们来看看struct inet_protosw 这个结构
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;/* This is used to register socket interfaces for IP protocols. */
</span><span class='line'>struct inet_protosw {
</span><span class='line'>struct list_head list;
</span><span class='line'>
</span><span class='line'>/* These two fields form the lookup key. */
</span><span class='line'>unsigned short     type;     /* This is the 2nd argument to socket(2). */
</span><span class='line'>unsigned short     protocol; /* This is the L4 protocol number. */
</span><span class='line'>
</span><span class='line'>struct proto     *prot;
</span><span class='line'>const struct proto_ops *ops;
</span><span class='line'>
</span><span class='line'>int capability; /* Which (if any) capability do
</span><span class='line'>                 * we need to use this socket
</span><span class='line'>                 * interface?
</span><span class='line'>                                  */
</span><span class='line'>char no_check; /* checksum on rcv/xmit/none? */
</span><span class='line'>unsigned char     flags; /* See INET_PROTOSW_* below. */
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;/*
</span><span class='line'> *    Create an inet socket. //从这个注释中我们可以看到，还可以创建其他类型的socket
</span><span class='line'> */
</span><span class='line'>
</span><span class='line'>static int inet_create(struct socket *sock, int protocol)
</span><span class='line'>{
</span><span class='line'>struct sock *sk;
</span><span class='line'>struct list_head *p;
</span><span class='line'>struct inet_protosw *answer;
</span><span class='line'>struct inet_sock *inet;
</span><span class='line'>struct proto *answer_prot;
</span><span class='line'>unsigned char answer_flags;
</span><span class='line'>char answer_no_check;
</span><span class='line'>int try_loading_module = 0;
</span><span class='line'>int err;
</span><span class='line'>
</span><span class='line'>sock-&gt;state = SS_UNCONNECTED;
</span><span class='line'>
</span><span class='line'>/* Look for the requested type/protocol pair. */
</span><span class='line'>answer = NULL;
</span><span class='line'>lookup_protocol:
</span><span class='line'>err = -ESOCKTNOSUPPORT;
</span><span class='line'>rcu_read_lock();
</span><span class='line'>list_for_each_rcu(p, &amp;inetsw[sock-&gt;type]) {   //在这里我们遍历inetsw数组，根据是UDP，TCP，RAW类型得到了struct inet_protosw结构
</span><span class='line'>    answer = list_entry(p, struct inet_protosw, list);
</span><span class='line'>
</span><span class='line'>    /* Check the non-wild match. */
</span><span class='line'>    if (protocol == answer-&gt;protocol) {
</span><span class='line'>        if (protocol != IPPROTO_IP)
</span><span class='line'>            break;
</span><span class='line'>    } else {
</span><span class='line'>        /* Check for the two wild cases. */
</span><span class='line'>        if (IPPROTO_IP == protocol) {
</span><span class='line'>            protocol = answer-&gt;protocol;
</span><span class='line'>            break;
</span><span class='line'>        }
</span><span class='line'>        if (IPPROTO_IP == answer-&gt;protocol)
</span><span class='line'>            break;
</span><span class='line'>    }
</span><span class='line'>    err = -EPROTONOSUPPORT;
</span><span class='line'>    answer = NULL;
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>if (unlikely(answer == NULL)) {
</span><span class='line'>    if (try_loading_module &lt; 2) {
</span><span class='line'>        rcu_read_unlock();
</span><span class='line'>        /*
</span><span class='line'>         * Be more specific, e.g. net-pf-2-proto-132-type-1
</span><span class='line'>         * (net-pf-PF_INET-proto-IPPROTO_SCTP-type-SOCK_STREAM)
</span><span class='line'>         */
</span><span class='line'>        if (++try_loading_module == 1)
</span><span class='line'>            request_module("net-pf-%d-proto-%d-type-%d",
</span><span class='line'>                    PF_INET, protocol, sock-&gt;type);
</span><span class='line'>        /*
</span><span class='line'>         * Fall back to generic, e.g. net-pf-2-proto-132
</span><span class='line'>         * (net-pf-PF_INET-proto-IPPROTO_SCTP)
</span><span class='line'>         */
</span><span class='line'>        else
</span><span class='line'>            request_module("net-pf-%d-proto-%d",
</span><span class='line'>                    PF_INET, protocol);
</span><span class='line'>        goto lookup_protocol;
</span><span class='line'>    } else
</span><span class='line'>        goto out_rcu_unlock;
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>err = -EPERM;
</span><span class='line'>if (answer-&gt;capability &gt; 0 &amp;&amp; !capable(answer-&gt;capability))
</span><span class='line'>    goto out_rcu_unlock;
</span><span class='line'>
</span><span class='line'>sock-&gt;ops = answer-&gt;ops;    //对socket结构进行了初始化
</span><span class='line'>answer_prot = answer-&gt;prot;
</span><span class='line'>answer_no_check = answer-&gt;no_check;
</span><span class='line'>answer_flags = answer-&gt;flags;
</span><span class='line'>rcu_read_unlock();
</span><span class='line'>
</span><span class='line'>BUG_TRAP(answer_prot-&gt;slab != NULL);
</span><span class='line'>
</span><span class='line'>err = -ENOBUFS;
</span><span class='line'>sk = sk_alloc(PF_INET, GFP_KERNEL, answer_prot, 1);   //这个函数创建了struct sock 这个庞然大物
</span><span class='line'>if (sk == NULL)
</span><span class='line'>    goto out;
</span><span class='line'>
</span><span class='line'>err = 0;
</span><span class='line'>sk-&gt;sk_no_check = answer_no_check;
</span><span class='line'>if (INET_PROTOSW_REUSE &amp; answer_flags)
</span><span class='line'>    sk-&gt;sk_reuse = 1;
</span><span class='line'>
</span><span class='line'>inet = inet_sk(sk);
</span><span class='line'>inet-&gt;is_icsk = (INET_PROTOSW_ICSK &amp; answer_flags) != 0;
</span><span class='line'>
</span><span class='line'>if (SOCK_RAW == sock-&gt;type) {
</span><span class='line'>    inet-&gt;num = protocol;
</span><span class='line'>    if (IPPROTO_RAW == protocol)
</span><span class='line'>        inet-&gt;hdrincl = 1;
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>if (ipv4_config.no_pmtu_disc)
</span><span class='line'>    inet-&gt;pmtudisc = IP_PMTUDISC_DONT;
</span><span class='line'>else
</span><span class='line'>    inet-&gt;pmtudisc = IP_PMTUDISC_WANT;
</span><span class='line'>
</span><span class='line'>inet-&gt;id = 0;
</span><span class='line'>
</span><span class='line'>sock_init_data(sock, sk);  //在这里对struct sock里面重要的字段进行了初始化，包括接受队列，发送队列，以及长度等
</span><span class='line'>
</span><span class='line'>sk-&gt;sk_destruct     = inet_sock_destruct;   
</span><span class='line'>sk-&gt;sk_family     = PF_INET;
</span><span class='line'>sk-&gt;sk_protocol     = protocol;
</span><span class='line'>sk-&gt;sk_backlog_rcv = sk-&gt;sk_prot-&gt;backlog_rcv;
</span><span class='line'>
</span><span class='line'>inet-&gt;uc_ttl    = -1;
</span><span class='line'>inet-&gt;mc_loop    = 1;
</span><span class='line'>inet-&gt;mc_ttl    = 1;
</span><span class='line'>inet-&gt;mc_index    = 0;
</span><span class='line'>inet-&gt;mc_list    = NULL;
</span><span class='line'>
</span><span class='line'>sk_refcnt_debug_inc(sk);
</span><span class='line'>
</span><span class='line'>if (inet-&gt;num) {    //我们看到当我们调用RAW类型的socket的时候，这个if条件就成立了
</span><span class='line'>    /* It assumes that any protocol which allows
</span><span class='line'>     * the user to assign a number at socket
</span><span class='line'>     * creation time automatically
</span><span class='line'>     * shares.
</span><span class='line'>     */
</span><span class='line'>    inet-&gt;sport = htons(inet-&gt;num);
</span><span class='line'>    /* Add to protocol hash chains. */
</span><span class='line'>    sk-&gt;sk_prot-&gt;hash(sk);
</span><span class='line'>}
</span><span class='line'>
</span><span class='line'>if (sk-&gt;sk_prot-&gt;init) {           //看L4层是否注册了初始化函数，我们看到UDP类型的socket为空，而TCP类型的socket注册了初始化函数
</span><span class='line'>    err = sk-&gt;sk_prot-&gt;init(sk);
</span><span class='line'>    if (err)
</span><span class='line'>        sk_common_release(sk);
</span><span class='line'>}
</span><span class='line'>out:
</span><span class='line'>return err;
</span><span class='line'>out_rcu_unlock:
</span><span class='line'>rcu_read_unlock();
</span><span class='line'>goto out;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;void sock_init_data(struct socket *sock, struct sock *sk)
</span><span class='line'>{
</span><span class='line'>skb_queue_head_init(&amp;sk-&gt;sk_receive_queue); //接受队列
</span><span class='line'>skb_queue_head_init(&amp;sk-&gt;sk_write_queue);   //发送队列
</span><span class='line'>skb_queue_head_init(&amp;sk-&gt;sk_error_queue);
</span><span class='line'>#ifdef CONFIG_NET_DMA
</span><span class='line'>skb_queue_head_init(&amp;sk-&gt;sk_async_wait_queue);
</span><span class='line'>#endif
</span><span class='line'>
</span><span class='line'>sk-&gt;sk_send_head    =    NULL;
</span><span class='line'>
</span><span class='line'>init_timer(&amp;sk-&gt;sk_timer);
</span><span class='line'>
</span><span class='line'>sk-&gt;sk_allocation    =    GFP_KERNEL;
</span><span class='line'>sk-&gt;sk_rcvbuf        =    sysctl_rmem_default;  //接受缓冲区大小
</span><span class='line'>sk-&gt;sk_sndbuf        =    sysctl_wmem_default;  //发送缓冲区大小
</span><span class='line'>sk-&gt;sk_state        =    TCP_CLOSE;   //被初始化为TCP_CLOSE，再下一篇绑定分析中我们会看到会检查这个状态
</span><span class='line'>sk-&gt;sk_socket        =    sock;
</span><span class='line'>
</span><span class='line'>sock_set_flag(sk, SOCK_ZAPPED);
</span><span class='line'>
</span><span class='line'>if(sock)
</span><span class='line'>{
</span><span class='line'>    sk-&gt;sk_type    =    sock-&gt;type;
</span><span class='line'>    sk-&gt;sk_sleep    =    &amp;sock-&gt;wait;
</span><span class='line'>    sock-&gt;sk    =    sk;
</span><span class='line'>} else
</span><span class='line'>    sk-&gt;sk_sleep    =    NULL;
</span><span class='line'>
</span><span class='line'>rwlock_init(&amp;sk-&gt;sk_dst_lock);
</span><span class='line'>rwlock_init(&amp;sk-&gt;sk_callback_lock);
</span><span class='line'>lockdep_set_class(&amp;sk-&gt;sk_callback_lock,
</span><span class='line'>        af_callback_keys + sk-&gt;sk_family);
</span><span class='line'>
</span><span class='line'>sk-&gt;sk_state_change    =    sock_def_wakeup;
</span><span class='line'>sk-&gt;sk_data_ready    =    sock_def_readable;
</span><span class='line'>sk-&gt;sk_write_space    =    sock_def_write_space;
</span><span class='line'>sk-&gt;sk_error_report    =    sock_def_error_report;
</span><span class='line'>sk-&gt;sk_destruct        =    sock_def_destruct;
</span><span class='line'>
</span><span class='line'>sk-&gt;sk_sndmsg_page    =    NULL;
</span><span class='line'>sk-&gt;sk_sndmsg_off    =    0;
</span><span class='line'>
</span><span class='line'>sk-&gt;sk_peercred.pid     =    0;
</span><span class='line'>sk-&gt;sk_peercred.uid    =    -1;
</span><span class='line'>sk-&gt;sk_peercred.gid    =    -1;
</span><span class='line'>sk-&gt;sk_write_pending    =    0;
</span><span class='line'>sk-&gt;sk_rcvlowat        =    1;
</span><span class='line'>sk-&gt;sk_rcvtimeo        =    MAX_SCHEDULE_TIMEOUT;
</span><span class='line'>sk-&gt;sk_sndtimeo        =    MAX_SCHEDULE_TIMEOUT;
</span><span class='line'>
</span><span class='line'>sk-&gt;sk_stamp.tv_sec = -1L;
</span><span class='line'>sk-&gt;sk_stamp.tv_usec = -1L;
</span><span class='line'>
</span><span class='line'>atomic_set(&amp;sk-&gt;sk_refcnt, 1);
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;```&lt;/p&gt;
</span><span class='line'>]]&gt;&lt;/content&gt;
</span><span class='line'>  &lt;/entry&gt;
</span><span class='line'>  
</span><span class='line'>  &lt;entry&gt;
</span><span class='line'>&lt;title type="html"&gt;&lt;![CDATA[socket绑定连接 sys_bind]]&gt;&lt;/title&gt;
</span><span class='line'>&lt;link href="http://abcdxyzk.github.io/blog/2015/06/09/kernel-net-bind/"/&gt;
</span><span class='line'>&lt;updated&gt;2015-06-09T17:41:00+08:00&lt;/updated&gt;
</span><span class='line'>&lt;id&gt;http://abcdxyzk.github.io/blog/2015/06/09/kernel-net-bind&lt;/id&gt;
</span><span class='line'>&lt;content type="html"&gt;&lt;![CDATA[&lt;p&gt;&lt;a href="http://blog.csdn.net/justlinux2010/article/details/8593539"&gt;http://blog.csdn.net/justlinux2010/article/details/8593539&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;bind()系统调用是给套接字分配一个本地协议地址，对于网际协议，协议地址是32位IPv4地址或128位IPv6地址与16位的TCP或UDP端口号的组合。如果没有通过bind()来指定本地的协议地址，在和远端通信时，内核会随机给套接字分配一个IP地址和端口号。bind()系统调用通常是在网络程序的服务器端调用，而且是必须的。如果TCP服务器不这么做，让内核来选择临时端口号而不是捆绑众所周知的端口，客户端如何发起与服务器的连接？&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h4&gt;一、sys_bind()&lt;/h4&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  bind()系统调用对应的内核实现是sys_bind()，其源码及分析如下：&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    /* 
</span><span class='line'> *  Bind a name to a socket. Nothing much to do here since it's 
</span><span class='line'> *  the protocol's responsibility to handle the local address. 
</span><span class='line'> * 
</span><span class='line'> *  We move the socket address to kernel space before we call 
</span><span class='line'> *  the protocol layer (having also checked the address is ok). 
</span><span class='line'> */  
</span><span class='line'>
</span><span class='line'>SYSCALL_DEFINE3(bind, int, fd, struct sockaddr __user *, umyaddr, int, addrlen)  
</span><span class='line'>{  
</span><span class='line'>    struct socket *sock;  
</span><span class='line'>    struct sockaddr_storage address;  
</span><span class='line'>    int err, fput_needed;  
</span><span class='line'>
</span><span class='line'>    /* 
</span><span class='line'>     * 以fd为索引从当前进程的文件描述符表中 
</span><span class='line'>     * 找到对应的file实例，然后从file实例的private_data中 
</span><span class='line'>     * 获取socket实例。 
</span><span class='line'>     */  
</span><span class='line'>    sock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);  
</span><span class='line'>    if (sock) {  
</span><span class='line'>        /* 
</span><span class='line'>         * 将用户空间的地址拷贝到内核空间的缓冲区中。 
</span><span class='line'>         */  
</span><span class='line'>        err = move_addr_to_kernel(umyaddr, addrlen, (struct sockaddr *)&amp;address);  
</span><span class='line'>        if (err &gt;= 0) {  
</span><span class='line'>            /* 
</span><span class='line'>             * SELinux相关，不需要关心。 
</span><span class='line'>             */  
</span><span class='line'>            err = security_socket_bind(sock,  
</span><span class='line'>                           (struct sockaddr *)&amp;address,  
</span><span class='line'>                           addrlen);  
</span><span class='line'>            /* 
</span><span class='line'>             * 如果是TCP套接字，sock-&gt;ops指向的是inet_stream_ops， 
</span><span class='line'>             * sock-&gt;ops是在inet_create()函数中初始化，所以bind接口 
</span><span class='line'>             * 调用的是inet_bind()函数。 
</span><span class='line'>             */  
</span><span class='line'>            if (!err)  
</span><span class='line'>                err = sock-&gt;ops-&gt;bind(sock,  
</span><span class='line'>                              (struct sockaddr *)  
</span><span class='line'>                              &amp;address, addrlen);  
</span><span class='line'>        }  
</span><span class='line'>        fput_light(sock-&gt;file, fput_needed);  
</span><span class='line'>    }  
</span><span class='line'>    return err;  
</span><span class='line'>}  
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;  sys_bind()的代码流程如下图所示：
</span><span class='line'>&lt;code&gt;
</span><span class='line'>    sys_bind()
</span><span class='line'>        |
</span><span class='line'>        |----&gt; sockfd_loockup_light()
</span><span class='line'>        |
</span><span class='line'>        |----&gt; move_addr_to_kernel()
</span><span class='line'>        |
</span><span class='line'>         ----&gt; inet_bind()
</span><span class='line'>&lt;/code&gt;
</span><span class='line'>  sys_bind()首先调用sockfd_lookup_light()查找套接字对应的socket实例，如果没有找到，则返回EBADF错误。在进行绑定操作之前，要先将用户传入的本地协议地址从用户空间拷贝到内核缓冲区中，在拷贝过程中会检查用户传入的地址是否正确。如果指定的长度参数小于0或者大于sockaddr_storage的大小，则返回EINVAL错误；如果在调用copy_from_user()执行拷贝操作过程中出现错误，则返回EFAULT错误。在上述的准备工作都完成后，调用inet_bind()函数（即sock-&gt;ops-&gt;bind指向的函数，参见注释）来完成绑定操作。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;h4&gt;二、inet_bind()&lt;/h4&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;inet_bind()比较简单，不做过多的分析，注释的已经很清楚了。代码及注释如下所示：&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    int inet_bind(struct socket *sock, struct sockaddr *uaddr, int addr_len)  
</span><span class='line'>{  
</span><span class='line'>    struct sockaddr_in *addr = (struct sockaddr_in *)uaddr;  
</span><span class='line'>    struct sock *sk = sock-&gt;sk;  
</span><span class='line'>    struct inet_sock *inet = inet_sk(sk);  
</span><span class='line'>    unsigned short snum;  
</span><span class='line'>    int chk_addr_ret;  
</span><span class='line'>    int err;  
</span><span class='line'>
</span><span class='line'>    /* If the socket has its own bind function then use it. (RAW) */  
</span><span class='line'>    /* 
</span><span class='line'>     * 如果是TCP套接字，sk-&gt;sk_prot指向的是tcp_prot，在 
</span><span class='line'>     * inet_create()中调用的sk_alloc()函数中初始化。由于 
</span><span class='line'>     * tcp_prot中没有设置bind接口，因此判断条件不成立。 
</span><span class='line'>     */  
</span><span class='line'>    if (sk-&gt;sk_prot-&gt;bind) {  
</span><span class='line'>        err = sk-&gt;sk_prot-&gt;bind(sk, uaddr, addr_len);  
</span><span class='line'>        goto out;  
</span><span class='line'>    }  
</span><span class='line'>    err = -EINVAL;  
</span><span class='line'>    if (addr_len &lt; sizeof(struct sockaddr_in))  
</span><span class='line'>        goto out;  
</span><span class='line'>
</span><span class='line'>    /* 
</span><span class='line'>     * 判断传入的地址类型。 
</span><span class='line'>     */  
</span><span class='line'>    chk_addr_ret = inet_addr_type(sock_net(sk), addr-&gt;sin_addr.s_addr);  
</span><span class='line'>
</span><span class='line'>    /* Not specified by any standard per-se, however it breaks too 
</span><span class='line'>     * many applications when removed.  It is unfortunate since 
</span><span class='line'>     * allowing applications to make a non-local bind solves 
</span><span class='line'>     * several problems with systems using dynamic addressing. 
</span><span class='line'>     * (ie. your servers still start up even if your ISDN link 
</span><span class='line'>     *  is temporarily down) 
</span><span class='line'>     */  
</span><span class='line'>    err = -EADDRNOTAVAIL;  
</span><span class='line'>    /* 
</span><span class='line'>     * 如果系统不支持绑定本地地址，或者 
</span><span class='line'>     * 传入的地址类型有误，则返回EADDRNOTAVAIL 
</span><span class='line'>     * 错误。 
</span><span class='line'>     */  
</span><span class='line'>    if (!sysctl_ip_nonlocal_bind &amp;&amp;  
</span><span class='line'>        !(inet-&gt;freebind || inet-&gt;transparent) &amp;&amp;  
</span><span class='line'>        addr-&gt;sin_addr.s_addr != htonl(INADDR_ANY) &amp;&amp;  
</span><span class='line'>        chk_addr_ret != RTN_LOCAL &amp;&amp;  
</span><span class='line'>        chk_addr_ret != RTN_MULTICAST &amp;&amp;  
</span><span class='line'>        chk_addr_ret != RTN_BROADCAST)  
</span><span class='line'>        goto out;  
</span><span class='line'>
</span><span class='line'>    snum = ntohs(addr-&gt;sin_port);  
</span><span class='line'>    err = -EACCES;  
</span><span class='line'>    /* 
</span><span class='line'>     * 如果绑定的端口号小于1024(保留端口号)，但是 
</span><span class='line'>     * 当前用户没有CAP_NET_BIND_SERVICE权限，则返回EACCESS错误。 
</span><span class='line'>     */  
</span><span class='line'>    if (snum &amp;&amp; snum &lt; PROT_SOCK &amp;&amp; !capable(CAP_NET_BIND_SERVICE))  
</span><span class='line'>        goto out;  
</span><span class='line'>
</span><span class='line'>    /*      We keep a pair of addresses. rcv_saddr is the one 
</span><span class='line'>     *      used by hash lookups, and saddr is used for transmit. 
</span><span class='line'>     * 
</span><span class='line'>     *      In the BSD API these are the same except where it 
</span><span class='line'>     *      would be illegal to use them (multicast/broadcast) in 
</span><span class='line'>     *      which case the sending device address is used. 
</span><span class='line'>     */  
</span><span class='line'>    lock_sock(sk);  
</span><span class='line'>
</span><span class='line'>    /* Check these errors (active socket, double bind). */  
</span><span class='line'>    err = -EINVAL;  
</span><span class='line'>    /* 
</span><span class='line'>     * 如果套接字状态不是TCP_CLOSE(套接字的初始状态，参见 
</span><span class='line'>     * sock_init_data()函数)，或者已经绑定过，则返回EINVAL错误。 
</span><span class='line'>     */  
</span><span class='line'>    if (sk-&gt;sk_state != TCP_CLOSE || inet-&gt;num)  
</span><span class='line'>        goto out_release_sock;  
</span><span class='line'>
</span><span class='line'>    inet-&gt;rcv_saddr = inet-&gt;saddr = addr-&gt;sin_addr.s_addr;  
</span><span class='line'>    if (chk_addr_ret == RTN_MULTICAST || chk_addr_ret == RTN_BROADCAST)  
</span><span class='line'>        inet-&gt;saddr = 0;  /* Use device */  
</span><span class='line'>
</span><span class='line'>    /* Make sure we are allowed to bind here. */  
</span><span class='line'>    /* 
</span><span class='line'>     * 这里实际调用的是inet_csk_get_port()函数。 
</span><span class='line'>     * 检查要绑定的端口号是否已经使用，如果已经使用， 
</span><span class='line'>     * 则检查是否允许复用。如果检查失败，则返回 
</span><span class='line'>     * EADDRINUSE错误。 
</span><span class='line'>     */  
</span><span class='line'>    if (sk-&gt;sk_prot-&gt;get_port(sk, snum)) {  
</span><span class='line'>        inet-&gt;saddr = inet-&gt;rcv_saddr = 0;  
</span><span class='line'>        err = -EADDRINUSE;  
</span><span class='line'>        goto out_release_sock;  
</span><span class='line'>    }  
</span><span class='line'>
</span><span class='line'>    /* 
</span><span class='line'>     * rcv_saddr存储的是已绑定的本地地址，接收数据时使用。 
</span><span class='line'>     * 如果已绑定的地址不为0，则设置SOCK_BINDADDR_LOCK标志， 
</span><span class='line'>     * 表示已绑定本地地址。 
</span><span class='line'>     */  
</span><span class='line'>    if (inet-&gt;rcv_saddr)  
</span><span class='line'>        sk-&gt;sk_userlocks |= SOCK_BINDADDR_LOCK;  
</span><span class='line'>    /* 
</span><span class='line'>     * 如果绑定的端口号不为0，则设置SOCK_BINDPORT_LOCK标志， 
</span><span class='line'>     * 表示已绑定本地端口号。 
</span><span class='line'>     */  
</span><span class='line'>    if (snum)  
</span><span class='line'>        sk-&gt;sk_userlocks |= SOCK_BINDPORT_LOCK;  
</span><span class='line'>    inet-&gt;sport = htons(inet-&gt;num);  
</span><span class='line'>    inet-&gt;daddr = 0;  
</span><span class='line'>    inet-&gt;dport = 0;  
</span><span class='line'>    /* 
</span><span class='line'>     * 重新初始化目的路由缓存项，如果之前已设置，则 
</span><span class='line'>     * 调用dst_release()释放老的路由缓存项。 
</span><span class='line'>     */  
</span><span class='line'>    sk_dst_reset(sk);  
</span><span class='line'>    err = 0;  
</span><span class='line'>out_release_sock:  
</span><span class='line'>    release_sock(sk);  
</span><span class='line'>out:  
</span><span class='line'>    return err;  
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>]]&gt;&lt;/content&gt;
</span><span class='line'>  &lt;/entry&gt;
</span><span class='line'>  
</span><span class='line'>  &lt;entry&gt;
</span><span class='line'>&lt;title type="html"&gt;&lt;![CDATA[socket接收连接 sys_accept]]&gt;&lt;/title&gt;
</span><span class='line'>&lt;link href="http://abcdxyzk.github.io/blog/2015/06/09/kernel-net-accept/"/&gt;
</span><span class='line'>&lt;updated&gt;2015-06-09T17:10:00+08:00&lt;/updated&gt;
</span><span class='line'>&lt;id&gt;http://abcdxyzk.github.io/blog/2015/06/09/kernel-net-accept&lt;/id&gt;
</span><span class='line'>&lt;content type="html"&gt;&lt;![CDATA[&lt;p&gt;&lt;a href="http://linux.chinaunix.net/techdoc/net/"&gt;http://linux.chinaunix.net/techdoc/net/&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;&lt;a href="http://linux.chinaunix.net/techdoc/net/2008/12/30/1055672.shtml"&gt;http://linux.chinaunix.net/techdoc/net/2008/12/30/1055672.shtml&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;这一节我们开始分析如何接收TCP的socket的连接请求，象以前的分析章节一样我们先看练习中的用户界面
</span><span class='line'>&lt;code&gt;
</span><span class='line'>accept(server_sockfd, （struct sockaddr *)&amp;client_address, client_len);
</span><span class='line'>&lt;/code&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;还是以前的分析方法，这里要注意第二个参数，client_address，它是在我们的测试程序中另外声明用于保存客户端socket地址的数据结构变量。其他二个参数无需多说。还是按照以前的方式我们直接看sys_socketcall()函数的代码部分
</span><span class='line'>&lt;code&gt;
</span><span class='line'>case SYS_ACCEPT:
</span><span class='line'>    err = sys_accept(a0, (struct sockaddr __user *)a1,
</span><span class='line'>         (int __user *)a[2]);
</span><span class='line'>    break;
</span><span class='line'>&lt;/code&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;显然是进入sys_accept()这个函数
</span><span class='line'>&lt;code&gt;
</span><span class='line'>sys_socketcall()--&gt;sys_accept()
</span><span class='line'>asmlinkage long sys_accept(int fd, struct sockaddr __user *upeer_sockaddr,
</span><span class='line'>             int __user *upeer_addrlen)
</span><span class='line'>{
</span><span class='line'>    struct socket *sock, *newsock;
</span><span class='line'>    struct file *newfile;
</span><span class='line'>    int err, len, newfd, fput_needed;
</span><span class='line'>    char address[MAX_SOCK_ADDR];
</span><span class='line'>    sock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);
</span><span class='line'>    if (!sock)
</span><span class='line'>        goto out;
</span><span class='line'>    err = -ENFILE;
</span><span class='line'>    if (!(newsock = sock_alloc()))
</span><span class='line'>        goto out_put;
</span><span class='line'>    newsock-&gt;type = sock-&gt;type;
</span><span class='line'>    newsock-&gt;ops = sock-&gt;ops;
</span><span class='line'>    /*
</span><span class='line'>     * We don't need try_module_get here, as the listening socket (sock)
</span><span class='line'>     * has the protocol module (sock-&gt;ops-&gt;owner) held.qinjian
</span><span class='line'>     */
</span><span class='line'>    __module_get(newsock-&gt;ops-&gt;owner);
</span><span class='line'>    newfd = sock_alloc_fd(&amp;newfile);
</span><span class='line'>    if (unlikely(newfd  0)) {
</span><span class='line'>        err = newfd;
</span><span class='line'>        sock_release(newsock);
</span><span class='line'>        goto out_put;
</span><span class='line'>    }
</span><span class='line'>    err = sock_attach_fd(newsock, newfile);
</span><span class='line'>    if (err  0)
</span><span class='line'>        goto out_fd_simple;
</span><span class='line'>    err = security_socket_accept(sock, newsock);
</span><span class='line'>    if (err)
</span><span class='line'>        goto out_fd;
</span><span class='line'>    err = sock-&gt;ops-&gt;accept(sock, newsock, sock-&gt;file-&gt;f_flags);
</span><span class='line'>    if (err  0)
</span><span class='line'>        goto out_fd;
</span><span class='line'>    if (upeer_sockaddr) {
</span><span class='line'>        if (newsock-&gt;ops-&gt;getname(newsock, (struct sockaddr *)address,
</span><span class='line'>                     &amp;len, 2)  0) {
</span><span class='line'>            err = -ECONNABORTED;
</span><span class='line'>            goto out_fd;
</span><span class='line'>        }
</span><span class='line'>        err = move_addr_to_user(address, len, upeer_sockaddr,
</span><span class='line'>                    upeer_addrlen);
</span><span class='line'>        if (err  0)
</span><span class='line'>            goto out_fd;
</span><span class='line'>    }
</span><span class='line'>    /* File flags are not inherited via accept() unlike another OSes.QJ */
</span><span class='line'>    fd_install(newfd, newfile);
</span><span class='line'>    err = newfd;
</span><span class='line'>    security_socket_post_accept(sock, newsock);
</span><span class='line'>out_put:
</span><span class='line'>    fput_light(sock-&gt;file, fput_needed);
</span><span class='line'>out:
</span><span class='line'>    return err;
</span><span class='line'>out_fd_simple:
</span><span class='line'>    sock_release(newsock);
</span><span class='line'>    put_filp(newfile);
</span><span class='line'>    put_unused_fd(newfd);
</span><span class='line'>    goto out_put;
</span><span class='line'>out_fd:
</span><span class='line'>    fput(newfile);
</span><span class='line'>    put_unused_fd(newfd);
</span><span class='line'>    goto out_put;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;
</span><span class='line'>这个函数总的作用就是使服务端的socket能够创建与客户端连接的“子连接”，也就是会利用服务器端的socket创建一个新的能与客户端建立连接的socket，而且会把新连接的socket的id号，返回到我们测试程序中的client_sockfd，同时也把客户端的socket地址保存在client_address中，函数中首先会进入sockfd_lookup_light（）中找到我们服务器端的socket，这个函数前面章节中用到多次了不再进入细细分析了，接着函数中调用sock_alloc（）函数创建一个新的socket,此后为这个新创建的socket分配一个可用的文件号，然后能过sock_attach_fd使其与文件号挂钩。最重要的当属这句代码&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    err = sock-&gt;ops-&gt;accept(sock, newsock, sock-&gt;file-&gt;f_flags);
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;这部分开始入手分析TCP的socket是如何执行的，这里会进入inet_stream_ops中执行，可能有些朋友是直接阅读本文的，最好是看一下前面的章节理清是如何进入这个函数的，我们这里不再重复了。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    const struct proto_ops inet_stream_ops = {
</span><span class='line'>    。。。。。。
</span><span class='line'>    .accept         = inet_accept,
</span><span class='line'>    。。。。。。
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;我们再次看一下af_inet.c中的这个数据结构，很显然进入了inet_accept()函数
</span><span class='line'>&lt;code&gt;
</span><span class='line'>sys_socketcall()--&gt;sys_accept()--&gt;inet_accept()
</span><span class='line'>int inet_accept(struct socket *sock, struct socket *newsock, int flags)
</span><span class='line'>{
</span><span class='line'>    struct sock *sk1 = sock-&gt;sk;
</span><span class='line'>    int err = -EINVAL;
</span><span class='line'>    struct sock *sk2 = sk1-&gt;sk_prot-&gt;accept(sk1, flags, &amp;err);
</span><span class='line'>    if (!sk2)
</span><span class='line'>        goto do_err;
</span><span class='line'>    lock_sock(sk2);
</span><span class='line'>    BUG_TRAP((1  sk2-&gt;sk_state) &amp;
</span><span class='line'>         (TCPF_ESTABLISHED | TCPF_CLOSE_WAIT | TCPF_CLOSE));
</span><span class='line'>    sock_graft(sk2, newsock);
</span><span class='line'>    newsock-&gt;state = SS_CONNECTED;
</span><span class='line'>    err = 0;
</span><span class='line'>    release_sock(sk2);
</span><span class='line'>do_err:
</span><span class='line'>    return err;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;进入这个函数的时候已经找到了我们前面建立的socket结构，而newsock是我们新分配建立的socket结构，我们看到上面函数中执行了&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    struct sock *sk2 = sk1-&gt;sk_prot-&gt;accept(sk1, flags, &amp;err);
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;进而进入了钩子函数中执行，那里的struct proto tcp_prot结构变量可以看到
</span><span class='line'>&lt;code&gt;
</span><span class='line'>struct proto tcp_prot = {
</span><span class='line'>    。。。。。。
</span><span class='line'>    .accept            = inet_csk_accept,
</span><span class='line'>    。。。。。。
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;
</span><span class='line'>很显然是执行的inet_csk_accept（）函数
</span><span class='line'>&lt;code&gt;
</span><span class='line'>sys_socketcall()--&gt;sys_accept()--&gt;inet_accept()--&gt;inet_csk_accept()
</span><span class='line'>struct sock *inet_csk_accept(struct sock *sk, int flags, int *err)
</span><span class='line'>{
</span><span class='line'>    struct inet_connection_sock *icsk = inet_csk(sk);
</span><span class='line'>    struct sock *newsk;
</span><span class='line'>    int error;
</span><span class='line'>    lock_sock(sk);
</span><span class='line'>    /* We need to make sure that this socket is listening,
</span><span class='line'>     * and that it has something pending.qinjian
</span><span class='line'>     */
</span><span class='line'>    error = -EINVAL;
</span><span class='line'>    if (sk-&gt;sk_state != TCP_LISTEN)
</span><span class='line'>        goto out_err;
</span><span class='line'>    /* Find already established connection */
</span><span class='line'>    if (reqsk_queue_empty(&amp;icsk-&gt;icsk_accept_queue)) {
</span><span class='line'>        long timeo = sock_rcvtimeo(sk, flags &amp; O_NONBLOCK);
</span><span class='line'>        /* If this is a non blocking socket don't sleep */
</span><span class='line'>        error = -EAGAIN;
</span><span class='line'>        if (!timeo)
</span><span class='line'>            goto out_err;
</span><span class='line'>        error = inet_csk_wait_for_connect(sk, timeo);
</span><span class='line'>        if (error)
</span><span class='line'>            goto out_err;
</span><span class='line'>    }
</span><span class='line'>    newsk = reqsk_queue_get_child(&amp;icsk-&gt;icsk_accept_queue, sk);
</span><span class='line'>    BUG_TRAP(newsk-&gt;sk_state != TCP_SYN_RECV);
</span><span class='line'>out:
</span><span class='line'>    release_sock(sk);
</span><span class='line'>    return newsk;
</span><span class='line'>out_err:
</span><span class='line'>    newsk = NULL;
</span><span class='line'>    *err = error;
</span><span class='line'>    goto out;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;象往常叙述的一样首先是在sock中取得struct inet_connection_sock结构,然后判断一下sock的状态是否已经处于监听状态，如果没有处于监听状态的话就不能接收了，只好出错返回了。接着是检查icsk中的icsk_accept_queue请求队列是否为空，因为我们练习中还未启动客户端程序，所以此时还没有连接请求到来，这个队列现在是空的，所以进入if语句，sock_rcvtimeo（）是根据是否允许“阻塞”即等待，而取得sock结构中的sk_rcvtimeo时间值，然后根据这个值进入inet_csk_wait_for_connect（）函数中&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    sys_socketcall()--&gt;sys_accept()--&gt;inet_accept()--&gt;inet_csk_accept()--&gt;inet_csk_wait_for_connect()
</span><span class='line'>static int inet_csk_wait_for_connect(struct sock *sk, long timeo)
</span><span class='line'>{
</span><span class='line'>    struct inet_connection_sock *icsk = inet_csk(sk);
</span><span class='line'>    DEFINE_WAIT(wait);
</span><span class='line'>    int err;
</span><span class='line'>    /*
</span><span class='line'>     * True wake-one mechanism for incoming connections: only
</span><span class='line'>     * one process gets woken up, not the 'whole herd'.
</span><span class='line'>     * Since we do not 'race &amp; poll' for established sockets
</span><span class='line'>     * anymore, the common case will execute the loop only once.
</span><span class='line'>     *
</span><span class='line'>     * Subtle issue: "add_wait_queue_exclusive()" will be added
</span><span class='line'>     * after any current non-exclusive waiters, and we know that
</span><span class='line'>     * it will always _stay_ after any new non-exclusive waiters
</span><span class='line'>     * because all non-exclusive waiters are added at the
</span><span class='line'>     * beginning of the wait-queue. As such, it's ok to "drop"
</span><span class='line'>     * our exclusiveness temporarily when we get woken up without
</span><span class='line'>     * having to remove and re-insert us on the wait queue.wumingxiaozu
</span><span class='line'>     */
</span><span class='line'>    for (;;) {
</span><span class='line'>        prepare_to_wait_exclusive(sk-&gt;sk_sleep, &amp;wait,
</span><span class='line'>                     TASK_INTERRUPTIBLE);
</span><span class='line'>        release_sock(sk);
</span><span class='line'>        if (reqsk_queue_empty(&amp;icsk-&gt;icsk_accept_queue))
</span><span class='line'>            timeo = schedule_timeout(timeo);
</span><span class='line'>        lock_sock(sk);
</span><span class='line'>        err = 0;
</span><span class='line'>        if (!reqsk_queue_empty(&amp;icsk-&gt;icsk_accept_queue))
</span><span class='line'>            break;
</span><span class='line'>        err = -EINVAL;
</span><span class='line'>        if (sk-&gt;sk_state != TCP_LISTEN)
</span><span class='line'>            break;
</span><span class='line'>        err = sock_intr_errno(timeo);
</span><span class='line'>        if (signal_pending(current))
</span><span class='line'>            break;
</span><span class='line'>        err = -EAGAIN;
</span><span class='line'>        if (!timeo)
</span><span class='line'>            break;
</span><span class='line'>    }
</span><span class='line'>    finish_wait(sk-&gt;sk_sleep, &amp;wait);
</span><span class='line'>    return err;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;函数首先是调用了宏来声明一个等待队列
</span><span class='line'>&lt;code&gt;
</span><span class='line'>#define DEFINE_WAIT(name)                                \
</span><span class='line'>wait_queue_t name = {                                    \
</span><span class='line'>    .private      = current,                             \
</span><span class='line'>    .func         = autoremove_wake_function,            \
</span><span class='line'>    .task_list    = LIST_HEAD_INIT((name).task_list),    \
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;
</span><span class='line'>关于等待队列的具体概念我们留在以后专门的章节中论述，这里可以看出是根据当前进程而建立的名为wait的等待队列，接着函数中调用了&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    sys_socketcall()--&gt;sys_accept()--&gt;inet_accept()--&gt;inet_csk_accept()--&gt;inet_csk_wait_for_connect()--&gt;prepare_to_wait_exclusive()
</span><span class='line'>void
</span><span class='line'>prepare_to_wait_exclusive(wait_queue_head_t *q, wait_queue_t *wait, int state)
</span><span class='line'>{
</span><span class='line'>    unsigned long flags;
</span><span class='line'>    wait-&gt;flags |= WQ_FLAG_EXCLUSIVE;
</span><span class='line'>    spin_lock_irqsave(&amp;q-&gt;lock, flags);
</span><span class='line'>    if (list_empty(&amp;wait-&gt;task_list))
</span><span class='line'>        __add_wait_queue_tail(q, wait);
</span><span class='line'>    /*
</span><span class='line'>     * don't alter the task state if this is just going to
</span><span class='line'>      * queue an async wait queue callback wumingxiaozu
</span><span class='line'>     */
</span><span class='line'>    if (is_sync_wait(wait))
</span><span class='line'>        set_current_state(state);
</span><span class='line'>    spin_unlock_irqrestore(&amp;q-&gt;lock, flags);
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;接着要把这里创建的wait，即当前进程的这里的等待队列挂入sk中的sk_sleep队列，这样我们可以理解到多个进程都可以对一个socket并发的连接，这个函数与我们所说的等待队列部分内容是密切相关的，我们只简单的叙述一下，函数中主要是将我们上面建立的等待队列插入到这里的sock结构中的sk_sleep所指定的等待队列头中，此后再次调用reqsk_queue_empty（）函数检查一下icsk_accept_queue是否为空，如果还为空就说明没有连接请求到来，开始睡眠等待了，schedule_timeout（）这个函数与时钟密切相关，所以请朋友们参考其他资料，这里是根据我们上面得到的定时时间来进入睡眠的。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;当从这个函数返回时，再次锁住sock防止其他进程打扰，然后这里还是判断一下icsk_accept_queue是否为空，如果还为空的话就要跳出for循环了，醒来后还要检查一下是否是因为信号而醒来的，如果有信号就要处理信号signal_pending（），最后如果睡眠的时间已经用完了也会跳出循环，跳出循环后就要将这里的等待队列从sock中的sk_sleep中摘链。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;我们回到inet_csk_accept（）函数中继续往下看，如果这时队列icsk_accept_queue不为空，即有连接请求到来怎么办呢，继续看下面的代码&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    newsk = reqsk_queue_get_child(&amp;icsk-&gt;icsk_accept_queue, sk);
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;这里看到是进入了reqsk_queue_get_child函数中&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    sys_socketcall()--&gt;sys_accept()--&gt;inet_accept()--&gt;inet_csk_accept()--&gt;reqsk_queue_get_child()
</span><span class='line'>static inline struct sock *reqsk_queue_get_child(struct request_sock_queue *queue,
</span><span class='line'>                         struct sock *parent)
</span><span class='line'>{
</span><span class='line'>    struct request_sock *req = reqsk_queue_remove(queue);
</span><span class='line'>    struct sock *child = req-&gt;sk;
</span><span class='line'>    BUG_TRAP(child != NULL);
</span><span class='line'>    sk_acceptq_removed(parent);
</span><span class='line'>    __reqsk_free(req);
</span><span class='line'>    return child;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;函数中首先是调用了reqsk_queue_remove（）从队列中摘下一个已经到来的request_sock结构&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    sys_socketcall()--&gt;sys_accept()--&gt;inet_accept()--&gt;inet_csk_accept()--&gt;reqsk_queue_get_child()--&gt;reqsk_queue_remove()
</span><span class='line'>static inline struct request_sock *reqsk_queue_remove(struct request_sock_queue *queue)
</span><span class='line'>{
</span><span class='line'>    struct request_sock *req = queue-&gt;rskq_accept_head;
</span><span class='line'>    BUG_TRAP(req != NULL);
</span><span class='line'>    queue-&gt;rskq_accept_head = req-&gt;dl_next;
</span><span class='line'>    if (queue-&gt;rskq_accept_head == NULL)
</span><span class='line'>        queue-&gt;rskq_accept_tail = NULL;
</span><span class='line'>    return req;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;很明显上面函数中是从队列的rskq_accept_head摘下一个已经到来的request_sock这个结构是从客户端请求连接时挂入的，reqsk_queue_get_child（）函数在这里把request_sock中载运的sock结构返回到inet_csk_accept中的局部变量newsk使用。而sk_acceptq_removed是递减我们服务器端sock中的sk_ack_backlog。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;然后__reqsk_free释放掉request_sock结构。回到inet_csk_accept函数中，然后返回我们间接从icsk-&gt;icsk_accept_queue队列中获得了与客户端密切相关的sock结构。这个与客户端密切相关的结构是由我们服务器端在响应底层驱动的数据包过程中建立的，我们将在后边讲解完客户端的连接请求把这一过程补上，这里假设我们已经接收到了客户端的数据包并且服务器端为此专门建了这个与客户端数据包相联系的sock结构，接着返回到inet_accept()函数中，接着调用sock_graft（）函数，注意参数sock_graft(sk2, newsock);sk2是我们上边叙述的与客户端密切相关的sock结构，是从接收队列中获得的。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;而newsock，则是我们服务器端为了这个代表客户端的sock结构而准备的新的socket。我们以前说过，socket结构在具体应用上分为二部分，另一部分是这里的sock结构，因为sock是与具体的协议即以前所说的规程的相关，所以变化比较大，而socket比较通用，所以我们上面通过socket_alloc()只是分配了通用部分的socket结构，并没有建立对应协议的sock结构，那么我们分配的新的socket的所需要的sock是从哪里来的呢，我们可以在代码中看到他是取的代表客户端的sock结构，与我们新建的socket挂入的，看一下这个关键的函数&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    sys_socketcall()--&gt;sys_accept()--&gt;inet_accept()--&gt;sock_graft()
</span><span class='line'>static inline void sock_graft(struct sock *sk, struct socket *parent)
</span><span class='line'>{
</span><span class='line'>    write_lock_bh(&amp;sk-&gt;sk_callback_lock);
</span><span class='line'>    sk-&gt;sk_sleep = &amp;parent-&gt;wait;
</span><span class='line'>    parent-&gt;sk = sk;
</span><span class='line'>    sk-&gt;sk_socket = parent;
</span><span class='line'>    security_sock_graft(sk, parent);
</span><span class='line'>    write_unlock_bh(&amp;sk-&gt;sk_callback_lock);
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;上面传递的参数是
</span><span class='line'>&lt;code&gt;
</span><span class='line'>sock_graft(sk2, newsock);
</span><span class='line'>&lt;/code&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;sk2是代表我们客户端的sock，newsock是我们服务器端的新socket，可以看出上面的sock_graft,graft是嫁接的意思，从函数面上就可以理解了，然后其内部就是将服务器端新建的socket与客户端的sock“挂钩了”，从此以后，这个socket就是服务器端与客户端通讯的桥梁了。这样回到上面的inet_accept函数时，我们看到将newsock-&gt;state = SS_CONNECTED;也就是状态改变成了连接状态，而以前的服务器的socket并没有任何的状态改变，那个socket继续覆行他的使命“孵化”新的socket。回到我们的sys_accept()函数中下面接着看，我们在练习中看到需要获得客户端的地址，在那个章节中我们又走到了&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    newsock-&gt;ops-&gt;getname(newsock, (struct sockaddr )address, &amp;len, 2)
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;这要看我们在sys_accpet()函数中新创建的newsock的ops钩子结构了，很明显我们在sys_accept()函数中看到了newsock-&gt;ops = sock-&gt;ops;所以newsock是使用的已经建立的服务器端的inet_stream_ops结构变量，我们可以在这个结构中看到
</span><span class='line'>&lt;code&gt;
</span><span class='line'>const struct proto_ops inet_stream_ops = {
</span><span class='line'>    。。。。。。
</span><span class='line'>    .getname     = inet_getname,
</span><span class='line'>    。。。。。。
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;因此进入了inet_getname()函数，这个函数在/net/ipv4/af_inet.c中的683行处。
</span><span class='line'>&lt;code&gt;
</span><span class='line'>sys_accept()--&gt;inet_getname()
</span><span class='line'>int inet_getname(struct socket *sock, struct sockaddr *uaddr,
</span><span class='line'>            int *uaddr_len, int peer)
</span><span class='line'>{
</span><span class='line'>    struct sock *sk        = sock-&gt;sk;
</span><span class='line'>    struct inet_sock *inet    = inet_sk(sk);
</span><span class='line'>    struct sockaddr_in *sin    = (struct sockaddr_in *)uaddr;
</span><span class='line'>    sin-&gt;sin_family = AF_INET;
</span><span class='line'>    if (peer) {
</span><span class='line'>        if (!inet-&gt;dport ||
</span><span class='line'>         (((1  sk-&gt;sk_state) &amp; (TCPF_CLOSE | TCPF_SYN_SENT)) &amp;&amp;
</span><span class='line'>         peer == 1))
</span><span class='line'>            return -ENOTCONN;
</span><span class='line'>        sin-&gt;sin_port = inet-&gt;dport;
</span><span class='line'>        sin-&gt;sin_addr.s_addr = inet-&gt;daddr;
</span><span class='line'>    } else {
</span><span class='line'>        __be32 addr = inet-&gt;rcv_saddr;
</span><span class='line'>        if (!addr)
</span><span class='line'>            addr = inet-&gt;saddr;
</span><span class='line'>        sin-&gt;sin_port = inet-&gt;sport;
</span><span class='line'>        sin-&gt;sin_addr.s_addr = addr;
</span><span class='line'>    }
</span><span class='line'>    memset(sin-&gt;sin_zero, 0, sizeof(sin-&gt;sin_zero));
</span><span class='line'>    *uaddr_len = sizeof(*sin);
</span><span class='line'>    return 0;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;在上面的代码中，关键的是这二句&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    sin-&gt;sin_port = inet-&gt;dport;
</span><span class='line'>sin-&gt;sin_addr.s_addr = inet-&gt;daddr;
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;这里直接将我们练习中的准备接收的数组address转换成tcp的地址结构struct sockaddr_in指针，然后直接用上面二句赋值了，我们看到他是使用的我们刚刚提到的从icsk-&gt;icsk_accept_queue接收队列中得到的sock进而得到了inet_sock专用于INET的sock结构&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    struct inet_sock {
</span><span class='line'>    /* sk and pinet6 has to be the first two members of inet_sock */
</span><span class='line'>    struct sock        sk;
</span><span class='line'>#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
</span><span class='line'>    struct ipv6_pinfo    *pinet6;
</span><span class='line'>#endif
</span><span class='line'>    /* Socket demultiplex comparisons on incoming packets.wumingxiaozu */
</span><span class='line'>    __be32               daddr;
</span><span class='line'>    __be32               rcv_saddr;
</span><span class='line'>    __be16               dport;
</span><span class='line'>    __u16                num;
</span><span class='line'>    __be32               saddr;
</span><span class='line'>    __s16                uc_ttl;
</span><span class='line'>    __u16                cmsg_flags;
</span><span class='line'>    struct ip_options    *opt;
</span><span class='line'>    __be16               sport;
</span><span class='line'>    __u16                id;
</span><span class='line'>    __u8                 tos;
</span><span class='line'>    __u8                 mc_ttl;
</span><span class='line'>    __u8                 pmtudisc;
</span><span class='line'>    __u8                 recverr:1,
</span><span class='line'>                         is_icsk:1,
</span><span class='line'>                         freebind:1,
</span><span class='line'>                         hdrincl:1,
</span><span class='line'>                         mc_loop:1;
</span><span class='line'>    int                  mc_index;
</span><span class='line'>    __be32               mc_addr;
</span><span class='line'>    struct ip_mc_socklist    *mc_list;
</span><span class='line'>    struct {
</span><span class='line'>        unsigned int        flags;
</span><span class='line'>        unsigned int        fragsize;
</span><span class='line'>        struct ip_options   *opt;
</span><span class='line'>        struct dst_entry    *dst;
</span><span class='line'>        int                 length; /* Total length of all frames */
</span><span class='line'>        __be32              addr;
</span><span class='line'>        struct flowi        fl;
</span><span class='line'>    } cork;
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;这个结构中的头一个变量就是sock结构，所以这里直接将sock的地址做为inet_sock结构的开始是完全可以的，这也就是inet_sk()这个函数的主要作用&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    sys_accept()--&gt;inet_getname()--&gt;inet_sk()
</span><span class='line'>static inline struct inet_sock *inet_sk(const struct sock *sk)
</span><span class='line'>{
</span><span class='line'>    return (struct inet_sock *)sk;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;那么可能会有朋友问我们只是从icsk-&gt;icsk_accept_queue接收队列中间接得到了sock结构指针并没有看到inet_sock结构指针啊？请朋友们相信我们在后边叙述完了客户端的连接请求过程后会把这部分给补上的，所以这里的inet_sock肯定是在服务器的底层驱动相关的部分完成的，我们将在完成客户端的连接后分析这部分的关键内容。所以我们看到这里将inet_sock结构中的请求方即客户端的端口和地址间接设置进了应用程序的地址结构变量client_address就取得了客户端的地址，这个过程是在sys_accept()中使用&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    err = move_addr_to_user(address, len, upeer_sockaddr,
</span><span class='line'>                upeer_addrlen);
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;将客户端的socket地址复制给我们的应用程序界面。我们上边已经通过inet_getname（）函数复制客户端的地址到address数组中了，这样通过move_addr_to_user()函数后，我们程序界面上client_address就得到了客户端的socket地址。接着我们看到函数执行了fd_install（）函数，即为新创建的socket分配一个文件号和file结构，有关没有详述的函数请朋友们参考深入理解LINUX内核第三版中的介绍，自己阅读暂且做为一种练习吧。 朋友们看到这里可以结合一下我们的地图，因为截止到现在我们都是围绕着地图中的服务器角度来分析的，接下来的章节我们将转换到客户端的角度来分析。&lt;/p&gt;
</span><span class='line'>]]&gt;&lt;/content&gt;
</span><span class='line'>  &lt;/entry&gt;
</span><span class='line'>  
</span><span class='line'>  &lt;entry&gt;
</span><span class='line'>&lt;title type="html"&gt;&lt;![CDATA[Receive packet steering patch详解]]&gt;&lt;/title&gt;
</span><span class='line'>&lt;link href="http://abcdxyzk.github.io/blog/2015/06/03/kernel-net-rps/"/&gt;
</span><span class='line'>&lt;updated&gt;2015-06-03T15:39:00+08:00&lt;/updated&gt;
</span><span class='line'>&lt;id&gt;http://abcdxyzk.github.io/blog/2015/06/03/kernel-net-rps&lt;/id&gt;
</span><span class='line'>&lt;content type="html"&gt;&lt;![CDATA[&lt;p&gt;&lt;a href="http://simohayha.iteye.com/blog/720850"&gt;http://simohayha.iteye.com/blog/720850&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;Receive packet steering简称rps，是google贡献给linux kernel的一个patch，主要的功能是解决多核情况下，网络协议栈的软中断的负载均衡。这里的负载均衡也就是指能够将软中断均衡的放在不同的cpu核心上运行。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;简介在这里：&lt;br/&gt;
</span><span class='line'>&lt;a href="http://lwn.net/Articles/362339/"&gt;http://lwn.net/Articles/362339/&lt;/a&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;linux现在网卡的驱动支持两种模式，一种是NAPI，一种是非NAPI模式，这两种模式的区别，我前面的blog都有介绍，这里就再次简要的介绍下。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;在NAPI中，中断收到数据包后调用__napi_schedule调度软中断，然后软中断处理函数中会调用注册的poll回掉函数中调用netif_receive_skb将数据包发送到3层，没有进行任何的软中断负载均衡。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;在非NAPI中，中断收到数据包后调用netif_rx，这个函数会将数据包保存到input_pkt_queue，然后调度软中断，这里为了兼容NAPI的驱动，他的poll方法默认是process_backlog，最终这个函数会从input_pkt_queue中取得数据包然后发送到3层。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;通过比较我们可以看到，不管是NAPI还是非NAPI的话都无法做到软中断的负载均衡，因为软中断此时都是运行在在硬件中断相应的cpu上。也就是说如果始终是cpu0相应网卡的硬件中断，那么始终都是cpu0在处理软中断，而此时cpu1就被浪费了，因为无法并行的执行多个软中断。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;google的这个patch的基本原理是这样的,根据数据包的源地址，目的地址以及目的和源端口(这里它是将两个端口组合成一个4字节的无符数进行计算的，后面会看到)计算出一个hash值，然后根据这个hash值来选择软中断运行的cpu，从上层来看，也就是说将每个连接和cpu绑定，并通过这个hash值，来均衡软中断在多个cpu上。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;这个介绍比较简单，我们来看代码是如何实现的。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;它这里主要是hook了两个内核的函数，一个是netif_rx主要是针对非NAPI的驱动，一个是netif_receive_skb这个主要是针对NAPI的驱动，这两个函数我前面blog都有介绍过，想了解可以看我前面的blog，现在这里我只介绍打过patch的实现。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;在看netif_rx和netif_receive_skb之前，我们先来看这个patch中两个重要的函数get_rps_cpu和enqueue_to_backlog，我们一个个看。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;先来看相关的两个数据结构，首先是netdev_rx_queue，它表示对应的接收队列，因为有的网卡可能硬件上就支持多队列的模式，此时对应就会有多个rx队列，这个结构是挂载在net_device中的，也就是每个网络设备最终都会有一个或者多个rx队列。这个结构在sys文件系统中的表示类似这样的/sys/class/net/&lt;device&gt;/queues/rx-&lt;n&gt; 几个队列就是rx-n.
</span><span class='line'>&lt;code&gt;
</span><span class='line'>struct netdev_rx_queue {
</span><span class='line'>    // 保存了当前队列的rps map
</span><span class='line'>    struct rps_map *rps_map;
</span><span class='line'>    // 对应的kobject
</span><span class='line'>    struct kobject kobj;
</span><span class='line'>    // 指向第一个rx队列
</span><span class='line'>    struct netdev_rx_queue *first;
</span><span class='line'>    // 引用计数
</span><span class='line'>    atomic_t count;
</span><span class='line'>} ____cacheline_aligned_in_smp;
</span><span class='line'>&lt;/code&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;然后就是rps_map，其实这个也就是保存了能够执行数据包的cpu。
</span><span class='line'>&lt;code&gt;
</span><span class='line'>struct rps_map {
</span><span class='line'>    // cpu的个数，也就是cpus数组的个数
</span><span class='line'>    unsigned int len;
</span><span class='line'>    // RCU锁
</span><span class='line'>    struct rcu_head rcu;
</span><span class='line'>    // 保存了cpu的id.
</span><span class='line'>    u16 cpus[0];
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;看完上面的结构，我们来看函数的实现。
</span><span class='line'>get_rps_cpu主要是通过传递进来的skb然后来选择这个skb所应该被处理的cpu。它的逻辑很简单，就是通过skb计算hash，然后通过hash从对应的队列的rps_mapping中取得对应的cpu id。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;这里有个要注意的就是这个hash值是可以交给硬件网卡去计算的，作者自己说是最好交由硬件去计算这个hash值，因为如果是软件计算的话会导致CPU 缓存不命中，带来一定的性能开销。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;还有就是rps_mapping这个值是可以通过sys 文件系统设置的，位置在这里：
</span><span class='line'>/sys/class/net/&lt;device&gt;/queues/rx-&lt;n&gt;/rps_cpus 。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    static int get_rps_cpu(struct net_device *dev, struct sk_buff *skb)
</span><span class='line'>{
</span><span class='line'>    struct ipv6hdr *ip6;
</span><span class='line'>    struct iphdr *ip;
</span><span class='line'>    struct netdev_rx_queue *rxqueue;
</span><span class='line'>    struct rps_map *map;
</span><span class='line'>    int cpu = -1;
</span><span class='line'>    u8 ip_proto;
</span><span class='line'>    u32 addr1, addr2, ports, ihl;
</span><span class='line'>    // rcu锁
</span><span class='line'>    rcu_read_lock();
</span><span class='line'>    // 取得设备对应的rx 队列
</span><span class='line'>    if (skb_rx_queue_recorded(skb)) {
</span><span class='line'>    ..........................................
</span><span class='line'>        rxqueue = dev-&gt;_rx + index;
</span><span class='line'>    } else
</span><span class='line'>        rxqueue = dev-&gt;_rx;
</span><span class='line'>
</span><span class='line'>    if (!rxqueue-&gt;rps_map)
</span><span class='line'>        goto done;
</span><span class='line'>    // 如果硬件已经计算，则跳过计算过程
</span><span class='line'>    if (skb-&gt;rxhash)
</span><span class='line'>        goto got_hash; /* Skip hash computation on packet header */
</span><span class='line'>
</span><span class='line'>    switch (skb-&gt;protocol) {
</span><span class='line'>    case __constant_htons(ETH_P_IP):
</span><span class='line'>        if (!pskb_may_pull(skb, sizeof(*ip)))
</span><span class='line'>            goto done;
</span><span class='line'>        // 得到计算hash的几个值
</span><span class='line'>        ip = (struct iphdr *) skb-&gt;data;
</span><span class='line'>        ip_proto = ip-&gt;protocol;
</span><span class='line'>        // 两个地址
</span><span class='line'>        addr1 = ip-&gt;saddr;
</span><span class='line'>        addr2 = ip-&gt;daddr;
</span><span class='line'>        // 得到ip头
</span><span class='line'>        ihl = ip-&gt;ihl;
</span><span class='line'>        break;
</span><span class='line'>    case __constant_htons(ETH_P_IPV6):
</span><span class='line'>        ..........................................
</span><span class='line'>        break;
</span><span class='line'>    default:
</span><span class='line'>        goto done;
</span><span class='line'>    }
</span><span class='line'>    ports = 0;
</span><span class='line'>    switch (ip_proto) {
</span><span class='line'>    case IPPROTO_TCP:
</span><span class='line'>    case IPPROTO_UDP:
</span><span class='line'>    case IPPROTO_DCCP:
</span><span class='line'>    case IPPROTO_ESP:
</span><span class='line'>    case IPPROTO_AH:
</span><span class='line'>    case IPPROTO_SCTP:
</span><span class='line'>    case IPPROTO_UDPLITE:
</span><span class='line'>        if (pskb_may_pull(skb, (ihl * 4) + 4))
</span><span class='line'>        // 我们知道tcp头的前4个字节就是源和目的端口，因此这里跳过ip头得到tcp头的前4个字节
</span><span class='line'>            ports = *((u32 *) (skb-&gt;data + (ihl * 4)));
</span><span class='line'>        break;
</span><span class='line'>
</span><span class='line'>    default:
</span><span class='line'>        break;
</span><span class='line'>    }
</span><span class='line'>    // 计算hash
</span><span class='line'>    skb-&gt;rxhash = jhash_3words(addr1, addr2, ports, hashrnd);
</span><span class='line'>    if (!skb-&gt;rxhash)
</span><span class='line'>        skb-&gt;rxhash = 1;
</span><span class='line'>
</span><span class='line'>got_hash:
</span><span class='line'>    // 通过rcu得到对应rps map
</span><span class='line'>    map = rcu_dereference(rxqueue-&gt;rps_map);
</span><span class='line'>    if (map) {
</span><span class='line'>        // 取得对应的cpu
</span><span class='line'>        u16 tcpu = map-&gt;cpus[((u64) skb-&gt;rxhash * map-&gt;len) &gt;&gt; 32];
</span><span class='line'>        // 如果cpu是online的，则返回计算出的这个cpu，否则跳出循环。
</span><span class='line'>        if (cpu_online(tcpu)) {
</span><span class='line'>            cpu = tcpu;
</span><span class='line'>            goto done;
</span><span class='line'>        }
</span><span class='line'>    }
</span><span class='line'>
</span><span class='line'>done:
</span><span class='line'>    rcu_read_unlock();
</span><span class='line'>    // 如果上面失败，则返回-1.
</span><span class='line'>    return cpu;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;然后是enqueue_to_backlog这个方法，首先我们知道在每个cpu都有一个softnet结构，而他有一个input_pkt_queue的队列，以前这个主要是用于非NAPi的驱动的，而这个patch则将这个队列也用与NAPI的处理中了。也就是每个cpu现在都会有一个input_pkt_queue队列，用于保存需要处理的数据包队列。这个队列作用现在是，如果发现不属于当前cpu处理的数据包，则我们可以直接将数据包挂载到他所属的cpu的input_pkt_queue中。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;enqueue_to_backlog接受一个skb和cpu为参数，通过cpu来判断skb如何处理。要么加入所属的input_pkt_queue中，要么schecule 软中断。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;还有个要注意就是我们知道NAPI为了兼容非NAPI模式，有个backlog的napi_struct结构，也就是非NAPI驱动会schedule backlog这个napi结构，而在enqueue_to_backlog中则是利用了这个结构，也就是它会schedule backlog，因为它会将数据放到input_pkt_queue中，而backlog的pool方法process_backlog就是从input_pkt_queue中取得数据然后交给上层处理。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;这里还有一个会用到结构就是 rps_remote_softirq_cpus，它主要是保存了当前cpu上需要去另外的cpu schedule 软中断的cpu 掩码。因为我们可能将要处理的数据包放到了另外的cpu的input queue上，因此我们需要schedule 另外的cpu上的napi(也就是软中断),所以我们需要保存对应的cpu掩码，以便于后面遍历，然后schedule。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;而这里为什么mask有两个元素，注释写的很清楚：
</span><span class='line'>&lt;code&gt;
</span><span class='line'>/*
</span><span class='line'> * This structure holds the per-CPU mask of CPUs for which IPIs are scheduled
</span><span class='line'> * to be sent to kick remote softirq processing.  There are two masks since
</span><span class='line'> * the sending of IPIs must be done with interrupts enabled.  The select field
</span><span class='line'> * indicates the current mask that enqueue_backlog uses to schedule IPIs.
</span><span class='line'> * select is flipped before net_rps_action is called while still under lock,
</span><span class='line'> * net_rps_action then uses the non-selected mask to send the IPIs and clears
</span><span class='line'> * it without conflicting with enqueue_backlog operation.
</span><span class='line'> */
</span><span class='line'>struct rps_remote_softirq_cpus {
</span><span class='line'>    // 对应的cpu掩码
</span><span class='line'>    cpumask_t mask[2];
</span><span class='line'>    // 表示应该使用的数组索引
</span><span class='line'>    int select;
</span><span class='line'>};
</span><span class='line'>&lt;/code&gt;&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    static int enqueue_to_backlog(struct sk_buff *skb, int cpu)
</span><span class='line'>{
</span><span class='line'>    struct softnet_data *queue;
</span><span class='line'>    unsigned long flags;
</span><span class='line'>    // 取出传递进来的cpu的softnet-data结构
</span><span class='line'>    queue = &amp;per_cpu(softnet_data, cpu);
</span><span class='line'>
</span><span class='line'>    local_irq_save(flags);
</span><span class='line'>    __get_cpu_var(netdev_rx_stat).total++;
</span><span class='line'>    // 自旋锁
</span><span class='line'>    spin_lock(&amp;queue-&gt;input_pkt_queue.lock);
</span><span class='line'>    // 如果保存的队列还没到上限
</span><span class='line'>    if (queue-&gt;input_pkt_queue.qlen &lt;= netdev_max_backlog) {
</span><span class='line'>    // 如果当前队列的输入队列长度不为空
</span><span class='line'>        if (queue-&gt;input_pkt_queue.qlen) {
</span><span class='line'>enqueue:
</span><span class='line'>            // 将数据包加入到input_pkt_queue中,这里会有一个小问题，我们后面再说。
</span><span class='line'>            __skb_queue_tail(&amp;queue-&gt;input_pkt_queue, skb);
</span><span class='line'>            spin_unlock_irqrestore(&amp;queue-&gt;input_pkt_queue.lock,
</span><span class='line'>                flags);
</span><span class='line'>            return NET_RX_SUCCESS;
</span><span class='line'>        }
</span><span class='line'>
</span><span class='line'>        /* Schedule NAPI for backlog device */
</span><span class='line'>        // 如果可以调度软中断
</span><span class='line'>        if (napi_schedule_prep(&amp;queue-&gt;backlog)) {
</span><span class='line'>            // 首先判断数据包该不该当前的cpu处理
</span><span class='line'>            if (cpu != smp_processor_id()) {
</span><span class='line'>                // 如果不该，
</span><span class='line'>                struct rps_remote_softirq_cpus *rcpus =
</span><span class='line'>                    &amp;__get_cpu_var(rps_remote_softirq_cpus);
</span><span class='line'>
</span><span class='line'>                cpu_set(cpu, rcpus-&gt;mask[rcpus-&gt;select]);
</span><span class='line'>                __raise_softirq_irqoff(NET_RX_SOFTIRQ);
</span><span class='line'>            } else
</span><span class='line'>                // 如果就是应该当前cpu处理，则直接schedule 软中断，这里可以看到传递进去的是backlog
</span><span class='line'>                __napi_schedule(&amp;queue-&gt;backlog);
</span><span class='line'>        }
</span><span class='line'>        goto enqueue;
</span><span class='line'>    }
</span><span class='line'>
</span><span class='line'>    spin_unlock(&amp;queue-&gt;input_pkt_queue.lock);
</span><span class='line'>
</span><span class='line'>    __get_cpu_var(netdev_rx_stat).dropped++;
</span><span class='line'>    local_irq_restore(flags);
</span><span class='line'>
</span><span class='line'>    kfree_skb(skb);
</span><span class='line'>    return NET_RX_DROP;
</span><span class='line'>}
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;这里会有一个小问题，那就是假设此时一个属于cpu0的包进入处理，此时我们运行在cpu1,此时将数据包加入到input队列，然后cpu0上面刚好又来了一个cpu0需要处理的数据包，此时由于qlen不为0则又将数据包加入到input队列中，我们会发现cpu0上的napi没机会进行调度了。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;google的patch对这个是这样处理的，在软中断处理函数中当数据包处理完毕，会调用net_rps_action来调度前面保存到其他cpu上的input队列。&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;下面就是代码片断（net_rx_action）&lt;/p&gt;
</span><span class='line'>
</span><span class='line'>&lt;pre&gt;&lt;code&gt;    // 得到对应的rcpus.
</span><span class='line'>rcpus = &amp;__get_cpu_var(rps_remote_softirq_cpus);
</span><span class='line'>    select = rcpus-&gt;select;
</span><span class='line'>    // 翻转select，防止和enqueue_backlog冲突
</span><span class='line'>    rcpus-&gt;select ^= 1;
</span><span class='line'>
</span><span class='line'>    // 打开中断，此时下面的调度才会起作用.
</span><span class='line'>    local_irq_enable();
</span><span class='line'>    // 这个函数里面调度对应的远程cpu的napi.
</span><span class='line'>    net_rps_action(&amp;rcpus-&gt;mask[select]);
</span><span class='line'>&lt;/code&gt;&lt;/pre&gt;
</span><span class='line'>
</span><span class='line'>&lt;p&gt;然后就是net_rps_action，这个函数很简单，就是遍历所需要处理的cpu，然后调度napi</span></code></pre></td></tr></table></div></figure>
    static void net_rps_action(cpumask_t *mask)
    {
        int cpu;</p>

<pre><code>    /* Send pending IPI's to kick RPS processing on remote cpus. */
    // 遍历
    for_each_cpu_mask_nr(cpu, *mask) {
        struct softnet_data *queue = &amp;per_cpu(softnet_data, cpu);
        if (cpu_online(cpu))
            // 到对应的cpu调用csd方法。
            __smp_call_function_single(cpu, &amp;queue-&gt;csd, 0);
    }
    // 清理mask
    cpus_clear(*mask);
}
</code></pre>

<pre><code>

上面我们看到会调用csd方法，而上面的csd回掉就是被初始化为trigger_softirq函数。
</code></pre>

<pre><code>static void trigger_softirq(void *data)
{
    struct softnet_data *queue = data;
    // 调度napi可以看到依旧是backlog 这个napi结构体。
    __napi_schedule(&amp;queue-&gt;backlog);
    __get_cpu_var(netdev_rx_stat).received_rps++;
}
</code></pre>

<pre><code>

上面的函数都分析完毕了，剩下的就很简单了。

首先来看netif_rx如何被修改的，它被修改的很简单，首先是得到当前skb所应该被处理的cpu id，然后再通过比较这个cpu和当前正在处理的cpu id进行比较来做不同的处理。
</code></pre>

<pre><code>int netif_rx(struct sk_buff *skb)
{
    int cpu;

    /* if netpoll wants it, pretend we never saw it */
    if (netpoll_rx(skb))
        return NET_RX_DROP;

    if (!skb-&gt;tstamp.tv64)
        net_timestamp(skb);
    // 得到cpu id。
    cpu = get_rps_cpu(skb-&gt;dev, skb);
    if (cpu &lt; 0)
        cpu = smp_processor_id();
    // 通过cpu进行队列不同的处理
    return enqueue_to_backlog(skb, cpu);
}
</code></pre>

<pre><code>

然后是netif_receive_skb,这里patch将内核本身的这个函数改写为__netif_receive_skb。然后当返回值小于0,则说明不需要对队列进行处理，此时直接发送到3层。
</code></pre>

<pre><code>int netif_receive_skb(struct sk_buff *skb)
{
    int cpu;

    cpu = get_rps_cpu(skb-&gt;dev, skb);

    if (cpu &lt; 0)
        return __netif_receive_skb(skb);
    else
        return enqueue_to_backlog(skb, cpu);
}
</code></pre>

<p>```</p>

<p>最后来总结一下，可以看到input_pkt_queue是一个FIFO的队列，而且如果当qlen有值的时候，也就是在另外的cpu有数据包放到input_pkt_queue中，则当前cpu不会调度napi，而是将数据包放到input_pkt_queue中，然后等待trigger_softirq来调度napi。</p>

<p>因此这个patch完美的解决了软中断在多核下的均衡问题，并且没有由于是同一个连接会map到相同的cpu，并且input_pkt_queue的使用，因此乱序的问题也不会出现。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[内核协议栈tcp层的内存管理]]></title>
    <link href="http://abcdxyzk.github.io/blog/2015/06/03/kernel-net-mem/"/>
    <updated>2015-06-03T14:25:00+08:00</updated>
    <id>http://abcdxyzk.github.io/blog/2015/06/03/kernel-net-mem</id>
    <content type="html"><![CDATA[<p><a href="http://simohayha.iteye.com/blog/532450">http://simohayha.iteye.com/blog/532450</a></p>

<p><a href="http://www.ibm.com/developerworks/cn/linux/l-hisock.html#table1">http://www.ibm.com/developerworks/cn/linux/l-hisock.html#table1</a></p>

<p><a href="http://blog.csdn.net/russell_tao/article/details/18711023">http://blog.csdn.net/russell_tao/article/details/18711023</a></p>

<p>我们先来看tcp内存管理相关的几个内核参数,这些都能通过proc文件系统来修改:
<code>
    // 内核写buf的最大值.
    extern __u32 sysctl_wmem_max;
    // 协议栈读buf的最大值
    extern __u32 sysctl_rmem_max;
</code></p>

<p>这两个值在/proc/sys/net/core 下。这里要注意，这两个值的单位是字节。</p>

<p>它们的初始化在sk_init里面,这里可以看到这两个值的大小是依赖于num_physpages的，而这个值应该是物理页数。也就是说这两个值依赖于物理内存：</p>

<pre><code>    void __init sk_init(void)
    {
        if (num_physpages &lt;= 4096) {
            sysctl_wmem_max = 32767;
            sysctl_rmem_max = 32767;
            sysctl_wmem_default = 32767;
            sysctl_rmem_default = 32767;
        } else if (num_physpages &gt;= 131072) {
            sysctl_wmem_max = 131071;
            sysctl_rmem_max = 131071;
        }
    }
</code></pre>

<p>而我通过搜索源码，只有设置套接口选项的时候，才会用到这两个值，也就是setsockopt，optname为SO_SNDBUF或者SO_RCVBUF时，来限制设置的值:</p>

<pre><code>    case SO_SNDBUF:
            if (val &gt; sysctl_wmem_max)
                val = sysctl_wmem_max;
</code></pre>

<p>接下来就是整个tcp协议栈的socket的buf限制(也就是所有的socket).
这里要注意，这个东西的单位都是以页为单位的，我们下面就会看到。
<code>
    其中sysctl_tcp_mem[0]表示整个tcp sock的buf限制.
    sysctl_tcp_mem[1]也就是tcp sock内存使用的警戒线.
    sysctl_tcp_mem[2]也就是tcp sock内存使用的hard limit,当超过这个限制,我们就要禁止再分配buf.
    extern int sysctl_tcp_mem[3];
</code></p>

<p>接下来就是针对每个sock的读写buf限制。
<code>
    // 其中依次为最小buf,中等buf,以及最大buf.
    extern int sysctl_tcp_wmem[3];
    extern int sysctl_tcp_rmem[3];
</code></p>

<h4>tcp_init</h4>

<p>这几个值的初始化在tcp_init里面，这里就能清晰的看到sysctl_tcp_mem的单位是页。而sysctl_tcp_wmem和sysctl_tcp_rmem的单位是字节。</p>

<pre><code>    void __init tcp_init(void)
    {
        .................................
        // nr_pages就是页。
        nr_pages = totalram_pages - totalhigh_pages;
        limit = min(nr_pages, 1UL&lt;&lt;(28-PAGE_SHIFT)) &gt;&gt; (20-PAGE_SHIFT);
        limit = (limit * (nr_pages &gt;&gt; (20-PAGE_SHIFT))) &gt;&gt; (PAGE_SHIFT-11);
        limit = max(limit, 128UL);
        sysctl_tcp_mem[0] = limit / 4 * 3;
        sysctl_tcp_mem[1] = limit;
        sysctl_tcp_mem[2] = sysctl_tcp_mem[0] * 2;

        /* Set per-socket limits to no more than 1/128 the pressure threshold */
        // 转换为字节。
        limit = ((unsigned long)sysctl_tcp_mem[1]) &lt;&lt; (PAGE_SHIFT - 7);
        max_share = min(4UL*1024*1024, limit);

        sysctl_tcp_wmem[0] = SK_MEM_QUANTUM;
        sysctl_tcp_wmem[1] = 16*1024;
        sysctl_tcp_wmem[2] = max(64*1024, max_share);

        sysctl_tcp_rmem[0] = SK_MEM_QUANTUM;
        sysctl_tcp_rmem[1] = 87380;
        sysctl_tcp_rmem[2] = max(87380, max_share);
        ................................
    }
</code></pre>

<p>然后就是读写buf的最小值
<code>
    #define SOCK_MIN_SNDBUF 2048
    #define SOCK_MIN_RCVBUF 256
</code></p>

<p>最后就是当前tcp协议栈已经分配了的buf的总大小。这里要注意，这个值也是以页为单位的。
<code>
    atomic_t tcp_memory_allocated
</code></p>

<p>而上面的这些值如何与协议栈关联起来呢，我们来看tcp_prot结构，可以看到这些值的地址都被放到对应的tcp_prot的域。</p>

<pre><code>    struct proto tcp_prot = {
        .name = "TCP",
        .owner = THIS_MODULE,
        ...................................................
        .enter_memory_pressure = tcp_enter_memory_pressure,
        .sockets_allocated = &amp;tcp_sockets_allocated,
        .orphan_count = &amp;tcp_orphan_count,
        .memory_allocated = &amp;tcp_memory_allocated,
        .memory_pressure = &amp;tcp_memory_pressure,
        .sysctl_mem = sysctl_tcp_mem,
        .sysctl_wmem = sysctl_tcp_wmem,
        .sysctl_rmem = sysctl_tcp_rmem,
        ........................................................
    };
</code></pre>

<p>而对应的sock域中的几个值，这几个域非常重要，我们来看他们表示的含义</p>

<p>sk_rcvbuf和sk_sndbuf,这两个值分别代表每个sock的读写buf的最大限制</p>

<p>sk_rmem_alloc和sk_wmem_alloc这两个值分别代表已经提交的数据包的字节数。</p>

<p>读buf意味着进入tcp层的数据大小，而当数据提交给用户空间之后，这个值会相应的减去提交的大小（也就类似写buf的sk_wmem_queued)。</p>

<p>写buf意味着提交给ip层。可以看到这个值的增加是在tcp_transmit_skb中进行的。</p>

<p>而sk_wmem_queued也就代表skb的写队列write_queue的大小。</p>

<p>还有一个sk_forward_alloc，这个值表示一个预分配置，也就是整个tcp协议栈的内存cache，第一次为一个缓冲区分配buf的时候，我们不会直接分配精确的大小，而是按页来分配，而分配的大小就是这个值，下面我们会看到这个。并且这个值初始是0.</p>

<pre><code>    struct sock {
        int sk_rcvbuf;
        atomic_t sk_rmem_alloc;
        atomic_t sk_wmem_alloc;
        int sk_forward_alloc;
        ..........................
        int sk_sndbuf;
        // 这个表示写buf已经分配的字节长度
        int sk_wmem_queued;
        ...........................
    }
</code></pre>

<p>sk_sndbuf和sk_rcvbuf,这两个的初始化在这里：
<code>
    static int tcp_v4_init_sock(struct sock *sk)
    {
        ..................................
        sk-&gt;sk_sndbuf = sysctl_tcp_wmem[1];
        sk-&gt;sk_rcvbuf = sysctl_tcp_rmem[1];
        ..........................
    }
</code></p>

<p>而当进入establish状态之后,sock会自己调整sndbuf和rcvbuf.他是通过tcp_init_buffer_space来进行调整的.这个函数会调用tcp_fixup_rcvbuf和tcp_fixup_sndbuf来调整读写buf的大小.</p>

<p>这里有用到sk_userlock这个标记，这个标记主要就是用来标记SO_SNDBUF 和SO_RCVBUF套接口选项是否被设置。而是否设置对应的值为：</p>

<pre><code>    #define SOCK_SNDBUF_LOCK    1
    #define SOCK_RCVBUF_LOCK    2
</code></pre>

<p>我们可以看下面的设置SO_SNDBUF 和SO_RCVBUF的代码片断：</p>

<pre><code>    // 首先设置sk_userlocks.
    sk-&gt;sk_userlocks |= SOCK_SNDBUF_LOCK;
    if ((val * 2) &lt; SOCK_MIN_SNDBUF)
        sk-&gt;sk_sndbuf = SOCK_MIN_SNDBUF;
    else
        sk-&gt;sk_sndbuf = val * 2;
</code></pre>

<p>因此内核里面的处理是这样的，如果用户已经通过套接字选项设置了读或者写buf的大小，那么这里将不会调整读写buf的大小，否则就进入tcp_fixup_XXX来调整大小。</p>

<p>还有一个要注意的就是MAX_TCP_HEADER，这个值表示了TCP + IP + link layer headers 以及option的长度。</p>

<p>我们来看代码。</p>

<pre><code>    static void tcp_init_buffer_space(struct sock *sk)
    {
        struct tcp_sock *tp = tcp_sk(sk);
        int maxwin;

        // 判断sk_userlocks，来决定是否需要fix缓冲区大小。
        if (!(sk-&gt;sk_userlocks &amp; SOCK_RCVBUF_LOCK))
            tcp_fixup_rcvbuf(sk);
        if (!(sk-&gt;sk_userlocks &amp; SOCK_SNDBUF_LOCK))
            tcp_fixup_sndbuf(sk);
    ......................................

    }
</code></pre>

<p>接下来来看这两个函数如何来调整读写buf的大小，不过这里还有些疑问，就是为什么是要和3<em>sndmem以及4</em>rcvmem：</p>

<pre><code>    static void tcp_fixup_sndbuf(struct sock *sk)
    {
        // 首先通过mss，tcp头，以及sk_buff的大小，得到一个最小范围的sndmem。
        int sndmem = tcp_sk(sk)-&gt;rx_opt.mss_clamp + MAX_TCP_HEADER + 16 +sizeof(struct sk_buff);

        // 然后取sysctl_tcp_wmem[2]和3倍的sndmem之间的最小值。
        if (sk-&gt;sk_sndbuf &lt; 3 * sndmem)
            sk-&gt;sk_sndbuf = min(3 * sndmem, sysctl_tcp_wmem[2]);
    }

    static void tcp_fixup_rcvbuf(struct sock *sk)
    {
        struct tcp_sock *tp = tcp_sk(sk);
        // 这里和上面类似，也是先得到最小的一个rcvmem段。
        int rcvmem = tp-&gt;advmss + MAX_TCP_HEADER + 16 + sizeof(struct sk_buff);

        /* Try to select rcvbuf so that 4 mss-sized segments
         * will fit to window and corresponding skbs will fit to our rcvbuf.
         * (was 3; 4 is minimum to allow fast retransmit to work.)
         */
        // 这里则是通过sysctl_tcp_adv_win_scale来调整rcvmem的值。
        while (tcp_win_from_space(rcvmem) &lt; tp-&gt;advmss)
            rcvmem += 128;
        if (sk-&gt;sk_rcvbuf &lt; 4 * rcvmem)
            sk-&gt;sk_rcvbuf = min(4 * rcvmem, sysctl_tcp_rmem[2]);
    }
</code></pre>

<p>ok，看完初始化，我们来看协议栈具体如何管理内存的，先来看发送端，发送端的主要实现是在tcp_sendmsg里面，这个函数我们前面已经详细的分析过了，我们这次只分析里面几个与内存相关的东西。</p>

<p>来看代码片断：</p>

<pre><code>    int tcp_sendmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,
            size_t size)
    {
        ..................................

        if (copy &lt;= 0) {
    new_segment:
            if (!sk_stream_memory_free(sk))
                goto wait_for_sndbuf;

            skb = sk_stream_alloc_skb(sk, select_size(sk),
            sk-&gt;sk_allocation);
            if (sk-&gt;sk_route_caps &amp; NETIF_F_ALL_CSUM)
                skb-&gt;ip_summed = CHECKSUM_PARTIAL;

            skb_entail(sk, skb);
            copy = size_goal;
            max = size_goal;
        ..................
    }
</code></pre>

<p>可以看到这里第一个sk_stream_memory_free用来判断是否还有空间来供我们分配，如果没有则跳到wait_for_sndbuf来等待buf的释放。</p>

<p>然后如果有空间供我们分配，则调用sk_stream_alloc_skb来分配一个skb，然后这个大小的选择是通过select_size。</p>

<p>最后调用skb_entail来更新相关的域。</p>

<p>现在我们就来详细看上面的四个函数,先来看第一个：</p>

<pre><code>    static inline int sk_stream_memory_free(struct sock *sk)
    {
        return sk-&gt;sk_wmem_queued &lt; sk-&gt;sk_sndbuf;
    }
</code></pre>

<p>sk_stream_memory_free实现很简单，就是判断当前已经分配的写缓冲区的大小(sk_wmem_queued)是否小于当前写缓冲区(sk_sndbuf)的最大限制。</p>

<p>然后是skb_entail，这个函数主要是当我们分配完buf后，进行一些相关域的更新，以及添加skb到writequeue。</p>

<pre><code>    static inline void skb_entail(struct sock *sk, struct sk_buff *skb)
    {
        struct tcp_sock *tp = tcp_sk(sk);
        struct tcp_skb_cb *tcb = TCP_SKB_CB(skb);
        ............................
        skb_header_release(skb);
        tcp_add_write_queue_tail(sk, skb);
        // 增加sk_wmem_queued.
        sk-&gt;sk_wmem_queued += skb-&gt;truesize;
        // 这里调整sk_forward_alloc的大小，也就是预分配buf的大小(减小).
        sk_mem_charge(sk, skb-&gt;truesize);
        if (tp-&gt;nonagle &amp; TCP_NAGLE_PUSH)
            tp-&gt;nonagle &amp;= ~TCP_NAGLE_PUSH;
    }
    // 这个函数很简单，就是将sk_forward_alloc - size.
    static inline void sk_mem_charge(struct sock *sk, int size)
    {
        if (!sk_has_account(sk))
            return;
        sk-&gt;sk_forward_alloc -= size;
    }
</code></pre>

<p>然后是select_size，在看这个之前我们先来坎SKB_MAX_HEAD的实现.
SKB_MAX_HEAD主要是得到要分配的tcp数据段（不包括头)在一页中最大为多少。</p>

<pre><code>    #define SKB_WITH_OVERHEAD(X)    \
        ((X) - SKB_DATA_ALIGN(sizeof(struct skb_shared_info)))
    #define SKB_MAX_ORDER(X, ORDER) \
        SKB_WITH_OVERHEAD((PAGE_SIZE &lt;&lt; (ORDER)) - (X))
    #define SKB_MAX_HEAD(X)  (SKB_MAX_ORDER((X), 0))
</code></pre>

<p>我们带入代码来看，我们下面的代码是SKB_MAX_HEAD(MAX_TCP_HEADER)，展开这个宏可以看到就是PAGE_SIZE-MAX_TCP_HEADER-SKB_DATA_ALIGN(sizeof(struct skb_shared_info).其实也就是一页还能容纳多少tcp的数据。</p>

<pre><code>    static inline int select_size(struct sock *sk)
    {
        struct tcp_sock *tp = tcp_sk(sk);
        // 首先取得存储的mss。
        int tmp = tp-&gt;mss_cache;

        // 然后判断是否使用scatter–gather(前面blog有介绍)
        if (sk-&gt;sk_route_caps &amp; NETIF_F_SG) {
            if (sk_can_gso(sk))
                tmp = 0;
            else {
                // 然后开始计算buf的长度。
                int pgbreak = SKB_MAX_HEAD(MAX_TCP_HEADER);

                // 如果mss大于pgbreak,那么说明我们一页放不下当前需要的tcp数据，因此我们将会在skb的页区域分配，而skb的页区域是有限制的，因此tmp必须小于这个值。
                if (tmp &gt;= pgbreak &amp;&amp;
                        tmp &lt;= pgbreak + (MAX_SKB_FRAGS - 1) * PAGE_SIZE)
                    tmp = pgbreak;
            }
        }

        return tmp;
    }
</code></pre>

<h4>sk_stream_alloc_skb</h4>

<p>接下来来看sk_stream_alloc_skb的实现。</p>

<p>1 它会调用alloc_skb_fclone来分配内存，这个函数就不详细分析了，我们只需要知道它会从slab里分配一块内存，而大小为size+max_header(上面的分析我们知道slect_size只计算数据段).</p>

<p>2 如果分配成功，则调用sk_wmem_schedule来判断我们所分配的skb的大小是否精确，是的话，就调整指针，然后返回。</p>

<p>3 否则调用tcp_enter_memory_pressure设置标志进入TCP memory pressure zone。然后再调用sk_stream_moderate_sndbuf调整sndbuf(缩小sndbuf)。</p>

<pre><code>    struct sk_buff *sk_stream_alloc_skb(struct sock *sk, int size, gfp_t gfp)
    {
        struct sk_buff *skb;

        // 4字节对其
        size = ALIGN(size, 4);
        // 分配skb。
        skb = alloc_skb_fclone(size + sk-&gt;sk_prot-&gt;max_header, gfp);
        if (skb) {
            // 得到精确的大小。
            if (sk_wmem_schedule(sk, skb-&gt;truesize)) {
                // 返回skb。
                skb_reserve(skb, skb_tailroom(skb) - size);
                    return skb;
            }
            __kfree_skb(skb);
        } else {
            // 否则设置全局标记进入pressure zone
            sk-&gt;sk_prot-&gt;enter_memory_pressure(sk);
            sk_stream_moderate_sndbuf(sk);
        }
        return NULL;
    }
</code></pre>

<p>ok,现在就来看上面的几个函数的实现。先来看几个简单的。</p>

<p>首先是tcp_enter_memory_pressure,这个函数很简单，就是判断全局标记tcp_memory_pressure,然后设置这个标记。这个标记主要是用来通知其他模块调整的，比如窗口大小等等，详细的话自己搜索这个值，就知道了。
<code>
    void tcp_enter_memory_pressure(struct sock *sk)
    {
        if (!tcp_memory_pressure) {
            NET_INC_STATS(sock_net(sk), LINUX_MIB_TCPMEMORYPRESSURES);
            // 设置压力标志。
            tcp_memory_pressure = 1;
        }
    }
</code></p>

<p>然后是sk_stream_moderate_sndbuf，这个函数也是要使用sk_userlocks,来判断是否已经被用户设置了。可以看到如果我们自己设置过了snd_buf的话，内核就不会帮我们调整它的大小了。</p>

<pre><code>    static inline void sk_stream_moderate_sndbuf(struct sock *sk)
    {
        if (!(sk-&gt;sk_userlocks &amp; SOCK_SNDBUF_LOCK)) {
            // 它的大小调整为大于最小值，小于sk-&gt;sk_wmem_queued &gt;&gt; 1。
            sk-&gt;sk_sndbuf = min(sk-&gt;sk_sndbuf, sk-&gt;sk_wmem_queued &gt;&gt; 1);
            sk-&gt;sk_sndbuf = max(sk-&gt;sk_sndbuf, SOCK_MIN_SNDBUF);
        }
    }
</code></pre>

<h4>sk_wmem_schedule</h4>

<p>最后来看最核心的一个函数sk_wmem_schedule，这个函数只是对<code>__sk_mem_schedule</code>的简单封装。这里要知道传递进来的size是skb->truesize，也就是所分配的skb的真实大小。并且第一次进入这个函数，也就是分配第一个缓冲区包时，sk_forward_alloc是为0的，也就是说，第一次必然会执行<code>__sk_mem_schedule</code>函数。</p>

<pre><code>    static inline int sk_wmem_schedule(struct sock *sk, int size)
    {
        if (!sk_has_account(sk))
            return 1;
        // 先比较size(也就是skb-&gt;truesize)和预分配的内存大小。如果小于等于预分配的大小，则直接返回，否则调用__sk_mem_schedule进行调整。
        return size &lt;= sk-&gt;sk_forward_alloc ||
            __sk_mem_schedule(sk, size, SK_MEM_SEND);
    }
</code></pre>

<p>来看<code>__sk_mem_schedule</code>，这个函数的功能注释写的很清楚：</p>

<p>increase sk_forward_alloc and memory_allocated</p>

<p>然后来看源码。这里在看之前，我们要知道，协议栈通过读写buf的使用量，划分了3个区域，或者说标志。不同标志进行不同处理。这里的区域的划分是通过sysctl_tcp_mem，也就是prot->sysctl_mem这个数组进行的。</p>

<pre><code>    // 页的大小
    #define SK_MEM_QUANTUM ((int)PAGE_SIZE)

    int __sk_mem_schedule(struct sock *sk, int size, int kind)
    {
        struct proto *prot = sk-&gt;sk_prot;
        // 首先得到size占用几个内存页。
        int amt = sk_mem_pages(size);
        int allocated;
        // 更新sk_forward_alloc，可以看到这个值是页的大小的倍数。
        sk-&gt;sk_forward_alloc += amt * SK_MEM_QUANTUM;

        // amt+memory_allocated也就是当前的总得内存使用量加上将要分配的内存的话，现在的tcp协议栈的总得内存使用量。（可以看到是以页为单位的。
        allocated = atomic_add_return(amt, prot-&gt;memory_allocated);

        // 然后开始判断，将会落入哪一个区域。通过上面的分析我们知道sysctl_mem也就是sysctl_tcp_mem.

        // 先判断是否小于等于内存最小使用限额。
        if (allocated &lt;= prot-&gt;sysctl_mem[0]) {
            // 这里取消memory_pressure，然后返回。
            if (prot-&gt;memory_pressure &amp;&amp; *prot-&gt;memory_pressure)
                *prot-&gt;memory_pressure = 0;
            return 1;
        }

        // 然后判断Under pressure。
        if (allocated &gt; prot-&gt;sysctl_mem[1])
            // 大于sysctl_mem[1]说明，已经进入pressure，一次你需要调用tcp_enter_memory_pressure来设置标志。
            if (prot-&gt;enter_memory_pressure)
                prot-&gt;enter_memory_pressure(sk);

        // 如果超过的hard limit。则进入另外的处理。
        if (allocated &gt; prot-&gt;sysctl_mem[2])
            goto suppress_allocation;

        // 判断类型，这里只有两种类型，读和写。总的内存大小判断完，这里开始判断单独的sock的读写内存。
        if (kind == SK_MEM_RECV) {
            if (atomic_read(&amp;sk-&gt;sk_rmem_alloc) &lt; prot-&gt;sysctl_rmem[0])
                return 1;
        } else { /* SK_MEM_SEND */
            // 这里当为tcp的时候，写队列的大小只有当对端数据确认后才会更新，因此我们要用sk_wmem_queued来判断。
            if (sk-&gt;sk_type == SOCK_STREAM) {
                if (sk-&gt;sk_wmem_queued &lt; prot-&gt;sysctl_wmem[0])
                    return 1;
            } else if (atomic_read(&amp;sk-&gt;sk_wmem_alloc) &lt;
                   prot-&gt;sysctl_wmem[0])
                    return 1;
        }

        // 程序到达这里说明总的内存大小在sysctl_mem[0]和sysctl_mem[2]之间，因此我们再次判断memory_pressure
        if (prot-&gt;memory_pressure) {
            int alloc;

            // 如果没有在memory_pressure区域，则我们直接返回1。
            if (!*prot-&gt;memory_pressure)
                return 1;
            // 这个其实也就是计算整个系统分配的socket的多少。
            alloc = percpu_counter_read_positive(prot-&gt;sockets_allocated);
            // 这里假设其余的每个sock所占用的buf都和当前的sock一样大的时候，如果他们的总和小于sysctl_mem[2],也就是hard limit。那么我们也认为这次内存请求是成功的。
            if (prot-&gt;sysctl_mem[2] &gt; alloc *
                sk_mem_pages(sk-&gt;sk_wmem_queued +
                 atomic_read(&amp;sk-&gt;sk_rmem_alloc) +
                     sk-&gt;sk_forward_alloc))
                return 1;
        }

    suppress_allocation:

        // 到达这里说明，我们超过了hard limit或者说处于presure 区域。
        if (kind == SK_MEM_SEND &amp;&amp; sk-&gt;sk_type == SOCK_STREAM) {
            // 调整sk_sndbuf(减小).这个函数前面已经分析过了。
            sk_stream_moderate_sndbuf(sk);
            // 然后比较和sk_sndbuf的大小，如果大于的话，就说明下次我们再次要分配buf的时候会在tcp_memory_free阻塞住，因此这次我们返回1.
            if (sk-&gt;sk_wmem_queued + size &gt;= sk-&gt;sk_sndbuf)
                return 1;
        }

        /* Alas. Undo changes. */
        // 到达这里说明，请求内存是不被接受的，因此undo所有的操作。然后返回0.
        sk-&gt;sk_forward_alloc -= amt * SK_MEM_QUANTUM;
        atomic_sub(amt, prot-&gt;memory_allocated);
        return 0;
    }
</code></pre>

<p>接下来来看个很重要的函数skb_set_owner_w。</p>

<p>顾名思义，这个函数也就是将一个skb和scok关联起来。只不过关联的时候更新sock相应的域。我们来看源码：</p>

<pre><code>    static inline void skb_set_owner_w(struct sk_buff *skb, struct sock *sk)
    {
        skb_orphan(skb);
        // 与传递进来的sock关联起来
        skb-&gt;sk = sk;
        // 设置skb的析构函数
        skb-&gt;destructor = sock_wfree;
        // 更新sk_wmem_alloc域，就是sk_wmem_alloc+truesize.
        atomic_add(skb-&gt;truesize, &amp;sk-&gt;sk_wmem_alloc);
    }
</code></pre>

<p>ok，接下来来看个scok_wfree函数，这个函数做得基本和上面函数相反。这个函数都是被kfree_skb自动调用的。</p>

<pre><code>    void sock_wfree(struct sk_buff *skb)
    {
        struct sock *sk = skb-&gt;sk;
        int res;

        // 更新sk_wmem_alloc,减去skb的大小。
        res = atomic_sub_return(skb-&gt;truesize, &amp;sk-&gt;sk_wmem_alloc);
        if (!sock_flag(sk, SOCK_USE_WRITE_QUEUE))
        // 唤醒等待队列，也就是唤醒等待内存分配。
            sk-&gt;sk_write_space(sk);
        if (res == 0)
            __sk_free(sk);
    }
</code></pre>

<p>而skb_set_owner_w是什么时候被调用呢，我们通过搜索代码可以看到，它是在tcp_transmit_skb中被调用的。而tcp_transmit_skb我们知道是传递数据包到ip层的函数。</p>

<p>而kfree_skb被调用也就是在对端已经确认完我们发送的包后才会被调用来释放skb。</p>

<h4>tcp_rcv_established</h4>

<p>接下来来看接收数据的内存管理。我们主要来看tcp_rcv_established这个函数，我前面的blog已经断断续续的分析过了，因此这里我们只看一些重要的代码片断。</p>

<p>这里我们要知道，代码能到达下面的位置，则说明，数据并没有直接拷贝到用户空间。否则的话，是不会进入下面的片断的。</p>

<pre><code>    if (!eaten) {
        ..........................................

        // 如果skb的大小大于预分配的值,如果大于则要另外处理。
        if ((int)skb-&gt;truesize &gt; sk-&gt;sk_forward_alloc)
                goto step5;
        __skb_pull(skb, tcp_header_len);
        __skb_queue_tail(&amp;sk-&gt;sk_receive_queue, skb);
        // 这里关联skb和对应的sk，并且更新相关的域，我们下面会分析这个函数。
        skb_set_owner_r(skb, sk);
        tp-&gt;rcv_nxt = TCP_SKB_CB(skb)-&gt;end_seq;
    }
    ...............................................

    step5:
        if (th-&gt;ack &amp;&amp; tcp_ack(sk, skb, FLAG_SLOWPATH) &lt; 0)
            goto discard;

        tcp_rcv_rtt_measure_ts(sk, skb);

        /* Process urgent data. */
        tcp_urg(sk, skb, th);

        /* step 7: process the segment text */
        // 最核心的函数就是这个。我们接下来会详细分析这个函数。
        tcp_data_queue(sk, skb);

        tcp_data_snd_check(sk);
        tcp_ack_snd_check(sk);
        return 0;
</code></pre>

<p>先来看skb_set_owner_r函数，这个函数关联skb和sk其实它和skb_set_owner_w类似：</p>

<pre><code>    static inline void skb_set_owner_r(struct sk_buff *skb, struct sock *sk)
    {
        skb_orphan(skb);
        // 关联sk
        skb-&gt;sk = sk;
        // 设置析构函数
        skb-&gt;destructor = sock_rfree;
        // 更新rmem_alloc
        atomic_add(skb-&gt;truesize, &amp;sk-&gt;sk_rmem_alloc);
        // 改变forward_alloc.
        sk_mem_charge(sk, skb-&gt;truesize);
    }
</code></pre>

<h4>tcp_data_queue</h4>

<p>然后是tcp_data_queue，这个函数主要用来排队接收数据，并update相关的读buf。由于这个函数比较复杂，我们只关心我们感兴趣的部分：</p>

<pre><code>    static void tcp_data_queue(struct sock *sk, struct sk_buff *skb)
    {
        struct tcphdr *th = tcp_hdr(skb);
        struct tcp_sock *tp = tcp_sk(sk);
        int eaten = -1;
        .......................................
        // 首先判断skb的开始序列号和我们想要接收的序列号。如果相等开始处理这个数据包(也就是拷贝到用户空间).
        if (TCP_SKB_CB(skb)-&gt;seq == tp-&gt;rcv_nxt) {
            if (tcp_receive_window(tp) == 0)
                goto out_of_window;

            // tp的ucopy我前面的blog已经详细分析过了。这里就不解释了。
            if (tp-&gt;ucopy.task == current &amp;&amp;
                tp-&gt;copied_seq == tp-&gt;rcv_nxt &amp;&amp; tp-&gt;ucopy.len &amp;&amp;sock_owned_by_user(sk) &amp;&amp; !tp-&gt;urg_data)
            {
                // 计算将要拷贝给用户空间的大小。
                int chunk = min_t(unsigned int, skb-&gt;len,tp-&gt;ucopy.len);

                // 设置状态，说明我们处于进程上下文。
                __set_current_state(TASK_RUNNING);

                local_bh_enable();
                // 拷贝skb
                if (!skb_copy_datagram_iovec(skb, 0, tp-&gt;ucopy.iov, chunk)) {
                    tp-&gt;ucopy.len -= chunk;
                    tp-&gt;copied_seq += chunk;
                    // 更新eaten，它的默认值为-1.
                    eaten = (chunk == skb-&gt;len &amp;&amp; !th-&gt;fin);
                    tcp_rcv_space_adjust(sk);
                }
                local_bh_disable();
            }

            // 如果小于0则说明没有拷贝成功，或者说就没有进行拷贝。此时需要更新sock的相关域。
            if (eaten &lt;= 0) {
    queue_and_out:
                // 最关键的tcp_try_rmem_schedule函数。接下来会详细分析。
                if (eaten &lt; 0 &amp;&amp;
                        tcp_try_rmem_schedule(sk, skb-&gt;truesize))
                    goto drop;

                // 关联skb和sk。到达这里说明tcp_try_rmem_schedule成功，也就是返回0.
                skb_set_owner_r(skb, sk);
                // 加skb到receive_queue.
                __skb_queue_tail(&amp;sk-&gt;sk_receive_queue, skb);
            }
            // 更新期待序列号。
            tp-&gt;rcv_nxt = TCP_SKB_CB(skb)-&gt;end_seq;
            ..............................................

            .....................................

            tcp_fast_path_check(sk);

            if (eaten &gt; 0)
                __kfree_skb(skb);
            else if (!sock_flag(sk, SOCK_DEAD))
                sk-&gt;sk_data_ready(sk, 0);
            return;
        }
        // 下面就是处理乱序包。以后会详细分析。
        ......................................
    }
</code></pre>

<h4>tcp_try_rmem_schedule</h4>

<p>接下来我们就来看tcp_try_rmem_schedule这个函数,这个函数如果返回0则说明sk_rmem_schedule返回1,而sk_rmem_schedule和sk_wmem_schedule是一样的。也就是看当前的skb加入后有没有超过读buf的限制。并更新相关的域。：</p>

<pre><code>    static inline int tcp_try_rmem_schedule(struct sock *sk, unsigned int size)
    {
        // 首先判断rmem_alloc(当前的读buf字节数)是否大于最大buf字节数，如果大于则调用tcp_prune_queue调整分配的buf。否则调用sk_rmem_schedule来调整相关域（sk_forward_alloc）。
        if (atomic_read(&amp;sk-&gt;sk_rmem_alloc) &gt; sk-&gt;sk_rcvbuf ||!sk_rmem_schedule(sk, size)) {

            // 调整分配的buf。
            if (tcp_prune_queue(sk) &lt; 0)
                return -1;
            // 更新sk的相关域。
            if (!sk_rmem_schedule(sk, size)) {
                if (!tcp_prune_ofo_queue(sk))
                    return -1;

                if (!sk_rmem_schedule(sk, size))
                    return -1;
            }
        }
        return 0;
    }
</code></pre>

<p>来看sk_rmem_schedule，这个函数很简单，就是封装了<code>__sk_mem_schedule</code>。而这个函数我们上面已经分析过了。
<code>
    static inline int sk_rmem_schedule(struct sock *sk, int size)
    {
        if (!sk_has_account(sk))
            return 1;
        return size &lt;= sk-&gt;sk_forward_alloc ||
            __sk_mem_schedule(sk, size, SK_MEM_RECV);
    }
</code></p>

<h4>tcp_prune_queue</h4>

<p>最后是tcp_prune_queue，这个函数主要是用来丢掉一些skb，因为到这个函数就说明我们的内存使用已经到极限了，因此我们要合并一些buf。这个合并也就是将序列号连续的段进行合并。</p>

<p>这里我们要知道tcp的包是有序的，因此内核中tcp专门有一个队列来保存那些Out of order segments。因此我们这里会先处理这个队列里面的skb。</p>

<p>然后调用tcp_collapse来处理接收队列里面的skb。和上面的类似。</p>

<p>这里要注意，合并的话都是按页来合并，也就是先分配一页大小的内存，然后将老的skb复制进去，最后free掉老的buf。
```
    static int tcp_prune_queue(struct sock <em>sk)
    {
        struct tcp_sock </em>tp = tcp_sk(sk);
        &hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;&hellip;.
        // 如果rmem_alloc过于大，则重新计算窗口的大小。一半都会缩小窗口。
        if (atomic_read(&amp;sk->sk_rmem_alloc) >= sk->sk_rcvbuf)
            tcp_clamp_window(sk);
        // 如果处于pressure区域，则调整窗口大小。这里也是缩小窗口。
        else if (tcp_memory_pressure)
            tp->rcv_ssthresh = min(tp->rcv_ssthresh, 4U * tp->advmss);</p>

<pre><code>    // 处理ofo队列。
    tcp_collapse_ofo_queue(sk);
    // 如果接收队列为非空，则调用tcp_collapse来处理sk_receive_queue
    if (!skb_queue_empty(&amp;sk-&gt;sk_receive_queue))
        tcp_collapse(sk, &amp;sk-&gt;sk_receive_queue,
                 skb_peek(&amp;sk-&gt;sk_receive_queue),
                 NULL,
                 tp-&gt;copied_seq, tp-&gt;rcv_nxt);
    // 更新全局的已分配内存的大小，也就是memory_allocated，接下来会详细介绍这个函数。
    sk_mem_reclaim(sk);

    // 如果调整后小于sk_rcvbuf,则返回0.
    if (atomic_read(&amp;sk-&gt;sk_rmem_alloc) &lt;= sk-&gt;sk_rcvbuf)
        return 0;

    ......................................
    return -1;
}
</code></pre>

<pre><code>
#### tcp_collapse_ofo_queue 尝试减小ofo queue占内存的大小
</code></pre>

<pre><code>/* Collapse ofo queue. Algorithm: select contiguous sequence of skbs
 * and tcp_collapse() them until all the queue is collapsed.
 */
static void tcp_collapse_ofo_queue(struct sock *sk)
{
    struct tcp_sock *tp = tcp_sk(sk);
    struct sk_buff *skb = skb_peek(&amp;tp-&gt;out_of_order_queue);
    struct sk_buff *head;
    u32 start, end;

    if (skb == NULL)
        return;

    start = TCP_SKB_CB(skb)-&gt;seq;
    end = TCP_SKB_CB(skb)-&gt;end_seq;
    head = skb;

    for (;;) {
        struct sk_buff *next = NULL;

        if (!skb_queue_is_last(&amp;tp-&gt;out_of_order_queue, skb))
            next = skb_queue_next(&amp;tp-&gt;out_of_order_queue, skb);
        skb = next;

        /* Segment is terminated when we see gap or when
         * we are at the end of all the queue. */
        if (!skb ||
            after(TCP_SKB_CB(skb)-&gt;seq, end) ||
            before(TCP_SKB_CB(skb)-&gt;end_seq, start)) {  // 找到ofo queue中连续的一段skb，即 prev-&gt;end_seq &gt;= next-&gt;seq
            tcp_collapse(sk, &amp;tp-&gt;out_of_order_queue,
                     head, skb, start, end);            // 尝试减小这一段连续skb占用的内存
            head = skb;
            if (!skb)
                break;
            /* Start new segment */
            start = TCP_SKB_CB(skb)-&gt;seq;               // 下个skb就是新的一段的开始
            end = TCP_SKB_CB(skb)-&gt;end_seq;
        } else {
            if (before(TCP_SKB_CB(skb)-&gt;seq, start))    // 这种情况只可能是tcp_collapse中大包拆成小包，拆到一半内存不够，没拆完导致。
                start = TCP_SKB_CB(skb)-&gt;seq;
            if (after(TCP_SKB_CB(skb)-&gt;end_seq, end))
                end = TCP_SKB_CB(skb)-&gt;end_seq;
        }
    }
}
</code></pre>

<pre><code>
#### tcp_collapse，gro上来的包有可能是大于4k的包，所以这个函数有时是在拆包，利弊难定
</code></pre>

<pre><code>// 删除一个skb，返回下个skb
static struct sk_buff *tcp_collapse_one(struct sock *sk, struct sk_buff *skb,
                    struct sk_buff_head *list)
{
    struct sk_buff *next = NULL;

    if (!skb_queue_is_last(list, skb))
        next = skb_queue_next(list, skb);

    __skb_unlink(skb, list);
    __kfree_skb(skb);
    NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPRCVCOLLAPSED);

    return next;
}

/* Collapse contiguous sequence of skbs head..tail with
 * sequence numbers start..end.
 *
 * If tail is NULL, this means until the end of the list.
 *
 * Segments with FIN/SYN are not collapsed (only because this
 * simplifies code)
 */
static void
tcp_collapse(struct sock *sk, struct sk_buff_head *list,
         struct sk_buff *head, struct sk_buff *tail,
         u32 start, u32 end)
{
    struct sk_buff *skb, *n;
    bool end_of_skbs;

    /* First, check that queue is collapsible and find
     * the point where collapsing can be useful. */
    skb = head;
restart:
    end_of_skbs = true;
    skb_queue_walk_from_safe(list, skb, n) {
        if (skb == tail)
            break;
        /* No new bits? It is possible on ofo queue. */
        if (!before(start, TCP_SKB_CB(skb)-&gt;end_seq)) { // 这种情况现在是不会出现的，以前代码有可能出现？？
            skb = tcp_collapse_one(sk, skb, list);
            if (!skb)
                break;
            goto restart;
        }

        /* The first skb to collapse is:
         * - not SYN/FIN and
         * - bloated or contains data before "start" or
         *   overlaps to the next one.
         */
        if (!tcp_hdr(skb)-&gt;syn &amp;&amp; !tcp_hdr(skb)-&gt;fin &amp;&amp;         // SYN，FIN 不合并，简化操作
            (tcp_win_from_space(skb-&gt;truesize) &gt; skb-&gt;len ||    // 合并后可能减小空间的情况才合并
             before(TCP_SKB_CB(skb)-&gt;seq, start))) {            // seq到start的数据已经被读走了，有减小空间的可能
            end_of_skbs = false;
            break;
        }

        if (!skb_queue_is_last(list, skb)) {
            struct sk_buff *next = skb_queue_next(list, skb);
            if (next != tail &amp;&amp;
                TCP_SKB_CB(skb)-&gt;end_seq != TCP_SKB_CB(next)-&gt;seq) { // 两个skb之间有交集，有减小空间可能
                end_of_skbs = false;
                break;
            }
        }

        /* Decided to skip this, advance start seq. */
        start = TCP_SKB_CB(skb)-&gt;end_seq;     // 否则向后继续找可能减小空间的第一个skb
    }
    if (end_of_skbs || tcp_hdr(skb)-&gt;syn || tcp_hdr(skb)-&gt;fin)
        return;

    while (before(start, end)) {  // 落在在start到end的包就是这次要合并的
        struct sk_buff *nskb;
        unsigned int header = skb_headroom(skb); // skb中协议头的大小
        int copy = SKB_MAX_ORDER(header, 0);     // 一个页（4k）中出去协议头空间的大小，也就是能容下的数据大小

        /* Too big header? This can happen with IPv6. */
        if (copy &lt; 0)
            return;
        if (end - start &lt; copy)
            copy = end - start;
        nskb = alloc_skb(copy + header, GFP_ATOMIC);
        if (!nskb)
            return;

        skb_set_mac_header(nskb, skb_mac_header(skb) - skb-&gt;head);
        skb_set_network_header(nskb, (skb_network_header(skb) -
                          skb-&gt;head));
        skb_set_transport_header(nskb, (skb_transport_header(skb) -
                        skb-&gt;head));
        skb_reserve(nskb, header);
        memcpy(nskb-&gt;head, skb-&gt;head, header);
        memcpy(nskb-&gt;cb, skb-&gt;cb, sizeof(skb-&gt;cb));
        TCP_SKB_CB(nskb)-&gt;seq = TCP_SKB_CB(nskb)-&gt;end_seq = start;
        __skb_queue_before(list, skb, nskb);
        skb_set_owner_r(nskb, sk);

        /* Copy data, releasing collapsed skbs. */
        while (copy &gt; 0) {    // 如果copy = 0，这里就会出BUG，但如果没有认为改，是不会的。ipv6会吗？？？。后面版本改进这函数了，也不会出现copy=0了
            int offset = start - TCP_SKB_CB(skb)-&gt;seq;
            int size = TCP_SKB_CB(skb)-&gt;end_seq - start;

            BUG_ON(offset &lt; 0);
            if (size &gt; 0) { // copy旧的skb数据到新的skb上
                size = min(copy, size);
                if (skb_copy_bits(skb, offset, skb_put(nskb, size), size))
                    BUG();
                TCP_SKB_CB(nskb)-&gt;end_seq += size;
                copy -= size;
                start += size;
            }
            if (!before(start, TCP_SKB_CB(skb)-&gt;end_seq)) { // 旧的skb被copy完了就删掉
                skb = tcp_collapse_one(sk, skb, list);
                if (!skb ||
                    skb == tail ||
                    tcp_hdr(skb)-&gt;syn ||
                    tcp_hdr(skb)-&gt;fin)
                    return;
            }
        }
    }
}
</code></pre>

<pre><code>
来看sk_mem_reclaim函数，它只是简单的封装了`__sk_mem_reclaim`：
</code></pre>

<pre><code>static inline void sk_mem_reclaim(struct sock *sk)
{
    if (!sk_has_account(sk))
        return;
    // 如果sk_forward_alloc大于1页则调用__sk_mem_reclaim，我们知道sk_forward_alloc是以页为单位的，因此这里也就是和大于0一样。
    if (sk-&gt;sk_forward_alloc &gt;= SK_MEM_QUANTUM)
        __sk_mem_reclaim(sk);
}
</code></pre>

<pre><code>
`__sk_mem_reclaim`就是真正操作的函数，它会更新memory_allocated：
</code></pre>

<pre><code>void __sk_mem_reclaim(struct sock *sk)
{
    struct proto *prot = sk-&gt;sk_prot;
    // 更新memory_allocated，这里我们知道memory_allocated也是以页为单位的，因此需要将sk_forward_alloc转化为页。
    atomic_sub(sk-&gt;sk_forward_alloc &gt;&gt; SK_MEM_QUANTUM_SHIFT,prot-&gt;memory_allocated);

    // 更新这个sk的sk_forward_alloc为一页。
    sk-&gt;sk_forward_alloc &amp;= SK_MEM_QUANTUM - 1;
    // 判断是否处于pressure区域，是的话更新memory_pressure变量。
    if (prot-&gt;memory_pressure &amp;&amp; *prot-&gt;memory_pressure &amp;&amp;(atomic_read(prot-&gt;memory_allocated) &lt; （prot-&gt;sysctl_mem[0]))
        *prot-&gt;memory_pressure = 0;
}
</code></pre>

<pre><code>

最后看一下读buf的释放。这个函数会在kfree_skb中被调用。
</code></pre>

<pre><code>void sock_rfree(struct sk_buff *skb)
{

    struct sock *sk = skb-&gt;sk;
    // 更新rmem_alloc
    atomic_sub(skb-&gt;truesize, &amp;sk-&gt;sk_rmem_alloc);
    // 更新forward_alloc.
    sk_mem_uncharge(skb-&gt;sk, skb-&gt;truesize);
}
</code></pre>

<p>```</p>
]]></content>
  </entry>
  
</feed>
